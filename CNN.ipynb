{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STARTING a variational autoencoder from scratch, should input RGB images\n",
    "that are 70x70x3 (histopathological imaging)\n",
    "\n",
    "integrating some functionality from both the tutorial I found. + course DL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "* try more deep architecture (+ batch normalization, dropouts)\n",
    "* add attention layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import keras.backend as K\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history,metric=None):\n",
    "  fig, ax1 = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "  epoch_count=len(history.history['loss'])\n",
    "\n",
    "  line1,=ax1.plot(range(1,epoch_count+1),history.history['loss'],label='train_loss',color='orange')\n",
    "  ax1.plot(range(1,epoch_count+1),history.history['val_loss'],label='val_loss',color = line1.get_color(), linestyle = '--')\n",
    "  ax1.set_xlim([1,epoch_count])\n",
    "  ax1.set_ylim([0, max(max(history.history['loss']),max(history.history['val_loss']))])\n",
    "  ax1.set_ylabel('loss',color = line1.get_color())\n",
    "  ax1.tick_params(axis='y', labelcolor=line1.get_color())\n",
    "  ax1.set_xlabel('Epochs')\n",
    "  _=ax1.legend(loc='lower left')\n",
    "\n",
    "  if (metric!=None):\n",
    "    ax2 = ax1.twinx()\n",
    "    line2,=ax2.plot(range(1,epoch_count+1),history.history[metric],label='train_'+metric)\n",
    "    ax2.plot(range(1,epoch_count+1),history.history['val_'+metric],label='val_'+metric,color = line2.get_color(), linestyle = '--')\n",
    "    ax2.set_ylim([0, max(max(history.history[metric]),max(history.history['val_'+metric]))])\n",
    "    ax2.set_ylabel(metric,color=line2.get_color())\n",
    "    ax2.tick_params(axis='y', labelcolor=line2.get_color())\n",
    "    _=ax2.legend(loc='upper right')\n",
    "\n",
    "def show_confusion_matrix(conf_matrix,class_names,figsize=(10,10)):\n",
    "  fig, ax = plt.subplots(figsize=figsize)\n",
    "  img=ax.matshow(conf_matrix)\n",
    "  tick_marks = np.arange(len(class_names))\n",
    "  _=plt.xticks(tick_marks, class_names,rotation=45)\n",
    "  _=plt.yticks(tick_marks, class_names)\n",
    "  _=plt.ylabel('Real')\n",
    "  _=plt.xlabel('Predicted')\n",
    "  \n",
    "  for i in range(len(class_names)):\n",
    "    for j in range(len(class_names)):\n",
    "        text = ax.text(j, i, '{0:.1%}'.format(conf_matrix[i, j]),\n",
    "                       ha='center', va='center', color='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "imagePatches = glob('datasets/breast-histopathology/IDC_regular_ps50_idx5/**/*.png', recursive=True)\n",
    "for filename in imagePatches[0:10]:\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class0 = [] # 0 = no cancer\n",
    "class1 = [] # 1 = cancer\n",
    "\n",
    "for filename in imagePatches:\n",
    "    if filename.endswith(\"class0.png\"):\n",
    "         class0.append(filename)\n",
    "    else:\n",
    "        class1.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(class1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(class0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_class0 = random.sample(class0, 78786)\n",
    "sampled_class1 = random.sample(class1, 78786)\n",
    "print(len(sampled_class0))\n",
    "print(len(sampled_class1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imread\n",
    "import cv2\n",
    "\n",
    "def get_image_arrays(data, label):\n",
    "    img_arrays = []\n",
    "    for i in data:\n",
    "        if i.endswith('.png'):\n",
    "            img = cv2.imread(i ,cv2.IMREAD_COLOR)\n",
    "            img_sized = cv2.resize(img, (50, 50), #was (70,70)\n",
    "                        interpolation=cv2.INTER_LINEAR)\n",
    "            img_arrays.append([img_sized, label]) \n",
    "    return img_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class0_array = get_image_arrays(sampled_class0, 0)\n",
    "class1_array = get_image_arrays(sampled_class1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = cv2.imread('datasets/breast-histopathology/IDC_regular_ps50_idx5/13689/1/13689_idx5_x801_y1501_class1.png', cv2.IMREAD_COLOR)\n",
    "#test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = np.concatenate((class0_array, class1_array))\n",
    "#random.seed(11)\n",
    "#random.shuffle(combined_data) # sampling was creating unbalanced classes\n",
    "combined_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features, label in combined_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(-1, 50, 50, 3)\n",
    "y = np.array(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "np.average(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.2,\n",
    "                                    random_state = 11)\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, \n",
    "                            test_size = 0.25, random_state = 11) \n",
    "                            # 0.25 x 0.8 = 0.2\n",
    "train_y = to_categorical(train_y)\n",
    "test_y = to_categorical(test_y)\n",
    "val_y = to_categorical(val_y)\n",
    "train_y_label = np.argmax(train_y, axis=1) # from one-hot encoding to integer\n",
    "test_y_label = np.argmax(test_y, axis=1)\n",
    "val_y_label = np.argmax(val_y, axis=1)\n",
    "class_names = ('non-cancer','cancer')\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_y[0:10])\n",
    "print(train_y_label[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min value: ', train_x.min())\n",
    "print('Max value: ', train_x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x / 255\n",
    "val_x = val_x / 255\n",
    "test_x = test_x / 255\n",
    "print('Min value: ', train_x.min())\n",
    "print('Max value: ', train_x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = 10\n",
    "\n",
    "_, axs = plt.subplots(1, image_count, figsize=(20, 20))\n",
    "for i in range(image_count):\n",
    "  random_idx=random.randint(0, train_x.shape[0])\n",
    "  axs[i].imshow(train_x[random_idx], cmap='gray')\n",
    "  axs[i].axis('off')\n",
    "  axs[i].set_title(class_names[train_y_label[random_idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 250\n",
    "input_shape = (50, 50, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(input_shape=(50, 50, 3), output_class_count=2):\n",
    "    \n",
    "    inputs = layers.Input(shape=input_shape,name='Input')\n",
    "    #block 1 - pretrained\n",
    "    x = base_model.get_layer('block1_conv1')(inputs)\n",
    "    x.trainable=False\n",
    "\n",
    "    x = base_model.get_layer('block1_conv2')(x)\n",
    "    x.trainable=False\n",
    "\n",
    "    # block 2\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv1')(x)\n",
    "\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv2')(x)\n",
    "    \n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "# Block 3\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv1')(x)\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv2')(x)\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "      # Block 4\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv1')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv2')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # classifier\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    x = layers.Dense(120, activation='relu',name='dense1')(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(120, activation='relu', name='dense2')(x)\n",
    "    outputs = layers.Dense(units=output_class_count,activation='softmax',name='Output')(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.VGG19(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(50, 50, 3),\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(keras.Model):\n",
    "    def __init__(self, num_filters, kernel_size=(3, 3)):\n",
    "        super(ConvBlock, self).__init__()\n",
    "\n",
    "        self.conv = layers.Conv2D(num_filters, kernel_size)\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        self.relu = layers.Activation(\"relu\")\n",
    "        self.pooling = layers.MaxPool2D((2, 2))\n",
    "\n",
    "    def call(self, x, pool=True):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        if pool == True:\n",
    "            x = self.pooling(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(keras.Model):\n",
    "    def __init__(self, num_filters, kernel_size=(3, 3), padding='same'):\n",
    "        super(ConvBlock, self).__init__()\n",
    "\n",
    "        self.conv = layers.Conv2D(num_filters, kernel_size, padding=padding)\n",
    "        self.relu = layers.Activation(\"relu\")\n",
    "        self.pooling = layers.MaxPool2D((2, 2))\n",
    "                \n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.pooling(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = [layer.name for layer in base_model.layers][1:]\n",
    "layer_names = layer_names[0:2]\n",
    "layer_names\n",
    "base_model.get_layer('block1_conv1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_blocks(input_shape=(50, 50, 3), output_class_count=2):\n",
    "            \n",
    "    inputs = layers.Input(shape=input_shape,name='Input')\n",
    "\n",
    "    x = base_model.get_layer('block1_conv1')(inputs)\n",
    "    x.trainable=False\n",
    "\n",
    "    x = base_model.get_layer('block1_conv2')(x)\n",
    "    x.trainable=False\n",
    "\n",
    "\n",
    "    x = ConvBlock(6, kernel_size=(5, 5))(x)\n",
    "\n",
    "# layer 2   \n",
    "    x= ConvBlock(16, kernel_size=(5, 5))(x)\n",
    "    \n",
    "\n",
    "# layer 3\n",
    "    x = ConvBlock(120, kernel_size=(5, 5))(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(84, activation='relu',name='F6')(x)\n",
    "    outputs = layers.Dense(units=output_class_count,activation='softmax',name='Output')(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(input_shape=(50, 50, 3), output_class_count=2):\n",
    "                \n",
    "    inputs = layers.Input(shape=input_shape,name='Input')\n",
    "\n",
    "    x = base_model.get_layer('block1_conv1')(inputs)\n",
    "    x.trainable=False\n",
    "\n",
    "    x = base_model.get_layer('block1_conv2')(x)\n",
    "    x.trainable=False\n",
    "\n",
    "\n",
    "    x = layers.Conv2D(filters=6, kernel_size=5, strides=1,padding='valid',name='conv1_1')(x)\n",
    "   \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool2D(pool_size=2, strides=2,name='S1')(x)\n",
    "    \n",
    "\n",
    "# layer 2\n",
    "    x = layers.Conv2D(filters=16, kernel_size=5,strides=1,padding='valid',name='conv2_1')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool2D(pool_size=2, strides=2,name='S2')(x)\n",
    "    \n",
    "\n",
    "# layer 3\n",
    "    x = layers.Conv2D(filters=120, kernel_size=5,strides=1,padding='valid',name='conv3_1')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(84, activation='relu',name='F6')(x)\n",
    "    outputs = layers.Dense(units=output_class_count,activation='softmax',name='Output')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(input_shape=(50, 50, 3), output_class_count=2):\n",
    "    \n",
    "    inputs = layers.Input(shape=input_shape,name='Input')\n",
    "    #block 1 - pretrained\n",
    "    x = base_model.get_layer('block1_conv1')(inputs)\n",
    "    x.trainable=False\n",
    "\n",
    "    x = base_model.get_layer('block1_conv2')(x)\n",
    "    x.trainable=False\n",
    "\n",
    "    # block 2\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv1')(x)\n",
    "\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv2')(x)\n",
    "    \n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "# Block 3\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv1')(x)\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv2')(x)\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "      # Block 4\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv1')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv2')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # classifier\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    x = layers.Dense(120, activation='relu',name='dense1')(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(120, activation='relu', name='dense2')(x)\n",
    "    outputs = layers.Dense(units=output_class_count,activation='softmax',name='Output')(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN((50, 50, 3), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),  \n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "      f1_score,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=keras.optimizers.Adam()\n",
    "model.compile(optimizer = optimizer, loss='binary_crossentropy', metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history, metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% PLOTTING RESULTS (Train vs Validation FOLDER 1)\n",
    "\n",
    "def Train_Val_Plot(acc,val_acc,loss,val_loss,auc,val_auc,precision,val_precision,f1,val_f1):\n",
    "    \n",
    "    fig, (ax1, ax2,ax3,ax4,ax5) = plt.subplots(1,5, figsize= (16,4))\n",
    "    fig.suptitle(\" MODEL'S METRICS VISUALIZATION \")\n",
    "\n",
    "    ax1.plot(range(1, len(acc) + 1), acc)\n",
    "    ax1.plot(range(1, len(val_acc) + 1), val_acc)\n",
    "    ax1.set_title('History of Accuracy')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    #ax1.legend(['training', 'validation'])\n",
    "\n",
    "\n",
    "    ax2.plot(range(1, len(loss) + 1), loss)\n",
    "    ax2.plot(range(1, len(val_loss) + 1), val_loss)\n",
    "    ax2.set_title('History of Loss')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    #ax2.legend(['training', 'validation'])\n",
    "    \n",
    "    ax3.plot(range(1, len(auc) + 1), auc)\n",
    "    ax3.plot(range(1, len(val_auc) + 1), val_auc)\n",
    "    ax3.set_title(' History of AUC ')\n",
    "    ax3.set_xlabel(' Epochs ')\n",
    "    ax3.set_ylabel('AUC')\n",
    "    #ax3.legend(['training', 'validation'])\n",
    "    \n",
    "    ax4.plot(range(1, len(precision) + 1), precision)\n",
    "    ax4.plot(range(1, len(val_precision) + 1), val_precision)\n",
    "    ax4.set_title('History of Precision')\n",
    "    ax4.set_xlabel('Epochs')\n",
    "    ax4.set_ylabel('Precision')\n",
    "    #ax4.legend(['training', 'validation'])\n",
    "    \n",
    "    ax5.plot(range(1, len(f1) + 1), f1)\n",
    "    ax5.plot(range(1, len(val_f1) + 1), val_f1)\n",
    "    ax5.set_title('History of F1-score')\n",
    "    ax5.set_xlabel('Epochs')\n",
    "    ax5.set_ylabel('F1 score')\n",
    "    #ax5.legend(['training', 'validation'])\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "Train_Val_Plot(history.history['accuracy'],history.history['val_accuracy'],\n",
    "               history.history['loss'],history.history['val_loss'],\n",
    "               history.history['auc'],history.history['val_auc'],\n",
    "               history.history['precision'],history.history['val_precision'],\n",
    "               history.history['f1_score'],history.history['val_f1_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performance on test set\n",
    "results = model.evaluate(test_x, test_y, batch_size = batch_size, verbose=0)\n",
    "print('Loss: {:.3f} Accuracy: {:.3f}'.format(results[0], results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_conf_pred = model.predict(test_x)\n",
    "print('Output predictions shape: ',test_conf_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_pred = np.argsort(test_conf_pred, axis=1)[:,-1]\n",
    "print('Class predictions shape: ',test_y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_conf_pred = model.predict(val_x)\n",
    "print('Output predictions shape: ',test_conf_pred.shape)\n",
    "\n",
    "val_y_pred = np.argsort(test_conf_pred, axis=1)[:,-1]\n",
    "print('Class predictions shape: ',val_y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.equal(test_y_pred, test_y_label)\n",
    "accuracy = correct.sum() / len(correct)\n",
    "print('Test set accuracy: {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(test_y_label, test_y_pred, normalize='all')\n",
    "print(conf_matrix)\n",
    "show_confusion_matrix(conf_matrix,class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(test_y_label, test_y_pred, normalize='true')\n",
    "print(conf_matrix)\n",
    "show_confusion_matrix(conf_matrix,class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(val_y_label, val_y_pred, normalize='true')\n",
    "print(conf_matrix)\n",
    "show_confusion_matrix(conf_matrix,class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_to_show = 12\n",
    "\n",
    "error_indices = np.where(correct == False)[0]\n",
    "\n",
    "if error_indices.shape[0] > 0:\n",
    "  image_per_row = 4\n",
    "  top_class_count = 3\n",
    "\n",
    "  selected_indices = []\n",
    "  for i in range(min(images_to_show, error_indices.shape[0])):\n",
    "    random_idx = random.randint(0, error_indices.shape[0])\n",
    "    selected_indices.append(random_idx)\n",
    "  error_indices = error_indices[selected_indices]\n",
    "\n",
    "  row_count = math.ceil(len(error_indices)/image_per_row)\n",
    "  column_count = image_per_row\n",
    "  plt.rcParams.update({'font.size': 12})\n",
    "  _, axs = plt.subplots(row_count, column_count,figsize=(25, 4*row_count),squeeze=False)\n",
    "\n",
    "  for i in range(row_count):\n",
    "    for j in range(column_count):\n",
    "      axs[i,j].axis('off')\n",
    "\n",
    "  for i in range(len(error_indices)):\n",
    "    q = i // image_per_row\n",
    "    r = i % image_per_row\n",
    "    idx = error_indices[i]\n",
    "\n",
    "    axs[q,r].imshow(test_x[idx].squeeze(),cmap='gray')\n",
    "    axs[q,r].set_title(class_names[test_y_label[idx]])\n",
    "\n",
    "    sorted_conf_indices=np.argsort(test_conf_pred[idx])\n",
    "    best_indices=sorted_conf_indices[-top_class_count:]\n",
    "        \n",
    "    text=''\n",
    "    for j in range(len(best_indices)-1,-1,-1):\n",
    "        text+='{}: {:.3f}\\n'.format(class_names[best_indices[j]],test_conf_pred[idx][best_indices[j]])\n",
    "\n",
    "    axs[q,r].text(35, 10, text, horizontalalignment='left', verticalalignment='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save_weights('weights/CNN_weights.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_x[0]\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "img_tensor = image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "print(img_tensor.shape)\n",
    "plt.imshow(img_tensor[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return a list of 5 Numpy arrays:\n",
    "# one array per layer activation\n",
    "activations = activation_model.predict(img_tensor)\n",
    "len(activations)\n",
    "first_layer_activation = activations[5]\n",
    "print(first_layer_activation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0284a593613b942586af6b8f0d4ee916e356aed836174e2f823c929bc6bc05cc"
  },
  "kernelspec": {
   "display_name": "dis_vae",
   "language": "python",
   "name": "dis_vae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
