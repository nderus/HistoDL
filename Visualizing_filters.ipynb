{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing convnet filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/himanshurawlani/convnet-interpretability-keras/blob/master/Visualizing%20filters/visualizing_convnet_filters.ipynb\n",
    "\n",
    "- for the gradients and : https://www.sicara.ai/blog/2019-08-28-interpretability-deep-learning-tensorflow\n",
    "https://gist.github.com/RaphaelMeudec/31b7bba0b972ec6ec80ed131a59c5b3f#file-kernel_visualization-py\n",
    "\n",
    "- for building blocks instead of layers (better visualization) as blocks (conv + pooling)\n",
    "together can capture structures: https://github.com/nikhilroxtomar/Custom-Blocks-in-TensorFlow-using-Keras-API/blob/main/cifar10.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class ConvBlock(keras.Model):\n",
    "    def __init__(self, num_filters, kernel_size=(3, 3)):\n",
    "        super(ConvBlock, self).__init__()\n",
    "\n",
    "        self.conv = layers.Conv2D(num_filters, kernel_size)\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        self.relu = layers.Activation(\"relu\")\n",
    "        self.pooling = layers.MaxPool2D((2, 2))\n",
    "\n",
    "    def call(self, x, pool=True):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        if pool == True:\n",
    "            x = self.pooling(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.VGG19(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(50, 50, 3),\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_blocks(input_shape=(50, 50, 3), output_class_count=2):\n",
    "            \n",
    "    inputs = layers.Input(shape=input_shape,name='Input')\n",
    "\n",
    "    x = base_model.get_layer('block1_conv1')(inputs)\n",
    "    x.trainable=False\n",
    "\n",
    "    x = base_model.get_layer('block1_conv2')(x)\n",
    "    x.trainable=False\n",
    "\n",
    "\n",
    "    x = ConvBlock(6, kernel_size=(5, 5))(x, pool=False)\n",
    "\n",
    "# layer 2   \n",
    "    x= ConvBlock(16, kernel_size=(5, 5))(x,pool=False)\n",
    "    \n",
    "\n",
    "# layer 3\n",
    "    x = ConvBlock(120, kernel_size=(5, 5))(x, pool=False)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(84, activation='relu',name='F6')(x)\n",
    "    outputs = layers.Dense(units=output_class_count,activation='softmax',name='Output')(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'Input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/PERSONALE/nicolas.derus2/HistoML/Visualizing_filters.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoML/Visualizing_filters.ipynb#ch0000004vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m#model = load_model('models/CNN.h5', custom_objects={'f1_score':f1_score})\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoML/Visualizing_filters.ipynb#ch0000004vscode-remote?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m CNN_blocks((\u001b[39m50\u001b[39;49m, \u001b[39m50\u001b[39;49m, \u001b[39m3\u001b[39;49m), \u001b[39m2\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoML/Visualizing_filters.ipynb#ch0000004vscode-remote?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39mload_weights(\u001b[39m'\u001b[39m\u001b[39mweights/CNN_weights.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/home/PERSONALE/nicolas.derus2/HistoML/Visualizing_filters.ipynb Cell 7'\u001b[0m in \u001b[0;36mCNN_blocks\u001b[0;34m(input_shape, output_class_count)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoML/Visualizing_filters.ipynb#ch0000023vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mCNN_blocks\u001b[39m(input_shape\u001b[39m=\u001b[39m(\u001b[39m50\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m3\u001b[39m), output_class_count\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoML/Visualizing_filters.ipynb#ch0000023vscode-remote?line=2'>3</a>\u001b[0m     inputs \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39;49mInput(shape\u001b[39m=\u001b[39minput_shape,name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoML/Visualizing_filters.ipynb#ch0000023vscode-remote?line=4'>5</a>\u001b[0m     x \u001b[39m=\u001b[39m base_model\u001b[39m.\u001b[39mget_layer(\u001b[39m'\u001b[39m\u001b[39mblock1_conv1\u001b[39m\u001b[39m'\u001b[39m)(inputs)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoML/Visualizing_filters.ipynb#ch0000023vscode-remote?line=5'>6</a>\u001b[0m     x\u001b[39m.\u001b[39mtrainable\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'Input'"
     ]
    }
   ],
   "source": [
    "#model = load_model('models/CNN.h5', custom_objects={'f1_score':f1_score})\n",
    "model = CNN_blocks((50, 50, 3), 2)\n",
    "model.load_weights('weights/CNN_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    if 'conv' in layer.name:\n",
    "        print(layer.name)\n",
    "        print(len(layer.get_weights()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting visualization variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotFilters(conv_filter):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(5,5))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( conv_filter, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for layer in model.layers:\n",
    "    if 'conv' in layer.name:\n",
    "        filters, bias = layer.get_weights()\n",
    "        print(layer.name, filters.shape)\n",
    "         #normalize filter values between  0 and 1 for visualization\n",
    "        f_min, f_max = filters.min(), filters.max()\n",
    "        filters = (filters - f_min) / (f_max - f_min)  \n",
    "        print(filters.shape[3])\n",
    "        axis_x=1\n",
    "        #plotting all the filters\n",
    "        #for i in range(filters.shape[3]):\n",
    "        for i in range(6):\n",
    "            #get the filters\n",
    "            filt=filters[:,:,:, i]\n",
    "            plotFilters(filt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximize the activation of a specific filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Layer name to inspect\n",
    "layer_name = 'block1_conv2'\n",
    "\n",
    "epochs = 100\n",
    "step_size = 1.\n",
    "filter_index = 1\n",
    "\n",
    "# Create a connection between the input and the target layer\n",
    "submodel = tf.keras.models.Model([model.inputs[0]], [model.get_layer(layer_name).output])\n",
    "\n",
    "# Initiate random noise\n",
    "input_img_data = np.random.random((1, 50, 50, 3))\n",
    "input_img_data = (input_img_data - 0.5) * 20 + 128.\n",
    "\n",
    "# Cast random noise from np.float64 to tf.float32 Variable\n",
    "input_img_data = tf.Variable(tf.cast(input_img_data, tf.float32))\n",
    "\n",
    "# Iterate gradient ascents\n",
    "for _ in range(epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = submodel(input_img_data)\n",
    "        loss_value = tf.reduce_mean(outputs[:, :, :, filter_index])\n",
    "    grads = tape.gradient(loss_value, input_img_data)\n",
    "    normalized_grads = grads / (tf.sqrt(tf.reduce_mean(tf.square(grads))) + 1e-5)\n",
    "    input_img_data.assign_add(normalized_grads * step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = input_img_data.numpy().astype(np.uint8)\n",
    "img = img.squeeze()\n",
    "img = img / 255\n",
    "img.max()\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img, cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dimensions of the generated pictures for each filter.\n",
    "img_width = 50\n",
    "img_height = 50\n",
    "\n",
    "# this is the placeholder for the input images\n",
    "input_img = model.input\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "#layer_dict = dict([(layer.name, layer) for layer in model.layers[0:]])\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "layer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "# util function to convert a tensor into a valid image\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + K.epsilon())\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_ascent(iterate):\n",
    "    # step size for gradient ascent    \n",
    "    step = 1.\n",
    "\n",
    "    # we start from a gray image with some random noise\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_img_data = np.random.random((1, 3, img_width, img_height))\n",
    "    else:\n",
    "        input_img_data = np.random.random((1, img_width, img_height, 3))\n",
    "    input_img_data = (input_img_data - 0.5) * 20 + 128\n",
    "\n",
    "    # we run gradient ascent for 20 steps\n",
    "    for i in range(20):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "\n",
    "#         print('------>Current loss value:', loss_value)\n",
    "        if loss_value <= 0.:\n",
    "            # some filters get stuck to 0, we can skip them\n",
    "            break\n",
    "        \n",
    "    # decode the resulting input image\n",
    "    if loss_value > 0:\n",
    "        img = deprocess_image(input_img_data[0])\n",
    "        kept_filters.append((img, loss_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nth_filter_loss(filter_index, layer_name):\n",
    "    \"\"\"\n",
    "    We build a loss function that maximizes the activation\n",
    "    of the nth filter of the layer considered\n",
    "    \"\"\"\n",
    "    \n",
    "    layer_output = layer_dict[layer_name].output\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        loss = K.mean(layer_output[:, filter_index, :, :])\n",
    "    else:\n",
    "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "    # Initiate random noise\n",
    "    # Create a connection between the input and the target layer\n",
    "    \n",
    "    submodel = tf.keras.models.Model([model.inputs[0]], [model.get_layer(layer_name).output])\n",
    "\n",
    "# Initiate random noise\n",
    "\n",
    "    input_img_data = np.random.random((1, 50, 50, 3))\n",
    "    input_img_data = (input_img_data - 0.5) * 20 + 128.\n",
    "\n",
    "    # Cast random noise from np.float64 to tf.float32 Variable\n",
    "    input_img_data = tf.Variable(tf.cast(input_img_data, tf.float32))\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = submodel(input_img_data)\n",
    "            loss_value = tf.reduce_mean(outputs[:, :, :, filter_index])\n",
    "        grads = tape.gradient(loss_value, input_img_data)\n",
    "        normalized_grads = grads / (tf.sqrt(tf.reduce_mean(tf.square(grads))) + 1e-5)\n",
    "        input_img_data.assign_add(normalized_grads * step_size)\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    #iterate = K.function([input_img], [loss_value, grads])\n",
    "\n",
    "    if loss_value > 0:\n",
    "        img = input_img_data.numpy().astype(np.float64)\n",
    "        img = img.squeeze()\n",
    "        img = deprocess_image(img)\n",
    "        kept_filters.append((img, loss_value))\n",
    "    #return iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [layer.name for layer in model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = model.get_layer('conv_block_1')\n",
    "range(min(layer.output.shape[-1], 100))\n",
    "layer_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_index = 5\n",
    "build_nth_filter_loss(filter_index, layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "kept_filters = []\n",
    "filters_dict = dict()\n",
    "for layer_name in layers:\n",
    "    if 'conv' in layer_name:\n",
    "        layer = model.get_layer(layer_name)\n",
    "        print('Processing filter for layer:', layer_name)\n",
    "        for filter_index in range(min(layer.output.shape[-1], 100)):\n",
    "            # print('Processing filter %d' % filter_index)\n",
    "\n",
    "            start_time = time.time()\n",
    "            build_nth_filter_loss(filter_index, layer_name)\n",
    "            end_time = time.time()\n",
    "\n",
    "    #         print('--->Filter %d processed in %ds' % (filter_index, end_time - start_time))\n",
    "        filters_dict[layer.name] = kept_filters\n",
    "        kept_filters = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_name, kept_filters in filters_dict.items():\n",
    "    print(layer_name, len(kept_filters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import save_img\n",
    "\n",
    "def stich_filters(kept_filters, layer_name):\n",
    "    # By default, we will stich the best 64 (n*n) filters on a 8 x 8 grid.\n",
    "    n = int(np.sqrt(len(kept_filters)))\n",
    "    # the filters that have the highest loss are assumed to be better-looking.\n",
    "    # we will only keep the top 64 filters.\n",
    "    kept_filters.sort(key=lambda x: x[1], reverse=True)\n",
    "    kept_filters = kept_filters[:n * n]\n",
    "\n",
    "    # build a black picture with enough space for\n",
    "    # our 8 x 8 filters of size 128 x 128, with a 5px margin in between\n",
    "    margin = 5\n",
    "    width = n * img_width + (n - 1) * margin\n",
    "    height = n * img_height + (n - 1) * margin\n",
    "    stitched_filters = np.zeros((width, height, 3))\n",
    "\n",
    "    # fill the picture with our saved filters\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            img, loss = kept_filters[i * n + j]\n",
    "            width_margin = (img_width + margin) * i\n",
    "            height_margin = (img_height + margin) * j\n",
    "            stitched_filters[\n",
    "                width_margin: width_margin + img_width,\n",
    "                height_margin: height_margin + img_height, :] = img\n",
    "\n",
    "    # save the result to disk\n",
    "    save_img('img/stitched_filters_{}.png'.format(layer_name), stitched_filters)\n",
    "    \n",
    "for layer_name, kept_filters in filters_dict.items():\n",
    "    print('Stiching filters for {}'.format(layer_name))\n",
    "    stich_filters(kept_filters, layer_name)\n",
    "    print('number of filters kept:', len(kept_filters))\n",
    "    print('Completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "filter_name = 'conv_block_2'\n",
    "\n",
    "img = image.img_to_array(image.load_img('img/stitched_filters_{}.png'.format(filter_name))) /255.\n",
    "plt.figure(figsize=(17,17))\n",
    "plt.imshow(img)\n",
    "plt.title(filter_name)\n",
    "plt.grid(False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0284a593613b942586af6b8f0d4ee916e356aed836174e2f823c929bc6bc05cc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('dis_vae')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
