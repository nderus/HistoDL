{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing convnet filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/himanshurawlani/convnet-interpretability-keras/blob/master/Visualizing%20filters/visualizing_convnet_filters.ipynb\n",
    "\n",
    "- for the gradients and : https://www.sicara.ai/blog/2019-08-28-interpretability-deep-learning-tensorflow\n",
    "https://gist.github.com/RaphaelMeudec/31b7bba0b972ec6ec80ed131a59c5b3f#file-kernel_visualization-py\n",
    "\n",
    "- for building blocks instead of layers (better visualization) as blocks (conv + pooling)\n",
    "together can capture structures: https://github.com/nikhilroxtomar/Custom-Blocks-in-TensorFlow-using-Keras-API/blob/main/cifar10.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.VGG19(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(50, 50, 3),\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 50, 50, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 50, 50, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 50, 50, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 25, 25, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 25, 25, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 25, 25, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(keras.Model):\n",
    "    def __init__(self, num_filters, kernel_size=(3, 3), padding='same'):\n",
    "        super(ConvBlock, self).__init__()\n",
    "\n",
    "        self.conv = layers.Conv2D(num_filters, kernel_size, padding=padding)\n",
    "        self.relu = layers.Activation(\"relu\")\n",
    "        self.pooling = layers.MaxPool2D((2, 2))\n",
    "                \n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.pooling(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_blocks(input_shape=(50, 50, 3), output_class_count=2):\n",
    "            \n",
    "    inputs = layers.Input(shape=input_shape,name='Input')\n",
    "\n",
    "    x = base_model.get_layer('block1_conv1')(inputs)\n",
    "    x.trainable=False\n",
    "\n",
    "    x = base_model.get_layer('block1_conv2')(x)\n",
    "    x.trainable=False\n",
    "\n",
    "\n",
    "    x = ConvBlock(6, kernel_size=(5, 5))(x)\n",
    "\n",
    "# layer 2   \n",
    "    x= ConvBlock(16, kernel_size=(5, 5))(x)\n",
    "    \n",
    "\n",
    "# layer 3\n",
    "    x = ConvBlock(120, kernel_size=(5, 5))(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(84, activation='relu',name='F6')(x)\n",
    "    outputs = layers.Dense(units=output_class_count,activation='softmax',name='Output')(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(input_shape=(50, 50, 3), output_class_count=2):\n",
    "                \n",
    "    inputs = layers.Input(shape=input_shape,name='Input')\n",
    "\n",
    "    x = base_model.get_layer('block1_conv1')(inputs)\n",
    "    x.trainable=False\n",
    "\n",
    "    x = base_model.get_layer('block1_conv2')(x)\n",
    "    x.trainable=False\n",
    "\n",
    "\n",
    "    x = layers.Conv2D(filters=6, kernel_size=5, strides=1,padding='valid',name='conv1_1')(x)\n",
    "   \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool2D(pool_size=2, strides=2,name='S1')(x)\n",
    "    \n",
    "\n",
    "# layer 2\n",
    "    x = layers.Conv2D(filters=16, kernel_size=5,strides=1,padding='valid',name='conv2_1')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool2D(pool_size=2, strides=2,name='S2')(x)\n",
    "    \n",
    "\n",
    "# layer 3\n",
    "    x = layers.Conv2D(filters=120, kernel_size=5,strides=1,padding='valid',name='conv3_1')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(84, activation='relu',name='F6')(x)\n",
    "    outputs = layers.Dense(units=output_class_count,activation='softmax',name='Output')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = CNN((50, 50, 3), 2)\n",
    "model.load_weights('weights/CNN_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_254\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 50, 50, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 50, 50, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 50, 50, 64)        36928     \n",
      "                                                                 \n",
      " conv1_1 (Conv2D)            (None, 46, 46, 6)         9606      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 46, 46, 6)        24        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 46, 46, 6)         0         \n",
      "                                                                 \n",
      " S1 (MaxPooling2D)           (None, 23, 23, 6)         0         \n",
      "                                                                 \n",
      " conv2_1 (Conv2D)            (None, 19, 19, 16)        2416      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 19, 19, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 19, 19, 16)        0         \n",
      "                                                                 \n",
      " S2 (MaxPooling2D)           (None, 9, 9, 16)          0         \n",
      "                                                                 \n",
      " conv3_1 (Conv2D)            (None, 5, 5, 120)         48120     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 5, 5, 120)        480       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_5 (ReLU)              (None, 5, 5, 120)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 3000)              0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 3000)              0         \n",
      "                                                                 \n",
      " F6 (Dense)                  (None, 84)                252084    \n",
      "                                                                 \n",
      " Output (Dense)              (None, 2)                 170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 351,684\n",
      "Trainable params: 351,400\n",
      "Non-trainable params: 284\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block1_conv1\n",
      "2\n",
      "block1_conv2\n",
      "2\n",
      "conv1_1\n",
      "2\n",
      "conv2_1\n",
      "2\n",
      "conv3_1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    if 'conv' in layer.name:\n",
    "        print(layer.name)\n",
    "        print(len(layer.get_weights()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "l, b = model.get_layer('block1_conv1').get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = model.get_layer('conv1').get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block1_conv1 (3, 3, 3, 64)\n",
      "block1_conv2 (3, 3, 64, 64)\n",
      "conv1_1 (5, 5, 64, 6)\n",
      "conv2_1 (5, 5, 6, 16)\n",
      "conv3_1 (5, 5, 16, 120)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    if 'conv' in layer.name:\n",
    "        filters, bias = layer.get_weights()\n",
    "        print(layer.name, filters.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting visualization variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximize the activation of a specific filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No such layer: conv_block. Existing layers are [<keras.engine.input_layer.InputLayer object at 0x7efcf00f6b80>, <keras.layers.convolutional.Conv2D object at 0x7efcb01952b0>, <keras.layers.convolutional.Conv2D object at 0x7efcb00ab6a0>, <keras.layers.convolutional.Conv2D object at 0x7efcf1a12520>, <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7efcf11bd130>, <keras.layers.advanced_activations.ReLU object at 0x7efcf273ea30>, <keras.layers.pooling.MaxPooling2D object at 0x7efcf00f6490>, <keras.layers.convolutional.Conv2D object at 0x7efcf563d490>, <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7efcb00cc400>, <keras.layers.advanced_activations.ReLU object at 0x7efce00b2a60>, <keras.layers.pooling.MaxPooling2D object at 0x7efcb01ee3a0>, <keras.layers.convolutional.Conv2D object at 0x7efcf00dc310>, <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7efcf00f61c0>, <keras.layers.advanced_activations.ReLU object at 0x7efcf00ea730>, <keras.layers.core.flatten.Flatten object at 0x7efcf00cc5e0>, <keras.layers.core.dropout.Dropout object at 0x7efcb072a8b0>, <keras.layers.core.dense.Dense object at 0x7efcb008fdc0>, <keras.layers.core.dense.Dense object at 0x7efcb01eedf0>].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/PERSONALE/nicolas.derus2/HistoDL/Visualizing_filters.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoDL/Visualizing_filters.ipynb#ch0000017vscode-remote?line=12'>13</a>\u001b[0m \u001b[39mtry\u001b[39;00m: \n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoDL/Visualizing_filters.ipynb#ch0000017vscode-remote?line=13'>14</a>\u001b[0m     submodel \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mModel([model\u001b[39m.\u001b[39minputs[\u001b[39m0\u001b[39m]], [model\u001b[39m.\u001b[39;49mget_layer(layer_name)\u001b[39m.\u001b[39mget_output_at(\u001b[39m1\u001b[39m)])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoDL/Visualizing_filters.ipynb#ch0000017vscode-remote?line=15'>16</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/engine/training.py:2631\u001b[0m, in \u001b[0;36mModel.get_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m   <a href='file:///home/PERSONALE/nicolas.derus2/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/engine/training.py?line=2629'>2630</a>\u001b[0m       \u001b[39mreturn\u001b[39;00m layer\n\u001b[0;32m-> <a href='file:///home/PERSONALE/nicolas.derus2/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/engine/training.py?line=2630'>2631</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNo such layer: \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m. Existing layers are \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   <a href='file:///home/PERSONALE/nicolas.derus2/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/engine/training.py?line=2631'>2632</a>\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   <a href='file:///home/PERSONALE/nicolas.derus2/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/engine/training.py?line=2632'>2633</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mProvide either a layer name or layer index at \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   <a href='file:///home/PERSONALE/nicolas.derus2/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/engine/training.py?line=2633'>2634</a>\u001b[0m                  \u001b[39m'\u001b[39m\u001b[39m`get_layer`.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: No such layer: conv_block. Existing layers are [<keras.engine.input_layer.InputLayer object at 0x7efcf00f6b80>, <keras.layers.convolutional.Conv2D object at 0x7efcb01952b0>, <keras.layers.convolutional.Conv2D object at 0x7efcb00ab6a0>, <keras.layers.convolutional.Conv2D object at 0x7efcf1a12520>, <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7efcf11bd130>, <keras.layers.advanced_activations.ReLU object at 0x7efcf273ea30>, <keras.layers.pooling.MaxPooling2D object at 0x7efcf00f6490>, <keras.layers.convolutional.Conv2D object at 0x7efcf563d490>, <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7efcb00cc400>, <keras.layers.advanced_activations.ReLU object at 0x7efce00b2a60>, <keras.layers.pooling.MaxPooling2D object at 0x7efcb01ee3a0>, <keras.layers.convolutional.Conv2D object at 0x7efcf00dc310>, <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7efcf00f61c0>, <keras.layers.advanced_activations.ReLU object at 0x7efcf00ea730>, <keras.layers.core.flatten.Flatten object at 0x7efcf00cc5e0>, <keras.layers.core.dropout.Dropout object at 0x7efcb072a8b0>, <keras.layers.core.dense.Dense object at 0x7efcb008fdc0>, <keras.layers.core.dense.Dense object at 0x7efcb01eedf0>].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/PERSONALE/nicolas.derus2/HistoDL/Visualizing_filters.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoDL/Visualizing_filters.ipynb#ch0000017vscode-remote?line=13'>14</a>\u001b[0m     submodel \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mModel([model\u001b[39m.\u001b[39minputs[\u001b[39m0\u001b[39m]], [model\u001b[39m.\u001b[39mget_layer(layer_name)\u001b[39m.\u001b[39mget_output_at(\u001b[39m1\u001b[39m)])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoDL/Visualizing_filters.ipynb#ch0000017vscode-remote?line=15'>16</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoDL/Visualizing_filters.ipynb#ch0000017vscode-remote?line=16'>17</a>\u001b[0m     submodel \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mModel([model\u001b[39m.\u001b[39minputs[\u001b[39m0\u001b[39m]], [model\u001b[39m.\u001b[39;49mget_layer(layer_name)\u001b[39m.\u001b[39moutput])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoDL/Visualizing_filters.ipynb#ch0000017vscode-remote?line=18'>19</a>\u001b[0m \u001b[39m# Initiate random noise\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoDL/Visualizing_filters.ipynb#ch0000017vscode-remote?line=19'>20</a>\u001b[0m input_img_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandom((\u001b[39m1\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m3\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/engine/training.py:2631\u001b[0m, in \u001b[0;36mModel.get_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m   <a href='file:///home/PERSONALE/nicolas.derus2/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/engine/training.py?line=2628'>2629</a>\u001b[0m     \u001b[39mif\u001b[39;00m layer\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m name:\n\u001b[1;32m   <a href='file:///home/PERSONALE/nicolas.derus2/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/engine/training.py?line=2629'>2630</a>\u001b[0m       \u001b[39mreturn\u001b[39;00m layer\n\u001b[0;32m-> <a href='file:///home/PERSONALE/nicolas.derus2/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/engine/training.py?line=2630'>2631</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNo such layer: \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m. Existing layers are \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   <a href='file:///home/PERSONALE/nicolas.derus2/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/engine/training.py?line=2631'>2632</a>\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   <a href='file:///home/PERSONALE/nicolas.derus2/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/engine/training.py?line=2632'>2633</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mProvide either a layer name or layer index at \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   <a href='file:///home/PERSONALE/nicolas.derus2/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/engine/training.py?line=2633'>2634</a>\u001b[0m                  \u001b[39m'\u001b[39m\u001b[39m`get_layer`.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: No such layer: conv_block. Existing layers are [<keras.engine.input_layer.InputLayer object at 0x7efcf00f6b80>, <keras.layers.convolutional.Conv2D object at 0x7efcb01952b0>, <keras.layers.convolutional.Conv2D object at 0x7efcb00ab6a0>, <keras.layers.convolutional.Conv2D object at 0x7efcf1a12520>, <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7efcf11bd130>, <keras.layers.advanced_activations.ReLU object at 0x7efcf273ea30>, <keras.layers.pooling.MaxPooling2D object at 0x7efcf00f6490>, <keras.layers.convolutional.Conv2D object at 0x7efcf563d490>, <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7efcb00cc400>, <keras.layers.advanced_activations.ReLU object at 0x7efce00b2a60>, <keras.layers.pooling.MaxPooling2D object at 0x7efcb01ee3a0>, <keras.layers.convolutional.Conv2D object at 0x7efcf00dc310>, <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7efcf00f61c0>, <keras.layers.advanced_activations.ReLU object at 0x7efcf00ea730>, <keras.layers.core.flatten.Flatten object at 0x7efcf00cc5e0>, <keras.layers.core.dropout.Dropout object at 0x7efcb072a8b0>, <keras.layers.core.dense.Dense object at 0x7efcb008fdc0>, <keras.layers.core.dense.Dense object at 0x7efcb01eedf0>]."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Layer name to inspect\n",
    "layer_name = 'conv_block'\n",
    "\n",
    "epochs = 100\n",
    "step_size = 1.\n",
    "filter_index = 5\n",
    "\n",
    "# Create a connection between the input and the target layer\n",
    "\n",
    "try: \n",
    "    submodel = tf.keras.models.Model([model.inputs[0]], [model.get_layer(layer_name).get_output_at(1)])\n",
    "    \n",
    "except:\n",
    "    submodel = tf.keras.models.Model([model.inputs[0]], [model.get_layer(layer_name).output])\n",
    "\n",
    "# Initiate random noise\n",
    "input_img_data = np.random.random((1, 50, 50, 3))\n",
    "input_img_data = (input_img_data - 0.5) * 20 + 128.\n",
    "\n",
    "# Cast random noise from np.float64 to tf.float32 Variable\n",
    "input_img_data = tf.Variable(tf.cast(input_img_data, tf.float32))\n",
    "\n",
    "# Iterate gradient ascents\n",
    "for _ in range(epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = submodel(input_img_data)\n",
    "        loss_value = tf.reduce_mean(outputs[:, :, :, filter_index])\n",
    "    grads = tape.gradient(loss_value, input_img_data)\n",
    "    normalized_grads = grads / (tf.sqrt(tf.reduce_mean(tf.square(grads))) + 1e-5)\n",
    "    input_img_data.assign_add(normalized_grads * step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18576"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = input_img_data.numpy().astype(np.uint8)\n",
    "img = img.squeeze()\n",
    "img = img / 255\n",
    "img.max()\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img, cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'block1_conv1': <keras.layers.convolutional.Conv2D at 0x7efce0092940>,\n",
       " 'block1_conv2': <keras.layers.convolutional.Conv2D at 0x7efe3c251850>,\n",
       " 'conv_block': <__main__.ConvBlock at 0x7efe3c272100>,\n",
       " 'conv_block_1': <__main__.ConvBlock at 0x7efcf0079be0>,\n",
       " 'conv_block_2': <__main__.ConvBlock at 0x7efce00a81c0>,\n",
       " 'flatten_1': <keras.layers.core.flatten.Flatten at 0x7efcf0063a30>,\n",
       " 'dropout_1': <keras.layers.core.dropout.Dropout at 0x7efce0049b80>,\n",
       " 'F6': <keras.layers.core.dense.Dense at 0x7efce0340b50>,\n",
       " 'Output': <keras.layers.core.dense.Dense at 0x7efce0092c40>}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dimensions of the generated pictures for each filter.\n",
    "img_width = 50\n",
    "img_height = 50\n",
    "\n",
    "# this is the placeholder for the input images\n",
    "input_img = model.input\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "#layer_dict = dict([(layer.name, layer) for layer in model.layers[0:]])\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "layer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "# util function to convert a tensor into a valid image\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + K.epsilon())\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nth_filter_loss(filter_index, layer_name):\n",
    "    \"\"\"\n",
    "    We build a loss function that maximizes the activation\n",
    "    of the nth filter of the layer considered\n",
    "    \"\"\"\n",
    "    \n",
    "    layer_output = layer_dict[layer_name].output\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        loss = K.mean(layer_output[:, filter_index, :, :])\n",
    "    else:\n",
    "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "    # Initiate random noise\n",
    "    # Create a connection between the input and the target layer\n",
    "    \n",
    "    try: \n",
    "        submodel = tf.keras.models.Model([model.inputs[0]], [model.get_layer(layer_name).get_output_at(1)])\n",
    "    \n",
    "    except:\n",
    "        submodel = tf.keras.models.Model([model.inputs[0]], [model.get_layer(layer_name).output])\n",
    "\n",
    "\n",
    "# Initiate random noise\n",
    "\n",
    "    input_img_data = np.random.random((1, 50, 50, 3))\n",
    "    input_img_data = (input_img_data - 0.5) * 20 + 128.\n",
    "\n",
    "    # Cast random noise from np.float64 to tf.float32 Variable\n",
    "    input_img_data = tf.Variable(tf.cast(input_img_data, tf.float32))\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = submodel(input_img_data)\n",
    "            loss_value = tf.reduce_mean(outputs[:, :, :, filter_index])\n",
    "        grads = tape.gradient(loss_value, input_img_data)\n",
    "        normalized_grads = grads / (tf.sqrt(tf.reduce_mean(tf.square(grads))) + 1e-5)\n",
    "        input_img_data.assign_add(normalized_grads * step_size)\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    #iterate = K.function([input_img], [loss_value, grads])\n",
    "\n",
    "    #if loss_value > 0:\n",
    "    img = input_img_data.numpy().astype(np.float64)\n",
    "    img = img.squeeze()\n",
    "    img = deprocess_image(img)\n",
    "    kept_filters.append((img, loss_value))\n",
    "    #return iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [layer.name for layer in model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing filter for layer: block1_conv1\n",
      "Processing filter for layer: block1_conv2\n",
      "Processing filter for layer: conv_block\n",
      "Processing filter for layer: conv_block_1\n",
      "Processing filter for layer: conv_block_2\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "kept_filters = []\n",
    "filters_dict = dict()\n",
    "for layer_name in layers:\n",
    "    if 'conv' in layer_name:\n",
    "        layer = model.get_layer(layer_name)\n",
    "        print('Processing filter for layer:', layer_name)\n",
    "        for filter_index in range(min(layer.output.shape[-1], 100)):\n",
    "            # print('Processing filter %d' % filter_index)\n",
    "\n",
    "            start_time = time.time()\n",
    "            build_nth_filter_loss(filter_index, layer_name)\n",
    "            end_time = time.time()\n",
    "\n",
    "    #         print('--->Filter %d processed in %ds' % (filter_index, end_time - start_time))\n",
    "        filters_dict[layer.name] = kept_filters\n",
    "        kept_filters = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block1_conv1 64\n",
      "block1_conv2 64\n",
      "conv_block 6\n",
      "conv_block_1 16\n",
      "conv_block_2 100\n"
     ]
    }
   ],
   "source": [
    "for layer_name, kept_filters in filters_dict.items():\n",
    "    print(layer_name, len(kept_filters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stiching filters for block1_conv1\n",
      "number of filters kept: 64\n",
      "Completed.\n",
      "Stiching filters for block1_conv2\n",
      "number of filters kept: 64\n",
      "Completed.\n",
      "Stiching filters for conv_block\n",
      "number of filters kept: 6\n",
      "Completed.\n",
      "Stiching filters for conv_block_1\n",
      "number of filters kept: 16\n",
      "Completed.\n",
      "Stiching filters for conv_block_2\n",
      "number of filters kept: 100\n",
      "Completed.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import save_img\n",
    "\n",
    "def stich_filters(kept_filters, layer_name):\n",
    "    # By default, we will stich the best 64 (n*n) filters on a 8 x 8 grid.\n",
    "    n = int(np.sqrt(len(kept_filters)))\n",
    "    # the filters that have the highest loss are assumed to be better-looking.\n",
    "    # we will only keep the top 64 filters.\n",
    "    kept_filters.sort(key=lambda x: x[1], reverse=True)\n",
    "    kept_filters = kept_filters[:n * n]\n",
    "\n",
    "    # build a black picture with enough space for\n",
    "    # our 8 x 8 filters of size 128 x 128, with a 5px margin in between\n",
    "    margin = 5\n",
    "    width = n * img_width + (n - 1) * margin\n",
    "    height = n * img_height + (n - 1) * margin\n",
    "    stitched_filters = np.zeros((width, height, 3))\n",
    "\n",
    "    # fill the picture with our saved filters\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            img, loss = kept_filters[i * n + j]\n",
    "            width_margin = (img_width + margin) * i\n",
    "            height_margin = (img_height + margin) * j\n",
    "            stitched_filters[\n",
    "                width_margin: width_margin + img_width,\n",
    "                height_margin: height_margin + img_height, :] = img\n",
    "\n",
    "    # save the result to disk\n",
    "    save_img('img/filters/stitched_filters_{}.png'.format(layer_name), stitched_filters)\n",
    "    \n",
    "for layer_name, kept_filters in filters_dict.items():\n",
    "    print('Stiching filters for {}'.format(layer_name))\n",
    "    stich_filters(kept_filters, layer_name)\n",
    "    print('number of filters kept:', len(kept_filters))\n",
    "    print('Completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "filter_name = 'conv3'\n",
    "\n",
    "img = image.img_to_array(image.load_img('img/stitched_filters_{}.png'.format(filter_name))) /255.\n",
    "plt.figure(figsize=(17,17))\n",
    "plt.imshow(img)\n",
    "plt.title(filter_name)\n",
    "plt.grid(False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0284a593613b942586af6b8f0d4ee916e356aed836174e2f823c929bc6bc05cc"
  },
  "kernelspec": {
   "display_name": "dis_vae",
   "language": "python",
   "name": "dis_vae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
