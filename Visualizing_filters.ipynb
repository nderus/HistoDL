{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing convnet filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/himanshurawlani/convnet-interpretability-keras/blob/master/Visualizing%20filters/visualizing_convnet_filters.ipynb\n",
    "\n",
    "- for the gradients and : https://www.sicara.ai/blog/2019-08-28-interpretability-deep-learning-tensorflow\n",
    "https://gist.github.com/RaphaelMeudec/31b7bba0b972ec6ec80ed131a59c5b3f#file-kernel_visualization-py\n",
    "\n",
    "- for building blocks instead of layers (better visualization) as blocks (conv + pooling)\n",
    "together can capture structures: https://github.com/nikhilroxtomar/Custom-Blocks-in-TensorFlow-using-Keras-API/blob/main/cifar10.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.VGG19(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(50, 50, 3),\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 50, 50, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 50, 50, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 50, 50, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 25, 25, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 25, 25, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 25, 25, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(input_shape=(50, 50, 3), output_class_count=2):\n",
    "                \n",
    "    inputs = layers.Input(shape=input_shape,name='Input')\n",
    "\n",
    "    x = base_model.get_layer('block1_conv1')(inputs)\n",
    "    x.trainable=False\n",
    "\n",
    "    x = base_model.get_layer('block1_conv2')(x)\n",
    "    x.trainable=False\n",
    "\n",
    "\n",
    "    x = layers.Conv2D(filters=6, kernel_size=5, strides=1,padding='valid',name='conv1')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.MaxPool2D(pool_size=2, strides=2,name='S2')(x)\n",
    "    \n",
    "\n",
    "# layer 2\n",
    "    x = layers.Conv2D(filters=16, kernel_size=5,strides=1,padding='valid',name='conv2')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPool2D(pool_size=2, strides=2,name='S4')(x)\n",
    "    \n",
    "# layer 3\n",
    "    x = layers.Conv2D(filters=120, kernel_size=5,strides=1,padding='valid',name='conv3')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Dense(84, activation='relu',name='F6')(x)\n",
    "    outputs = layers.Dense(units=output_class_count,activation='softmax',name='Output')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = load_model('models/CNN.h5', custom_objects={'f1_score':f1_score})\n",
    "model = CNN((50, 50, 3), 2)\n",
    "model.load_weights('weights/CNN_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 50, 50, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 50, 50, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 50, 50, 64)        36928     \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 46, 46, 6)         9606      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 46, 46, 6)        24        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 46, 46, 6)         0         \n",
      "                                                                 \n",
      " S2 (MaxPooling2D)           (None, 23, 23, 6)         0         \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 19, 19, 16)        2416      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 19, 19, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 19, 19, 16)        0         \n",
      "                                                                 \n",
      " S4 (MaxPooling2D)           (None, 9, 9, 16)          0         \n",
      "                                                                 \n",
      " conv3 (Conv2D)              (None, 5, 5, 120)         48120     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 5, 5, 120)        480       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_5 (ReLU)              (None, 5, 5, 120)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3000)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 3000)              0         \n",
      "                                                                 \n",
      " F6 (Dense)                  (None, 84)                252084    \n",
      "                                                                 \n",
      " Output (Dense)              (None, 2)                 170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 351,684\n",
      "Trainable params: 351,400\n",
      "Non-trainable params: 284\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block1_conv1\n",
      "2\n",
      "block1_conv2\n",
      "2\n",
      "conv1\n",
      "2\n",
      "conv2\n",
      "2\n",
      "conv3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    if 'conv' in layer.name:\n",
    "        print(layer.name)\n",
    "        print(len(layer.get_weights()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "l, b = model.get_layer('block1_conv1').get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = model.get_layer('conv1').get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block1_conv1 (3, 3, 3, 64)\n",
      "block1_conv2 (3, 3, 64, 64)\n",
      "conv1 (5, 5, 64, 6)\n",
      "conv2 (5, 5, 6, 16)\n",
      "conv3 (5, 5, 16, 120)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    if 'conv' in layer.name:\n",
    "        filters, bias = layer.get_weights()\n",
    "        print(layer.name, filters.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting visualization variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximize the activation of a specific filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Layer name to inspect\n",
    "layer_name = 'conv1'\n",
    "\n",
    "epochs = 100\n",
    "step_size = 1.\n",
    "filter_index = 5\n",
    "\n",
    "# Create a connection between the input and the target layer\n",
    "\n",
    "try: \n",
    "    submodel = tf.keras.models.Model([model.inputs[0]], [model.get_layer(layer_name).get_output_at(1)])\n",
    "    \n",
    "except:\n",
    "    submodel = tf.keras.models.Model([model.inputs[0]], [model.get_layer(layer_name).output])\n",
    "\n",
    "# Initiate random noise\n",
    "input_img_data = np.random.random((1, 50, 50, 3))\n",
    "input_img_data = (input_img_data - 0.5) * 20 + 128.\n",
    "\n",
    "# Cast random noise from np.float64 to tf.float32 Variable\n",
    "input_img_data = tf.Variable(tf.cast(input_img_data, tf.float32))\n",
    "\n",
    "# Iterate gradient ascents\n",
    "for _ in range(epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = submodel(input_img_data)\n",
    "        loss_value = tf.reduce_mean(outputs[:, :, :, filter_index])\n",
    "    grads = tape.gradient(loss_value, input_img_data)\n",
    "    normalized_grads = grads / (tf.sqrt(tf.reduce_mean(tf.square(grads))) + 1e-5)\n",
    "    input_img_data.assign_add(normalized_grads * step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36170"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(loss_value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = input_img_data.numpy().astype(np.uint8)\n",
    "img = img.squeeze()\n",
    "img = img / 255\n",
    "img.max()\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img, cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'block1_conv1': <keras.layers.convolutional.Conv2D at 0x7f80c6c9a5b0>,\n",
       " 'block1_conv2': <keras.layers.convolutional.Conv2D at 0x7f81c849f910>,\n",
       " 'conv1': <keras.layers.convolutional.Conv2D at 0x7f8144753970>,\n",
       " 'batch_normalization_3': <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f80c6ba02e0>,\n",
       " 're_lu_3': <keras.layers.advanced_activations.ReLU at 0x7f80c6b99a60>,\n",
       " 'S2': <keras.layers.pooling.MaxPooling2D at 0x7f80c6b9c940>,\n",
       " 'conv2': <keras.layers.convolutional.Conv2D at 0x7f80c6b9cd00>,\n",
       " 'batch_normalization_4': <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f80c6b9e9d0>,\n",
       " 're_lu_4': <keras.layers.advanced_activations.ReLU at 0x7f80c6b9f310>,\n",
       " 'S4': <keras.layers.pooling.MaxPooling2D at 0x7f80c6b9d220>,\n",
       " 'conv3': <keras.layers.convolutional.Conv2D at 0x7f80c6b99970>,\n",
       " 'batch_normalization_5': <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f80c6ba5f40>,\n",
       " 're_lu_5': <keras.layers.advanced_activations.ReLU at 0x7f80c6b9c640>,\n",
       " 'flatten_1': <keras.layers.core.flatten.Flatten at 0x7f80c6ba6250>,\n",
       " 'dropout_1': <keras.layers.core.dropout.Dropout at 0x7f80c6ba8bb0>,\n",
       " 'F6': <keras.layers.core.dense.Dense at 0x7f80c6ba6130>,\n",
       " 'Output': <keras.layers.core.dense.Dense at 0x7f80c6baa040>}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dimensions of the generated pictures for each filter.\n",
    "img_width = 50\n",
    "img_height = 50\n",
    "\n",
    "# this is the placeholder for the input images\n",
    "input_img = model.input\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "#layer_dict = dict([(layer.name, layer) for layer in model.layers[0:]])\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "layer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "# util function to convert a tensor into a valid image\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + K.epsilon())\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nth_filter_loss(filter_index, layer_name):\n",
    "    \"\"\"\n",
    "    We build a loss function that maximizes the activation\n",
    "    of the nth filter of the layer considered\n",
    "    \"\"\"\n",
    "    \n",
    "    layer_output = layer_dict[layer_name].output\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        loss = K.mean(layer_output[:, filter_index, :, :])\n",
    "    else:\n",
    "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "    # Initiate random noise\n",
    "    # Create a connection between the input and the target layer\n",
    "    \n",
    "    try: \n",
    "        submodel = tf.keras.models.Model([model.inputs[0]], [model.get_layer(layer_name).get_output_at(1)])\n",
    "    \n",
    "    except:\n",
    "        submodel = tf.keras.models.Model([model.inputs[0]], [model.get_layer(layer_name).output])\n",
    "\n",
    "\n",
    "# Initiate random noise\n",
    "\n",
    "    input_img_data = np.random.random((1, 50, 50, 3))\n",
    "    input_img_data = (input_img_data - 0.5) * 20 + 128.\n",
    "\n",
    "    # Cast random noise from np.float64 to tf.float32 Variable\n",
    "    input_img_data = tf.Variable(tf.cast(input_img_data, tf.float32))\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = submodel(input_img_data)\n",
    "            loss_value = tf.reduce_mean(outputs[:, :, :, filter_index])\n",
    "        grads = tape.gradient(loss_value, input_img_data)\n",
    "        normalized_grads = grads / (tf.sqrt(tf.reduce_mean(tf.square(grads))) + 1e-5)\n",
    "        input_img_data.assign_add(normalized_grads * step_size)\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    #iterate = K.function([input_img], [loss_value, grads])\n",
    "\n",
    "    #if loss_value > 0:\n",
    "    img = input_img_data.numpy().astype(np.float64)\n",
    "    img = img.squeeze()\n",
    "    img = deprocess_image(img)\n",
    "    kept_filters.append((img, loss_value))\n",
    "    #return iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [layer.name for layer in model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'conv1'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = model.get_layer('conv1')\n",
    "range(min(layer.output.shape[-1], 100))\n",
    "layer_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing filter for layer: block1_conv1\n",
      "Processing filter for layer: block1_conv2\n",
      "Processing filter for layer: conv1\n",
      "Processing filter for layer: conv2\n",
      "Processing filter for layer: conv3\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "kept_filters = []\n",
    "filters_dict = dict()\n",
    "for layer_name in layers:\n",
    "    if 'conv' in layer_name:\n",
    "        layer = model.get_layer(layer_name)\n",
    "        print('Processing filter for layer:', layer_name)\n",
    "        for filter_index in range(min(layer.output.shape[-1], 100)):\n",
    "            # print('Processing filter %d' % filter_index)\n",
    "\n",
    "            start_time = time.time()\n",
    "            build_nth_filter_loss(filter_index, layer_name)\n",
    "            end_time = time.time()\n",
    "\n",
    "    #         print('--->Filter %d processed in %ds' % (filter_index, end_time - start_time))\n",
    "        filters_dict[layer.name] = kept_filters\n",
    "        kept_filters = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_index = 5\n",
    "build_nth_filter_loss(filter_index, layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_name, kept_filters in filters_dict.items():\n",
    "    print(layer_name, len(kept_filters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import save_img\n",
    "\n",
    "def stich_filters(kept_filters, layer_name):\n",
    "    # By default, we will stich the best 64 (n*n) filters on a 8 x 8 grid.\n",
    "    n = int(np.sqrt(len(kept_filters)))\n",
    "    # the filters that have the highest loss are assumed to be better-looking.\n",
    "    # we will only keep the top 64 filters.\n",
    "    kept_filters.sort(key=lambda x: x[1], reverse=True)\n",
    "    kept_filters = kept_filters[:n * n]\n",
    "\n",
    "    # build a black picture with enough space for\n",
    "    # our 8 x 8 filters of size 128 x 128, with a 5px margin in between\n",
    "    margin = 5\n",
    "    width = n * img_width + (n - 1) * margin\n",
    "    height = n * img_height + (n - 1) * margin\n",
    "    stitched_filters = np.zeros((width, height, 3))\n",
    "\n",
    "    # fill the picture with our saved filters\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            img, loss = kept_filters[i * n + j]\n",
    "            width_margin = (img_width + margin) * i\n",
    "            height_margin = (img_height + margin) * j\n",
    "            stitched_filters[\n",
    "                width_margin: width_margin + img_width,\n",
    "                height_margin: height_margin + img_height, :] = img\n",
    "\n",
    "    # save the result to disk\n",
    "    save_img('img/filters/stitched_filters_{}.png'.format(layer_name), stitched_filters)\n",
    "    \n",
    "for layer_name, kept_filters in filters_dict.items():\n",
    "    print('Stiching filters for {}'.format(layer_name))\n",
    "    stich_filters(kept_filters, layer_name)\n",
    "    print('number of filters kept:', len(kept_filters))\n",
    "    print('Completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "filter_name = 'conv3'\n",
    "\n",
    "img = image.img_to_array(image.load_img('img/stitched_filters_{}.png'.format(filter_name))) /255.\n",
    "plt.figure(figsize=(17,17))\n",
    "plt.imshow(img)\n",
    "plt.title(filter_name)\n",
    "plt.grid(False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0284a593613b942586af6b8f0d4ee916e356aed836174e2f823c929bc6bc05cc"
  },
  "kernelspec": {
   "display_name": "dis_vae",
   "language": "python",
   "name": "dis_vae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
