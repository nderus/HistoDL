{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conditional Variational autoencoder (VAE) - Toy datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Utility functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "print(tf. __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_indices(lst, condition):\n",
    "    return np.array([i for i, elem in enumerate(lst) if condition(elem)])\n",
    "    \n",
    "def plot_2d_data_categorical(data_2d, y, titles=None, figsize = (7, 7), category_count=2):\n",
    "  fig, axs = plt.subplots(category_count, len(data_2d), figsize = figsize)\n",
    "  colors = np.array(['#7FFFD4', '#458B74'])\n",
    "  for i in range(len(data_2d)):\n",
    "      for k in range(category_count):\n",
    "\n",
    "        index = find_indices(y[i], lambda e: e == k)\n",
    "\n",
    "        data_2d_k = data_2d[i][index, ]\n",
    "        y_k = y[i][index]\n",
    "\n",
    "        if (titles != None):\n",
    "          axs[k,i].set_title(\"{} - Class: {}\".format(titles[i], k))\n",
    "\n",
    "        scatter = axs[k, i].scatter(data_2d_k[:, 0], data_2d_k[:, 1],\n",
    "                                s=1, c=colors[k], cmap=plt.cm.Paired)\n",
    "        axs[k, i].legend(*scatter.legend_elements())\n",
    "        axs[k, i].set_xlim([-60, 60])\n",
    "        axs[k, i].set_ylim([-60, 60])\n",
    "        wandb.log({\"Embdedding_classes\": wandb.Image(plt)})\n",
    "\n",
    "        \n",
    "def plot_2d_data(data_2d, y, titles=None, figsize = (7, 7)):\n",
    "  _, axs = plt.subplots(1, len(data_2d), figsize = figsize)\n",
    "\n",
    "  for i in range(len(data_2d)):\n",
    "    \n",
    "    if (titles != None):\n",
    "      axs[i].set_title(titles[i])\n",
    "    scatter=axs[i].scatter(data_2d[i][:, 0], data_2d[i][:, 1],\n",
    "                            s=1, c=y[i], cmap=plt.cm.Paired)\n",
    "    axs[i].legend(*scatter.legend_elements())\n",
    "    wandb.log({\"Embdedding\": wandb.Image(plt)})\n",
    "\n",
    "def plot_history(history,metric=None):\n",
    "  fig, ax1 = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "  epoch_count=len(history.history['loss'])\n",
    "\n",
    "  line1,=ax1.plot(range(1,epoch_count+1),history.history['loss'],\n",
    "                  label='train_loss',color='orange')\n",
    "  ax1.plot(range(1,epoch_count+1),history.history['val_loss'],\n",
    "                  label='val_loss',color = line1.get_color(), linestyle = '--')\n",
    "  ax1.set_xlim([1,epoch_count])\n",
    "  ax1.set_ylim([0, max(max(history.history['loss']),\n",
    "              max(history.history['val_loss']))])\n",
    "  ax1.set_ylabel('loss',color = line1.get_color())\n",
    "  ax1.tick_params(axis='y', labelcolor=line1.get_color())\n",
    "  ax1.set_xlabel('Epochs')\n",
    "  _=ax1.legend(loc='lower left')\n",
    "\n",
    "  if (metric!=None):\n",
    "    ax2 = ax1.twinx()\n",
    "    line2,=ax2.plot(range(1,epoch_count+1),history.history[metric],\n",
    "                    label='train_'+metric)\n",
    "    ax2.plot(range(1,epoch_count+1),history.history['val_'+metric],\n",
    "                    label='val_'+metric,color = line2.get_color(),\n",
    "                    linestyle = '--')\n",
    "    ax2.set_ylim([0, max(max(history.history[metric]),\n",
    "                max(history.history['val_'+metric]))])\n",
    "    ax2.set_ylabel(metric,color=line2.get_color())\n",
    "    ax2.tick_params(axis='y', labelcolor=line2.get_color())\n",
    "    _=ax2.legend(loc='upper right')\n",
    "\n",
    "def plot_generated_images(generated_images, nrows, ncols, digit_label,\n",
    "                          no_space_between_plots=False, figsize=(10, 10)):\n",
    "  _, axs = plt.subplots(nrows, ncols,figsize=figsize,squeeze=False)\n",
    "\n",
    "  for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "      axs[i,j].axis('off')\n",
    "      axs[i,j].imshow(generated_images[i][j], cmap='gray')\n",
    "\n",
    "  if no_space_between_plots:\n",
    "    plt.subplots_adjust(wspace=0,hspace=0)\n",
    "  \n",
    "  wandb.log({\"Latent_interpolation_class: {}\".format(digit_label): wandb.Image(plt)})\n",
    "\n",
    "  plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_input(self, inputs, label_size=10):\n",
    "    image_size = [self.shape[0], self.shape[1], self.shape[2]]\n",
    "    input_img = layers.InputLayer(input_shape=image_size,\n",
    "                                dtype ='float32')(inputs[0])\n",
    "    input_label = layers.InputLayer(input_shape=(label_size, ),\n",
    "                                    dtype ='float32')(inputs[1])\n",
    "    labels = tf.reshape(inputs[1], [-1, 1, 1, label_size])\n",
    "    labels = tf.cast(labels, dtype='float32')\n",
    "    ones = tf.ones([inputs[0].shape[0]] + image_size[0:-1] + [label_size])\n",
    "    labels = ones * labels\n",
    "    conditional_input = layers.Concatenate(axis=3)([input_img, labels]) \n",
    "    return  input_img, input_label, conditional_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(z_mean, z_log_var, input_label):\n",
    "\n",
    "    eps = tf.random.normal(tf.shape(z_log_var), dtype=tf.float32,\n",
    "                            mean=0., stddev=1.0, name='epsilon')\n",
    "    z = z_mean + tf.exp(z_log_var / 2) * eps\n",
    "    z_cond = tf.concat([z, input_label], axis=1) \n",
    "    return z_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Val_Plot(loss, val_loss, reconstruction_loss, val_reconstruction_loss, kl_loss, val_kl_loss):\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1,4, figsize= (16,4))\n",
    "    fig.suptitle(\" MODEL'S METRICS VISUALIZATION \")\n",
    "\n",
    "    ax1.plot(range(1, len(loss) + 1), loss)\n",
    "    ax1.plot(range(1, len(val_loss) + 1), val_loss)\n",
    "    ax1.set_title('History of Loss')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend(['training', 'validation'])\n",
    "\n",
    "    ax2.plot(range(1, len(reconstruction_loss) + 1), reconstruction_loss)\n",
    "    ax2.plot(range(1, len(val_reconstruction_loss) + 1), val_reconstruction_loss)\n",
    "    ax2.set_title('History of reconstruction_loss')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('reconstruction_loss')\n",
    "    ax2.legend(['training', 'validation'])\n",
    "    \n",
    "    ax3.plot(range(1, len(kl_loss) + 1), kl_loss)\n",
    "    ax3.plot(range(1, len(val_kl_loss) + 1), val_kl_loss)\n",
    "    ax3.set_title(' History of kl_loss')\n",
    "    ax3.set_xlabel(' Epochs ')\n",
    "    ax3.set_ylabel('kl_loss')\n",
    "    ax3.legend(['training', 'validation'])\n",
    "    wandb.log({\"Training\": wandb.Image(plt)})\n",
    "    plt.show()\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data import and manipulation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"Histo\"\n",
    "# import data\n",
    "imagePatches = glob('datasets/breast-histopathology/IDC_regular_ps50_idx5/**/*.png', recursive=True)\n",
    "for filename in imagePatches[0:10]:\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class0 = [] # 0 = no cancer\n",
    "class1 = [] # 1 = cancer\n",
    "\n",
    "for filename in imagePatches:\n",
    "    if filename.endswith(\"class0.png\"):\n",
    "         class0.append(filename)\n",
    "    else:\n",
    "        class1.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_class0 = random.sample(class0, 50000)\n",
    "sampled_class1 = random.sample(class1, 50000)\n",
    "len(sampled_class0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imread\n",
    "import cv2\n",
    "\n",
    "def get_image_arrays(data, label):\n",
    "    img_arrays = []\n",
    "    for i in data:\n",
    "        if i.endswith('.png'):\n",
    "            img = cv2.imread(i ,cv2.IMREAD_COLOR)\n",
    "            img_sized = cv2.resize(img, (50, 50), #was (70,70)\n",
    "                        interpolation=cv2.INTER_LINEAR)\n",
    "            img_arrays.append([img_sized, label]) \n",
    "    return img_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class0_array = get_image_arrays(sampled_class0, 0)\n",
    "class1_array = get_image_arrays(sampled_class1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = np.concatenate((class0_array, class1_array))\n",
    "random.seed(41)\n",
    "random.shuffle(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features, label in combined_data:\n",
    "    X.append(features)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(-1, 50, 50, 3)\n",
    "y = np.array(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.2,\n",
    "                                    random_state = 11)\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, \n",
    "                            test_size = 0.25, random_state = 11) \n",
    "                            # 0.25 x 0.8 = 0.2\n",
    "train_y_one_hot = to_categorical(train_y)\n",
    "test_y_one_hot = to_categorical(test_y)\n",
    "val_y_one_hot = to_categorical(val_y)\n",
    "train_y = np.argmax(train_y_one_hot, axis=1) # from one-hot encoding to integer\n",
    "test_y = np.argmax(test_y_one_hot, axis=1)\n",
    "val_y = np.argmax(val_y_one_hot, axis=1)\n",
    "labels = ['non-cancer','cancer']\n",
    "category_count = 2\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min value: ', train_x.min())\n",
    "print('Max value: ', train_x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = 10\n",
    "\n",
    "_, axs = plt.subplots(1, image_count, figsize=(20, 20))\n",
    "for i in range(image_count):\n",
    "  random_idx=random.randint(0, train_x.shape[0])\n",
    "  axs[i].imshow(train_x[random_idx], cmap='gray')\n",
    "  axs[i].axis('off')\n",
    "  axs[i].set_title(labels[train_y[random_idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(train_x.shape) == 3:\n",
    "    train_x=np.expand_dims(train_x,axis=3)\n",
    "    val_x=np.expand_dims(val_x,axis=3)\n",
    "    test_x=np.expand_dims(test_x,axis=3)\n",
    "    print('Train shape: ',train_x.shape)\n",
    "    print('Validation shape: ',val_x.shape)\n",
    "    print('Test shape: ',test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_x.shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x/255.0\n",
    "val_x = val_x/255.0\n",
    "test_x = test_x/255.0\n",
    "\n",
    "print('Min value: ',train_x.min())\n",
    "print('Max value: ', train_x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image_shape=(train_x.shape[1], train_x.shape[2])\n",
    "\n",
    "train_x_flatten=np.reshape(train_x,(train_x.shape[0],-1))\n",
    "val_x_flatten=np.reshape(val_x,(val_x.shape[0],-1))\n",
    "test_x_flatten=np.reshape(test_x,(test_x.shape[0],-1))\n",
    "\n",
    "print('Train data flatten shape: ',train_x_flatten.shape)\n",
    "print('Validation data flatten shape: ',val_x_flatten.shape)\n",
    "print('Test data flatten shape: ',test_x_flatten.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CVAE model**\n",
    "Creating a CVAE class and plugging encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_relu(inputs):\n",
    "    bn = layers.BatchNormalization()(inputs)\n",
    "    relu = layers.ReLU()(bn)\n",
    "    return(relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderResBlock(keras.Model):\n",
    "    def __init__(self, filters, downsample):\n",
    "        super().__init__()\n",
    "        if downsample:\n",
    "            self.conv1 = layers.Conv2D(filters, 3, 2, padding='same')\n",
    "            self.shortcut = keras.Sequential([\n",
    "                layers.Conv2D(filters, 1, 2),\n",
    "                layers.BatchNormalization()\n",
    "            ])\n",
    "        else:\n",
    "            self.conv1 = layers.Conv2D(filters, 3, 1, padding='same')\n",
    "            self.shortcut = keras.Sequential()\n",
    " \n",
    "        self.conv2 = layers.Conv2D(filters, 3, 1, padding='same')\n",
    "        \n",
    "    def __call__(self, input):\n",
    "        \n",
    "        shortcut = self.shortcut(input)\n",
    "\n",
    "        input = self.conv1(input)\n",
    "        input = layers.BatchNormalization()(input)\n",
    "        input = layers.ReLU()(input)\n",
    "        input = layers.BatchNormalization()(input)\n",
    "        input = layers.ReLU()(input)\n",
    "\n",
    "        input= input + shortcut\n",
    "        return layers.ReLU()(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderResNet(keras.Model):\n",
    "    def __init__(self, resblock, repeat, encoded_dim):\n",
    "   \n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer0 = keras.Sequential([\n",
    "            layers.Conv2D(64, 7, 2, padding='same'),\n",
    "            layers.MaxPool2D(pool_size=3, strides=2, padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU()\n",
    "        ], name='layer0')\n",
    "\n",
    "        self.layer1 = keras.Sequential([\n",
    "            resblock(64, downsample=False) for _ in range(repeat[0])\n",
    "        ], name='layer1')\n",
    "\n",
    "        self.layer2 = keras.Sequential([\n",
    "            resblock(128, downsample=True)\n",
    "        ] + [\n",
    "            resblock(128, downsample=False) for _ in range(1, repeat[1])\n",
    "        ], name='layer2')\n",
    "\n",
    "        self.layer3 = keras.Sequential([\n",
    "            resblock(256, downsample=True)\n",
    "        ] + [\n",
    "            resblock(256, downsample=False) for _ in range(1, repeat[2])\n",
    "        ], name='layer3')\n",
    "\n",
    "        self.layer4 = keras.Sequential([\n",
    "            resblock(512, downsample=True)\n",
    "        ] + [\n",
    "            resblock(512, downsample=False) for _ in range(1, repeat[3])\n",
    "        ], name='layer4')\n",
    "\n",
    "        self.flat = layers.Flatten(name = 'flatten')\n",
    "        self.bottleneck = layers.Dense(encoded_dim * 2, name='encoder_bottleneck')\n",
    "        self.mu = layers.Dense(encoded_dim, name='mu')\n",
    "        self.log_var = layers.Dense(encoded_dim, name='log_var')\n",
    " \n",
    "\n",
    "    def call(self, input):\n",
    "        input = self.layer0(input)\n",
    "        input = self.layer1(input)\n",
    "        input = self.layer2(input)\n",
    "        input = self.layer3(input)\n",
    "        input = self.layer4(input)\n",
    "        input = self.flat(input)\n",
    "        input = self.bottleneck(input)\n",
    "        mu = self.mu(input)\n",
    "        log_var = self.log_var(input)\n",
    "\n",
    "        return [mu, log_var]\n",
    "\n",
    "    def get_config(self):\n",
    "        return super().get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderResNet18(EncoderResNet):\n",
    "    def __init__(self, encoded_dim):\n",
    "        super().__init__(EncoderResBlock, [2, 2, 2, 2], encoded_dim)\n",
    "\n",
    "    def call(self, input):\n",
    "        return super().call(input)\n",
    "\n",
    "    def model(self, input_shape):\n",
    "        x = layers.Input(input_shape, name='input', dtype='float32')\n",
    "        return keras.models.Model(x, self.call(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder, ok.\n",
    "resnet18 = EncoderResNet18(encoded_dim = encoded_dim)\n",
    "resnet18 = resnet18.model(input_shape=(50, 50, 5))\n",
    "resnet18.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderResBlock(keras.Model):\n",
    "    def __init__(self, filters, upsample):\n",
    "        super().__init__()\n",
    "        if upsample:\n",
    "            self.conv1 = layers.Conv2DTranspose(filters, 3, 2, padding='same')\n",
    "            self.shortcut = keras.Sequential([\n",
    "                layers.Conv2DTranspose(filters, 1, 2),\n",
    "                layers.BatchNormalization()\n",
    "            ])\n",
    "        else:\n",
    "            self.conv1 = layers.Conv2DTranspose(filters, 3, 1, padding='same')\n",
    "            self.shortcut = keras.Sequential()\n",
    " \n",
    "        self.conv2 = layers.Conv2DTranspose(filters, 3, 1, padding='same')\n",
    "\n",
    "    def __call__(self, input):\n",
    "        shortcut = self.shortcut(input)\n",
    "\n",
    "        input = self.conv1(input)\n",
    "        input = layers.BatchNormalization()(input)\n",
    "        input = layers.ReLU()(input)\n",
    "\n",
    "        input = self.conv2(input)\n",
    "        input = layers.BatchNormalization()(input)\n",
    "        input = layers.ReLU()(input)\n",
    "\n",
    "        input = input + shortcut\n",
    "        return layers.ReLU()(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderResNet(keras.Model):\n",
    "    def __init__(self, resblock, repeat, encoded_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer5 = keras.Sequential([\n",
    "            resblock(512, upsample=False)\n",
    "        ] + [\n",
    "            resblock(512, upsample=False)  for _ in range(1, repeat[0])\n",
    "        ], name='layer5')\n",
    "\n",
    "\n",
    "        self.layer6 = keras.Sequential([\n",
    "            resblock(256, upsample=True)\n",
    "        ] + [\n",
    "            resblock(256, upsample=False) for _ in range(1, repeat[1])\n",
    "        ], name='layer6')\n",
    "\n",
    "\n",
    "        self.layer7 = keras.Sequential([\n",
    "            resblock(128, upsample=True)\n",
    "        ] + [\n",
    "            resblock(128, upsample=False) for _ in range(1, repeat[2])\n",
    "        ], name='layer7')\n",
    "        \n",
    "        # self.layer7 = keras.Sequential([ # TO DO: change back this into resblock, heigth/depth issue\n",
    "        #     layers.Conv2DTranspose(128, 4, 1, padding='valid'),\n",
    "        #     #layers.BatchNormalization(),\n",
    "        #     layers.ReLU()\n",
    "        # ], name='layer7')\n",
    "\n",
    "        self.layer8 =  keras.Sequential([ \n",
    "            resblock(64, upsample=True)\n",
    "        ] + [\n",
    "            resblock(64, upsample=False) for _ in range(repeat[3])\n",
    "        ], name='layer8')\n",
    "\n",
    "        self.layer9 = keras.Sequential([\n",
    "                layers.Conv2DTranspose(64, 7, 1, padding='same'),\n",
    "                layers.UpSampling2D(3),\n",
    "                #layers.MaxPool2D(pool_size=3, strides=2, padding='same'),\n",
    "                layers.BatchNormalization(),\n",
    "                layers.ReLU()\n",
    "            ], name='layer9')\n",
    "          \n",
    "        self.bottleneck = layers.Dense(encoded_dim * 2, name='bottleneck')\n",
    "        self.pre_reshape = layers.Dense(2*2*512, name='pre_reshape')\n",
    "        self.reshape = layers.Reshape(target_shape=(2, 2, 512), name = 'reshape')\n",
    "        self.output_layer = layers.Conv2DTranspose(filters = 3, kernel_size=3, strides=1, activation='sigmoid' ,padding='valid', name='outputs')\n",
    "    \n",
    "    def call(self, input):\n",
    "        input = self.bottleneck(input)\n",
    "        input = self.pre_reshape(input)\n",
    "        input = self.reshape(input)\n",
    "        input = self.layer5(input)\n",
    "        input = self.layer6(input)\n",
    "        input = self.layer7(input)\n",
    "        input = self.layer8(input)\n",
    "        input = self.layer9(input)\n",
    "        out = self.output_layer(input)\n",
    "        return out\n",
    "\n",
    "    def get_config(self):\n",
    "        return super().get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderResNet18(DecoderResNet):\n",
    "    def __init__(self, encoded_dim):\n",
    "        super().__init__(DecoderResBlock, [2, 2, 2, 1], encoded_dim)\n",
    "\n",
    "    def call(self, input):\n",
    "        return super().call(input)\n",
    "\n",
    "    def model(self, input_shape):\n",
    "        x = keras.Input(input_shape, name='input')\n",
    "        return keras.models.Model(x, self.call(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder, ok?\n",
    "decoder = DecoderResNet18( encoded_dim = encoded_dim)\n",
    "decoder = decoder.model(input_shape=(encoded_dim + category_count,))\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae_encoder = resnet18\n",
    "cvae_decoder = decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.random.normal((10, 50, 50, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "visualkeras.layered_view(cvae_encoder, legend=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualkeras.layered_view(cvae_decoder, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, beta, shape, **kwargs):\n",
    "        super(CVAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.beta = beta\n",
    "        self.shape = shape\n",
    "        self.latent_var = []\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        self.total_loss_no_weights_tracker = keras.metrics.Mean(name=\"loss_no_weights\")\n",
    "        #\n",
    "        self.val_total_loss_tracker = keras.metrics.Mean(name=\"val_loss\")\n",
    "        self.val_reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"val_reconstruction_loss\")\n",
    "        self.val_kl_loss_tracker = keras.metrics.Mean(name=\"val_kl_loss\")\n",
    "        self.val_total_loss_no_weights_tracker = keras.metrics.Mean(name=\"val_loss_no_weights\")\n",
    "        self.latent_var_tracker = keras.metrics.Mean(name=\"latent_var\") #added\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            self.val_total_loss_tracker,\n",
    "            self.val_reconstruction_loss_tracker,\n",
    "            self.val_kl_loss_tracker,\n",
    "            self.total_loss_no_weights_tracker,\n",
    "            self.val_total_loss_no_weights_tracker,\n",
    "            self.latent_var_tracker,\n",
    "\n",
    "        ]\n",
    "       \n",
    "    def call(self, inputs):\n",
    "        _, input_label, conditional_input = self.conditional_input(inputs)\n",
    "        z_mean, z_log_var = self.encoder(conditional_input)\n",
    "        z_cond = self.sampling(z_mean, z_log_var, input_label)\n",
    "        return self.decoder(z_cond)\n",
    "\n",
    "  \n",
    "    def conditional_input(self, inputs, label_size=2):\n",
    "        image_size = [self.shape[0], self.shape[1], self.shape[2]]\n",
    "        input_img = layers.InputLayer(input_shape=image_size,\n",
    "                                    dtype ='float32')(inputs[0])\n",
    "        input_label = layers.InputLayer(input_shape=(label_size, ),\n",
    "                                        dtype ='float32')(inputs[1])\n",
    "        labels = tf.reshape(inputs[1], [-1, 1, 1, label_size])\n",
    "        labels = tf.cast(labels, dtype='float32')\n",
    "        ones = tf.ones([inputs[0].shape[0]] + image_size[0:-1] + [label_size])\n",
    "        labels = ones * labels\n",
    "\n",
    "        conditional_input = layers.Concatenate(axis=3)([input_img, labels]) \n",
    "        return  input_img, input_label, conditional_input\n",
    "\n",
    "    def sampling(self, z_mean, z_log_var, input_label):\n",
    "        if len(input_label.shape) == 1:\n",
    "            input_label = np.expand_dims(input_label, axis=0)\n",
    "\n",
    "        eps = tf.random.normal(tf.shape(z_log_var), dtype=tf.float32,\n",
    "                               mean=0., stddev=1.0, name='epsilon')\n",
    "        z = z_mean + tf.exp(z_log_var / 2) * eps\n",
    "        z_cond = tf.concat([z, input_label], axis=1)\n",
    "        return z_cond\n",
    "\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            input_img, input_label, conditional_input = self.conditional_input(data)\n",
    "            z_mean, z_log_var = self.encoder(conditional_input)\n",
    "            z_cond = self.sampling(z_mean, z_log_var, input_label)\n",
    "            reconstruction = self.decoder(z_cond)\n",
    "\n",
    "            #reconstruction_loss = np.prod(self.shape) * tf.keras.losses.MSE(tf.keras.backend.flatten(input_img),\n",
    "            #                        tf.keras.backend.flatten(reconstruction))\n",
    "            reconstruction_loss = tf.reduce_sum(\n",
    "                 keras.losses.MSE(input_img, # removed np.prod(self.shape) *\n",
    "                                    reconstruction), axis=(1, 2))            \n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean)\n",
    "                      - tf.exp(z_log_var))\n",
    "\n",
    "            kl_loss = tf.reduce_sum(kl_loss, axis=1) #sum over encoded dimensiosn, average over batch\n",
    "            total_loss_no_weights = reconstruction_loss + kl_loss\n",
    "            total_loss_no_weights = tf.reduce_mean(total_loss_no_weights)\n",
    "            kl_loss = self.beta * kl_loss\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "            total_loss = tf.reduce_mean(total_loss) \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        self.total_loss_no_weights_tracker.update_state(total_loss_no_weights)\n",
    "        self.latent_var_tracker.update_state(z_log_var)\n",
    "        #wandb.log({\"loss\": total_loss, \"reconstructon_loss\": reconstruction_loss, \"kl_loss\": kl_loss,})\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "            \"loss_no_weights\": self.total_loss_no_weights_tracker.result(),\n",
    "            \"latent_var\": self.latent_var_tracker.result()\n",
    "        }\n",
    "\n",
    "\n",
    "    def test_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        \n",
    "        input_img, input_label, conditional_input = self.conditional_input(data)\n",
    "        z_mean, z_log_var = self.encoder(conditional_input)\n",
    "        z_cond = self.sampling(z_mean, z_log_var, input_label)\n",
    "        reconstruction = self.decoder(z_cond)\n",
    "        reconstruction_loss = tf.reduce_sum(\n",
    "                 keras.losses.MSE(input_img,\n",
    "                                    reconstruction), axis=(1, 2))   \n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean)\n",
    "                  - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_sum(kl_loss, axis=1)\n",
    "        total_loss_no_weights = reconstruction_loss + kl_loss\n",
    "        total_loss_no_weights = tf.reduce_mean(total_loss_no_weights)\n",
    "        kl_loss = self.beta * kl_loss\n",
    "        total_loss =  reconstruction_loss + kl_loss\n",
    "        total_loss = tf.reduce_mean(total_loss)\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        self.total_loss_no_weights_tracker.update_state(total_loss_no_weights)\n",
    "        return{\n",
    "            'loss': self.total_loss_tracker.result(),\n",
    "            'reconstruction_loss': self.reconstruction_loss_tracker.result(),\n",
    "            'kl_loss': self.kl_loss_tracker.result(),\n",
    "            \"loss_no_weights\": self.total_loss_no_weights_tracker.result()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kl_coefficient = encoded_dim / (input_shape[0] * input_shape[1] * input_shape[2])\n",
    "kl_coefficient = .65\n",
    "print('kl coefficient: {:.3f}'.format(kl_coefficient))\n",
    "# from b vae paper, use beta = encoded_dimension / pixel_dimension i.e. -> 0.068\n",
    "cvae = CVAE(cvae_encoder, cvae_decoder, kl_coefficient, input_shape)\n",
    "cvae.built = True\n",
    "cvae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_input(self, inputs, label_size=10): \n",
    "    print('ones_dim', inputs[0].shape[0])\n",
    "    image_size = [self.shape[0], self.shape[1], self.shape[2]]\n",
    "\n",
    "    input_img = layers.InputLayer(input_shape=image_size,\n",
    "                                    dtype ='float32')(inputs[0])\n",
    "    input_label = layers.InputLayer(input_shape=(label_size, ),\n",
    "                                    dtype ='float32')(inputs[1])\n",
    "    print('image_size:', image_size)\n",
    "\n",
    "    labels = tf.reshape(inputs[1], [-1, 1, 1, label_size])\n",
    "    labels = tf.cast(labels, dtype='float32')\n",
    "    print('labels dim:', labels.shape)\n",
    "\n",
    "    ones = tf.ones([batch_size] + image_size[0:-1] + [label_size]) \n",
    "    labels = ones * labels\n",
    "    print('labels dim:', labels.shape)\n",
    "    conditional_input = layers.Concatenate(axis=3)([input_img, labels]) \n",
    "    return  input_img, input_label, conditional_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae_input = cvae.encoder.input[0]\n",
    "cvae_output = cvae.decoder.output\n",
    "mu = cvae.encoder.get_layer('mu').output\n",
    "log_var = cvae.encoder.get_layer('log_var').output\n",
    "\n",
    "learning_rate = 0.0001 \n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "cvae.compile(optimizer = opt, run_eagerly=False)\n",
    "#cvae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_count = 100\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "#wandb.init(project=\"my-test-project\", entity=\"nrderus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patience = 5\n",
    "\n",
    "\n",
    "wandb.init(project=\"HistoDL\", entity=\"nrderus\",\n",
    "  config = {\n",
    "  \"dataset\": dataset_name,\n",
    "  \"model\": \"CVAE_resnet\",\n",
    "  \"encoded_dim\": encoded_dim,\n",
    "  \"kl_coefficient\": kl_coefficient,\n",
    "  \"learning_rate\": learning_rate,\n",
    "  \"epochs\": epoch_count,\n",
    "  \"batch_size\": batch_size,\n",
    "  \"patience\": patience,\n",
    "  \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "             patience=patience, restore_best_weights=False)\n",
    "\n",
    "history = cvae.fit([train_x,train_y_one_hot],\n",
    "                   validation_data=([val_x,val_y_one_hot],None),\n",
    "                   epochs=epoch_count,\n",
    "                   batch_size=100,\n",
    "                   callbacks=[early_stop, WandbCallback(save_weights_only=True) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K.get_value(cvae.latent_var[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.numpy_function(cvae.latent_var[0], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_Val_Plot(history.history['loss'][1:],\n",
    "#                history.history['val_loss'][1:],\n",
    "#                history.history['reconstruction_loss'][1:],\n",
    "               \n",
    "#                history.history['val_reconstruction_loss'][1:],\n",
    "#                history.history['kl_loss'][1:],\n",
    "#                history.history['val_kl_loss'][1:]\n",
    "#                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae.save_weights('weights/cvae_toy.h5')\n",
    "cvae_encoder.save('models/cvae_encoder_toy.h5')\n",
    "cvae_decoder.save('models/cvae_decoder_toy.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward the port 6006 on server on 12006 on  my machine\n",
    "# ssh -N -L 16006:127.0.0.1:6006 nicolas.derus2@137.204.48.211\n",
    "# access with http://127.0.0.1:16006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Embdedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_size = 10\n",
    "_, input_label_train, train_input = cvae.conditional_input([train_x, train_y_one_hot])\n",
    "_, input_label_test, test_input = cvae.conditional_input([test_x, test_y_one_hot])\n",
    "_, input_label_val, val_input = cvae.conditional_input([val_x, val_y_one_hot])\n",
    "\n",
    "\n",
    "print(input_label_train.shape)\n",
    "print(train_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_mean, train_log_var = cvae.encoder.predict(train_input)\n",
    "test_x_mean, test_log_var = cvae.encoder.predict(test_input)\n",
    "val_x_mean, val_log_var = cvae.encoder.predict(val_input)\n",
    "\n",
    "print(train_x_mean.shape)\n",
    "print(train_log_var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if encoded_dim > 2:\n",
    "    from sklearn import manifold\n",
    "    tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "    train_x_tsne = tsne.fit_transform(train_x_mean[:2000])\n",
    "    test_x_tsne = tsne.fit_transform(test_x_mean[:2000])\n",
    "    val_x_tsne = tsne.fit_transform(val_x_mean[:2000])\n",
    "    plot_2d_data( [train_x_tsne, test_x_tsne, val_x_tsne],\n",
    "            [train_y[:2000], test_y[:2000] ,val_y[:2000]],\n",
    "            ['Train','Test', 'Validation'],(18,6))\n",
    "    plot_2d_data_categorical( [train_x_tsne, test_x_tsne, val_x_tsne],\n",
    "            [train_y[:2000], test_y[:2000] ,val_y[:2000]],\n",
    "            ['Train','Test', 'Validation'],(18,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if encoded_dim == 2:\n",
    "    plot_2d_data( [train_x_mean, test_x_mean, val_x_mean],\n",
    "                [train_y, test_y ,val_y],\n",
    "                ['Train','Test', 'Validation'],(18,6))\n",
    "    plot_2d_data_categorical( [train_x_mean, test_x_mean, val_x_mean],\n",
    "                [train_y, test_y ,val_y],\n",
    "                ['Train','Test', 'Validation'],(12,36))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reconstruction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstructions...\n",
    "z_cond_train = sampling(train_x_mean, train_log_var, input_label_train)\n",
    "z_cond_test = sampling(test_x_mean, test_log_var, input_label_test)\n",
    "z_cond_val = sampling(val_x_mean, val_log_var, input_label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_train = cvae.decoder(z_cond_train[:100])\n",
    "reconstruction_test = cvae.decoder(z_cond_test[:100])\n",
    "reconstruction_val = cvae.decoder(z_cond_val[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = random.randint(0, reconstruction_train.shape[0])\n",
    "random_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = 10\n",
    "\n",
    "fig, axs = plt.subplots(2, image_count, figsize=(12, 3))\n",
    "for i in range(image_count):\n",
    "  random_idx = random.randint(0, reconstruction_train.shape[0]-1)\n",
    "  axs[0, i].imshow(train_x[random_idx])\n",
    "  axs[0, i].axis('off')\n",
    "  #axs[0, i].set_title(train_y[random_idx])\n",
    "  axs[0, i].set_title( labels[int(train_y[random_idx])]  )\n",
    "  axs[1, i].imshow(reconstruction_train[random_idx])\n",
    "  axs[1, i].axis('off')\n",
    "wandb.log({\"Reconstructions\": wandb.Image(plt)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cvae.latent_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparametrization(z_mean, z_log_var, input_label):\n",
    "    \"\"\" Performs the riparametrization trick\"\"\"\n",
    "\n",
    "    eps = tf.random.normal(shape = (input_label.shape[0], encoded_dim),\n",
    "                             mean = 0.0, stddev = 1.0)       \n",
    "    z = z_mean + tf.math.exp(z_log_var * .5) * eps\n",
    "    z_cond = tf.concat([z, input_label], axis=1) # (batch_size, label_dim + latent_dim)\n",
    "\n",
    "    return z_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_label = 0\n",
    "digit_label_one_hot = to_categorical(digit_label, category_count).reshape(1,-1)\n",
    "a = tf.convert_to_tensor(digit_label_one_hot)\n",
    "b = tf.concat([a, a], axis=0) # with 1 dimension, it fails...\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_cond = reparametrization(z_mean=0, z_log_var=0.2, input_label = b)\n",
    "decoded_x = cvae_decoder.predict(z_cond)\n",
    "digit = decoded_x[0].reshape(input_shape) \n",
    "plt.axis('off')\n",
    "plt.imshow(digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_label = 0\n",
    "_, axs = plt.subplots(2, image_count, figsize=(12, 3))\n",
    "for i in range(image_count):\n",
    "    digit_label_one_hot = to_categorical(digit_label, category_count).reshape(1,-1)\n",
    "    a = tf.convert_to_tensor(digit_label_one_hot)\n",
    "    b = tf.concat([a, a], axis=0) # with 1 dimension, it fails...\n",
    "    z_cond = reparametrization(z_mean=0, z_log_var=0.3, input_label = b)\n",
    "    decoded_x = cvae_decoder.predict(z_cond)\n",
    "    digit_0 = decoded_x[0].reshape(input_shape) \n",
    "    digit_1 = decoded_x[1].reshape(input_shape) \n",
    "    axs[0, i].imshow(digit_0)\n",
    "    axs[0, i].axis('off')\n",
    "    #axs[0, i].set_title(digit_label)\n",
    "    axs[0, i].set_title( labels[digit_label]  )\n",
    "    axs[1, i].imshow(digit_1)\n",
    "    axs[1, i].axis('off')\n",
    "    axs[1, i].set_title( labels[digit_label]  )\n",
    "wandb.log({\"Generations\": wandb.Image(plt)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generations_class(digit_label=1):\n",
    "    _, axs = plt.subplots(2, image_count, figsize=(12, 3))\n",
    "    for i in range(image_count):\n",
    "        digit_label_one_hot = to_categorical(digit_label, category_count).reshape(1,-1)\n",
    "        a = tf.convert_to_tensor(digit_label_one_hot)\n",
    "        b = tf.concat([a, a], axis=0) # with 1 dimension, it fails...\n",
    "        z_cond = reparametrization(z_mean=0, z_log_var=0.3, input_label = b)\n",
    "        decoded_x = cvae_decoder.predict(z_cond)\n",
    "        digit_0 = decoded_x[0].reshape(input_shape) \n",
    "        digit_1 = decoded_x[1].reshape(input_shape) \n",
    "        axs[0, i].imshow(digit_0)\n",
    "        axs[0, i].axis('off')\n",
    "        #axs[0, i].set_title(digit_label)\n",
    "        axs[0, i].set_title( labels[digit_label]  )\n",
    "        axs[1, i].imshow(digit_1)\n",
    "        axs[1, i].axis('off')\n",
    "        axs[1, i].set_title( labels[digit_label]  )\n",
    "        wandb.log({\"Generations: {}\".format(digit_label): wandb.Image(plt)})\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_size = category_count\n",
    "if (label_size <= 10):\n",
    "    for i in range(label_size):\n",
    "        generations_class(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_space_interpolation(digit_label=1):\n",
    "  n = 10 # number of images per row and column\n",
    "  limit=3 # random values are sampled from the range [-limit,+limit]\n",
    "  digit_label_one_hot = to_categorical(digit_label, category_count).reshape(1,-1)\n",
    "  a = tf.convert_to_tensor(digit_label_one_hot)\n",
    "  grid_x = np.linspace(-limit,limit, n) \n",
    "  grid_y = np.linspace(limit,-limit, n)\n",
    "\n",
    "  generated_images=[]\n",
    "  for i, yi in enumerate(grid_y):\n",
    "    single_row_generated_images=[]\n",
    "    for j, xi in enumerate(grid_x):\n",
    "      random_sample = np.array([[xi, yi]])\n",
    "      digit_label_one_hot = to_categorical(digit_label, category_count).reshape(1,-1)\n",
    "      a = tf.convert_to_tensor(digit_label_one_hot)\n",
    "      b = tf.concat([a, a], axis=0) # with 1 dimension, it fails...\n",
    "      z_cond = reparametrization(z_mean=random_sample, z_log_var=0.0, input_label = b)\n",
    "      decoded_x = cvae.decoder.predict(z_cond)\n",
    "      single_row_generated_images.append(decoded_x[0].reshape(original_image_shape))\n",
    "    generated_images.append(single_row_generated_images)      \n",
    "  plot_generated_images(generated_images,n,n,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_size = category_count\n",
    "if (encoded_dim == 2 & label_size <= 10):\n",
    "    for i in range(label_size):\n",
    "        latent_space_interpolation(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cvae.built = True\n",
    "#cvae.load_weights('weights/vae_toy.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish(exit_code=0, quiet = True) # TEMPORARY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualize activation functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_activations(model):\n",
    "    test = test_x[1]\n",
    "    plt.imshow(test)\n",
    "    #test = image.img_to_array(test)\n",
    "    test = np.expand_dims(test, axis=0)\n",
    "    test.shape\n",
    "    test_label = test_y_one_hot[0]\n",
    "    img_tensor = [test, test_label]\n",
    "    from keras import models\n",
    "\n",
    "    # Extracts the outputs of the top 8 layers:\n",
    "    import tensorflow as tf\n",
    "\n",
    "    layer_outputs = []\n",
    "    layer_names = []\n",
    "    for layer in model.layers[1:]:\n",
    "        \n",
    "        try: \n",
    "            layer_outputs.append(layer.get_output_at(1))\n",
    "            layer_names.append(layer.name)\n",
    "        \n",
    "        except:\n",
    "            layer_outputs.append(layer.output)\n",
    "            layer_names.append(layer.name)\n",
    "\n",
    "    # Creates a model that will return these outputs, given the model input:\n",
    "    activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "    \n",
    "    # This will return a list of 5 Numpy arrays:\n",
    "    # one array per layer activation\n",
    "    if 'encoder' in model.name:\n",
    "        input_img, input_label, conditional_input = cvae.conditional_input(img_tensor)\n",
    "        activations = activation_model.predict(conditional_input) #for encoder\n",
    "\n",
    "    if 'decoder' in model.name:\n",
    "        input_img, input_label, conditional_input = cvae.conditional_input(img_tensor)\n",
    "        input_label = np.expand_dims(input_label, axis=0)\n",
    "        z_mean, z_log_var = cvae.encoder(conditional_input)\n",
    "        z_cond = cvae.sampling(z_mean, z_log_var, input_label)\n",
    "        \n",
    "        activations = activation_model.predict(z_cond) #for decoder\n",
    "    \n",
    "    for activation, name in zip(activations[0:], layer_names[0:]):\n",
    "        print(name)\n",
    "        print(activation.shape)\n",
    "    \n",
    "    for counter, (activation, name) in enumerate(zip(activations[0:], layer_names[0:])):\n",
    "        print(name)\n",
    "        plot_filters(activation, name, counter, model_name=model.name)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_x[1]\n",
    "plt.imshow(test)\n",
    "#test = image.img_to_array(test)\n",
    "test = np.expand_dims(test, axis=0)\n",
    "test.shape\n",
    "test_label = test_y_one_hot[0]\n",
    "img_tensor = [test, test_label]\n",
    "input_img, input_label, conditional_input = cvae.conditional_input(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img.shape)\n",
    "print(input_label.shape)\n",
    "print(conditional_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [input_img, input_label]\n",
    "image_size = [28, 28, 1]\n",
    "input_img = layers.InputLayer(input_shape=image_size,\n",
    "                            dtype ='float32')(inputs[0])\n",
    "input_label = layers.InputLayer(input_shape=(label_size, ),\n",
    "                                dtype ='float32')(inputs[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tf.reshape(inputs[1], [-1, 1, 1, label_size])\n",
    "print(labels)\n",
    "labels = tf.cast(labels, dtype='float32')\n",
    "print(labels)\n",
    "ones = tf.ones([inputs[0].shape[0]] + image_size[0:-1] + [label_size])\n",
    "print(ones.shape)\n",
    "labels = ones * labels \n",
    "print(labels)\n",
    "conditional_input = layers.Concatenate(axis=3)([input_img, labels]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def plot_filters(activation_layer, layer_name, counter, model_name):\n",
    "    if len(activation_layer.shape) == 2: # if flat layer\n",
    "        print('flat')\n",
    "        return None\n",
    "        if activation_layer.shape[1] == 1875:\n",
    "            activation_layer = activation_layer.reshape(1, 25, 25, 3)\n",
    "        if activation_layer.shape[1] == 1024:\n",
    "           activation_layer = activation_layer.reshape(1, 16, 16, 4)\n",
    "        if activation_layer.shape[1] == 512:\n",
    "           activation_layer = activation_layer.reshape(1, 8, 8, 8)\n",
    "\n",
    "    n = math.floor(np.sqrt(activation_layer.shape[3]))\n",
    "\n",
    "    if int(n + 0.5) ** 2 == activation_layer.shape[3]:\n",
    "\n",
    "        m = n\n",
    "    else:\n",
    "        m = math.floor(activation_layer.shape[3] / n)\n",
    "\n",
    "    if activation_layer.shape[3] == 1:\n",
    "        fig, ax = plt.subplots(1, 1, sharex='col', sharey='row',\n",
    "                                figsize=(15, 15))\n",
    "        fig.suptitle(layer_name)\n",
    "\n",
    "        ax.imshow(activation_layer[0,:, :, 0], cmap='viridis')\n",
    "        wandb.log({\"Activations\": wandb.Image(plt, caption=\"{}_{}\".format(model_name, layer_name)) })\n",
    " \n",
    "        return None   \n",
    "\n",
    "            \n",
    "    if n == 1:\n",
    "\n",
    "        fig, ax = plt.subplots(1, 3, sharex='col', sharey='row',figsize=(15, 15))\n",
    "        fig.suptitle(layer_name)\n",
    "        for i in range(3):\n",
    "            ax[i].imshow(activation_layer[0,:, :, i], cmap='viridis')\n",
    "        wandb.log({\"Activations\": wandb.Image(plt, caption=\"{}_{}\".format(model_name, layer_name)) })\n",
    "        return None   \n",
    "\n",
    "    fig, ax = plt.subplots(n, m, sharex='col', sharey='row',figsize=(15, 15))\n",
    "    fig.suptitle(layer_name)\n",
    "    \n",
    " \n",
    "\n",
    "    filter_counter = 0\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            ax[i, j].imshow(activation_layer[0,:, :, filter_counter], cmap='viridis')\n",
    "            filter_counter += 1\n",
    "            if filter_counter == (activation_layer.shape[3] ):\n",
    "                break\n",
    "\n",
    "    wandb.log({\"Activations\": wandb.Image(plt, caption=\"{}_{}\".format(model_name, layer_name)) })\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_activations( cvae.encoder)\n",
    "visualize_activations(cvae.decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualize filters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cvae.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util function to convert a tensor into a valid image\n",
    "def deprocess_image(img):\n",
    "    # Normalize array: center on 0., ensure variance is 0.15\n",
    "    img -= img.mean()\n",
    "    img /= img.std() + 1e-5\n",
    "    img *= 0.15\n",
    "\n",
    "    # Center crop\n",
    "    #img = img[ 25:-25, 25:-25, :]\n",
    "\n",
    "    # Clip to [0, 1]\n",
    "    img += 0.5\n",
    "    img = np.clip(img, 0, 1)\n",
    "\n",
    "    # Convert to RGB array\n",
    "    img *= 255\n",
    "    img = np.clip(img, 0, 255).astype(\"uint8\")\n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_conditional_input( inputs, label_size=10): \n",
    "  \n",
    "        image_size = [input_shape[0], input_shape[1], input_shape[2]]\n",
    "\n",
    "        input_img = layers.InputLayer(input_shape=image_size,\n",
    "                                        dtype ='float32')(inputs[0])\n",
    "        input_label = layers.InputLayer(input_shape=(label_size, ),\n",
    "                                        dtype ='float32')(inputs[1])\n",
    "\n",
    "        labels = tf.reshape(inputs[1], [-1, 1, 1, label_size])\n",
    "        labels = tf.cast(labels, dtype='float32')\n",
    "        ones = tf.ones([inputs[0].shape[0]] + image_size[0:-1] + [label_size]) \n",
    "        labels = ones * labels\n",
    "        conditional_input = layers.Concatenate(axis=3)([input_img, labels]) \n",
    "        return  input_img, input_label, conditional_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nth_filter_loss(filter_index, layer_name):\n",
    "    \"\"\"\n",
    "    We build a loss function that maximizes the activation\n",
    "    of the nth filter of the layer considered\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a connection between the input and the target layer\n",
    "    \n",
    "    submodel = tf.keras.models.Model([model.inputs[0]],\n",
    "                                     [model.get_layer(layer_name).output])\n",
    "\n",
    "# Initiate random noise\n",
    "\n",
    "    input_img_data = np.random.random((1, input_shape[0], input_shape[1],\n",
    "                                     input_shape[2]))\n",
    "\n",
    "    input_img_data =(input_img_data - 0.5) * 0.25\n",
    "    # Cast random noise from np.float64 to tf.float32 Variable\n",
    "    input_img_data = tf.Variable(tf.cast(input_img_data, tf.float32))\n",
    "\n",
    "    data = [input_img_data, train_y_one_hot[0]]\n",
    "    _, _, conditional_input_img = filter_conditional_input(data) \n",
    "    conditional_input_img= tf.Variable(tf.cast(conditional_input_img,\n",
    "                                         tf.float32))\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = submodel(conditional_input_img)\n",
    "            loss_value = tf.reduce_mean(outputs[:, 2:-2, 2:-2, filter_index]) #removed borders in loss\n",
    "        grads = tape.gradient(loss_value, conditional_input_img)\n",
    "        normalized_grads = grads / (tf.sqrt(tf.reduce_mean(tf.square(grads)))\n",
    "                                   + 1e-5)\n",
    "        #normalized_grads = tf.math.l2_normalize(grads)\n",
    "        conditional_input_img.assign_add(normalized_grads * step_size)\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    #iterate = K.function([input_img], [loss_value, grads])\n",
    "\n",
    "    if loss_value > 0:\n",
    "        \n",
    "        #img = conditional_input_img.numpy().astype(np.float64)\n",
    "        #img = img.squeeze()\n",
    "        #img = deprocess_image(img) / 255.\n",
    "        img = conditional_input_img.numpy().astype(np.float64)\n",
    "        img = img.squeeze()\n",
    "        img = deprocess_image(img)\n",
    "        kept_filters.append((img, loss_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dimensions of the generated pictures for each filter.\n",
    "img_width = input_shape[0]\n",
    "img_height = input_shape[1]\n",
    "\n",
    "# this is the placeholder for the input images\n",
    "input_img = model.input\n",
    "print(input_img.shape)\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "#layer_dict = dict([(layer.name, layer) for layer in model.layers[0:]])\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "layer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_filters = [layer.name for layer in model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "step_size = 10.\n",
    "kept_filters = []\n",
    "filters_dict = dict()\n",
    "for layer_name in layers_filters:\n",
    "    if 'conv' in layer_name:\n",
    "        layer = model.get_layer(layer_name)\n",
    "        print('Processing filter for layer:', layer_name)\n",
    "        for filter_index in range(min(layer.output.shape[-1], 100)):\n",
    "            # print('Processing filter %d' % filter_index)\n",
    "            build_nth_filter_loss(filter_index, layer_name)\n",
    "        filters_dict[layer.name] = kept_filters\n",
    "        kept_filters = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import save_img\n",
    "\n",
    "def stich_filters(kept_filters, layer_name):\n",
    "    # By default, we will stich the best 64 (n*n) filters on a 8 x 8 grid.\n",
    "    n = int(np.sqrt(len(kept_filters)))\n",
    "    # the filters that have the highest loss are assumed to be better-looking.\n",
    "    # we will only keep the top 64 filters.\n",
    "    kept_filters.sort(key=lambda x: x[1], reverse=True)\n",
    "    kept_filters = kept_filters[:n * n]\n",
    "\n",
    "    # build a black picture with enough space for\n",
    "    # our 8 x 8 filters of size 128 x 128, with a 5px margin in between\n",
    "    margin = 5\n",
    "    \n",
    "    width = n * img_width + (n - 1) * margin\n",
    "    height = n * img_height + (n - 1) * margin\n",
    "\n",
    "    stitched_filters = np.zeros((width, height, 3))\n",
    "\n",
    "    # fill the picture with our saved filters\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            img, _ = kept_filters[i * n + j]\n",
    "            width_margin = (img_width + margin) * i\n",
    "            height_margin = (img_height + margin) * j\n",
    "            stitched_filters[\n",
    "                width_margin: width_margin + img_width,\n",
    "                height_margin: height_margin + img_height, :] = img[:, :, :3] \n",
    "\n",
    "    wandb.log({\"Filters\": wandb.Image(stitched_filters, caption=\"{}_{}\".format(model.name, layer_name)) })\n",
    "    # save the result to disk\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_name, kept_filters in filters_dict.items():\n",
    "    print('Stiching filters for {}'.format(layer_name))\n",
    "    stich_filters(kept_filters, layer_name)\n",
    "    print('number of filters kept:', len(kept_filters))\n",
    "    print('Completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish(exit_code=0, quiet = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.cvae import CVAE\n",
    "#CVAE(cvae_encoder, cvae_decoder, kl_coefficient, input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Report activations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Report filters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0284a593613b942586af6b8f0d4ee916e356aed836174e2f823c929bc6bc05cc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('dis_vae')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
