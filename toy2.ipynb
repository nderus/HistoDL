{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conditional Variational autoencoder (VAE) - Toy datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Utility functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "print(tf. __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, os\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_indices(lst, condition):\n",
    "    return np.array([i for i, elem in enumerate(lst) if condition(elem)])\n",
    "    \n",
    "def plot_2d_data_categorical(data_2d, y, titles=None, figsize = (7, 7), category_count=10):\n",
    "  fig, axs = plt.subplots(category_count, len(data_2d), figsize = figsize)\n",
    "  colors = np.array(['#7FFFD4', '#458B74', '#0000CD', '#EE3B3B', '#7AC5CD', '#66CD00',\n",
    "         '#EE7621', '#3D59AB', '#CD950C', '#483D8B'])\n",
    "  for i in range(len(data_2d)):\n",
    "      for k in range(category_count):\n",
    "\n",
    "        index = find_indices(y[i], lambda e: e == k)\n",
    "\n",
    "        data_2d_k = data_2d[i][index, ]\n",
    "        y_k = y[i][index]\n",
    "\n",
    "        if (titles != None):\n",
    "          axs[k,i].set_title(titles[i])\n",
    "\n",
    "        scatter = axs[k, i].scatter(data_2d_k[:, 0], data_2d_k[:, 1],\n",
    "                                s=1, c=colors[k], cmap=plt.cm.Paired)\n",
    "        axs[k, i].legend(*scatter.legend_elements())\n",
    "        axs[k, i].set_xlim([-3, 3])\n",
    "        axs[k, i].set_ylim([-3, 3])\n",
    "        fig.savefig('reports/' + directory + '/encoding_categorical')\n",
    "        \n",
    "def plot_2d_data(data_2d, y, titles=None, figsize = (7, 7)):\n",
    "  _, axs = plt.subplots(1, len(data_2d), figsize = figsize)\n",
    "\n",
    "  for i in range(len(data_2d)):\n",
    "    \n",
    "    if (titles != None):\n",
    "      axs[i].set_title(titles[i])\n",
    "    scatter=axs[i].scatter(data_2d[i][:, 0], data_2d[i][:, 1],\n",
    "                            s=1, c=y[i], cmap=plt.cm.Paired)\n",
    "    axs[i].legend(*scatter.legend_elements())\n",
    "\n",
    "\n",
    "def plot_history(history,metric=None):\n",
    "  fig, ax1 = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "  epoch_count=len(history.history['loss'])\n",
    "\n",
    "  line1,=ax1.plot(range(1,epoch_count+1),history.history['loss'],\n",
    "                  label='train_loss',color='orange')\n",
    "  ax1.plot(range(1,epoch_count+1),history.history['val_loss'],\n",
    "                  label='val_loss',color = line1.get_color(), linestyle = '--')\n",
    "  ax1.set_xlim([1,epoch_count])\n",
    "  ax1.set_ylim([0, max(max(history.history['loss']),\n",
    "              max(history.history['val_loss']))])\n",
    "  ax1.set_ylabel('loss',color = line1.get_color())\n",
    "  ax1.tick_params(axis='y', labelcolor=line1.get_color())\n",
    "  ax1.set_xlabel('Epochs')\n",
    "  _=ax1.legend(loc='lower left')\n",
    "\n",
    "  if (metric!=None):\n",
    "    ax2 = ax1.twinx()\n",
    "    line2,=ax2.plot(range(1,epoch_count+1),history.history[metric],\n",
    "                    label='train_'+metric)\n",
    "    ax2.plot(range(1,epoch_count+1),history.history['val_'+metric],\n",
    "                    label='val_'+metric,color = line2.get_color(),\n",
    "                    linestyle = '--')\n",
    "    ax2.set_ylim([0, max(max(history.history[metric]),\n",
    "                max(history.history['val_'+metric]))])\n",
    "    ax2.set_ylabel(metric,color=line2.get_color())\n",
    "    ax2.tick_params(axis='y', labelcolor=line2.get_color())\n",
    "    _=ax2.legend(loc='upper right')\n",
    "\n",
    "def plot_generated_images(generated_images, nrows, ncols,\n",
    "                          no_space_between_plots=False, figsize=(10, 10)):\n",
    "  _, axs = plt.subplots(nrows, ncols,figsize=figsize,squeeze=False)\n",
    "\n",
    "  for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "      axs[i,j].axis('off')\n",
    "      axs[i,j].imshow(generated_images[i][j], cmap='gray')\n",
    "\n",
    "  if no_space_between_plots:\n",
    "    plt.subplots_adjust(wspace=0,hspace=0)\n",
    "\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_input(self, inputs, label_size=10):\n",
    "    image_size = [self.shape[0], self.shape[1], self.shape[2]]\n",
    "    input_img = layers.InputLayer(input_shape=image_size,\n",
    "                                dtype ='float32')(inputs[0])\n",
    "    input_label = layers.InputLayer(input_shape=(label_size, ),\n",
    "                                    dtype ='float32')(inputs[1])\n",
    "    labels = tf.reshape(inputs[1], [-1, 1, 1, label_size])\n",
    "    labels = tf.cast(labels, dtype='float32')\n",
    "    ones = tf.ones([inputs[0].shape[0]] + image_size[0:-1] + [label_size])\n",
    "    labels = ones * labels\n",
    "    conditional_input = layers.Concatenate(axis=3)([input_img, labels]) \n",
    "    return  input_img, input_label, conditional_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(z_mean, z_log_var, input_label):\n",
    "\n",
    "    eps = tf.random.normal(tf.shape(z_log_var), dtype=tf.float32,\n",
    "                            mean=0., stddev=1.0, name='epsilon')\n",
    "    z = z_mean + tf.exp(z_log_var / 2) * eps\n",
    "    z_cond = tf.concat([z, input_label], axis=1) \n",
    "    return z_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Val_Plot(loss, val_loss, reconstruction_loss, val_reconstruction_loss, kl_loss, val_kl_loss):\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize= (16,4))\n",
    "    fig.suptitle(\" MODEL'S METRICS VISUALIZATION \")\n",
    "\n",
    "    ax1.plot(range(1, len(loss) + 1), loss)\n",
    "    ax1.plot(range(1, len(val_loss) + 1), val_loss)\n",
    "    ax1.set_title('History of Loss')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend(['training', 'validation'])\n",
    "\n",
    "    ax2.plot(range(1, len(reconstruction_loss) + 1), reconstruction_loss)\n",
    "    ax2.plot(range(1, len(val_reconstruction_loss) + 1), val_reconstruction_loss)\n",
    "    ax2.set_title('History of reconstruction_loss')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('reconstruction_loss')\n",
    "    ax2.legend(['training', 'validation'])\n",
    "    \n",
    "    ax3.plot(range(1, len(kl_loss) + 1), kl_loss)\n",
    "    ax3.plot(range(1, len(val_kl_loss) + 1), val_kl_loss)\n",
    "    ax3.set_title(' History of kl_loss')\n",
    "    ax3.set_xlabel(' Epochs ')\n",
    "    ax3.set_ylabel('kl_loss')\n",
    "    ax3.legend(['training', 'validation'])\n",
    "    \n",
    "    plt.show()\n",
    "    fig.savefig('reports/' + directory + '/loss_function')\n",
    "\n",
    "    wandb.log({\"Training\": plt})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data import and manipulation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data flatten shape:  (50000, 32, 32, 3)\n",
      "Train label shape:  (50000, 1)\n",
      "Test data flatten shape:  (10000, 32, 32, 3)\n",
      "Test label shape:  (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"cifar10\"\n",
    "category_count=10 \n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "print('Train data flatten shape: ',train_x.shape)\n",
    "print('Train label shape: ',train_y.shape)\n",
    "print('Test data flatten shape: ',test_x.shape)\n",
    "print('Test label shape: ',test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\",\n",
    "         \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data flatten shape:  (40000, 32, 32, 3)\n",
      "Train label shape:  (40000, 1)\n",
      "Validation data flatten shape:  (10000, 32, 32, 3)\n",
      "Validation label shape:  (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "val_size=10000\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y,\n",
    "                            test_size = val_size,random_state = 1,shuffle=True)\n",
    "\n",
    "print('Train data flatten shape: ',train_x.shape)\n",
    "print('Train label shape: ',train_y.shape)\n",
    "print('Validation data flatten shape: ',val_x.shape)\n",
    "print('Validation label shape: ',val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(train_x.shape) == 3:\n",
    "    train_x=np.expand_dims(train_x,axis=3)\n",
    "    val_x=np.expand_dims(val_x,axis=3)\n",
    "    test_x=np.expand_dims(test_x,axis=3)\n",
    "    print('Train shape: ',train_x.shape)\n",
    "    print('Validation shape: ',val_x.shape)\n",
    "    print('Test shape: ',test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = train_x.shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min value:  0.0\n",
      "Max value:  1.0\n"
     ]
    }
   ],
   "source": [
    "train_x = train_x/255.0\n",
    "val_x = val_x/255.0\n",
    "test_x = test_x/255.0\n",
    "\n",
    "print('Min value: ',train_x.min())\n",
    "print('Max value: ',train_x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data flatten shape:  (40000, 3072)\n",
      "Validation data flatten shape:  (10000, 3072)\n",
      "Test data flatten shape:  (10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "original_image_shape=(train_x.shape[1], train_x.shape[2])\n",
    "\n",
    "train_x_flatten=np.reshape(train_x,(train_x.shape[0],-1))\n",
    "val_x_flatten=np.reshape(val_x,(val_x.shape[0],-1))\n",
    "test_x_flatten=np.reshape(test_x,(test_x.shape[0],-1))\n",
    "\n",
    "print('Train data flatten shape: ',train_x_flatten.shape)\n",
    "print('Validation data flatten shape: ',val_x_flatten.shape)\n",
    "print('Test data flatten shape: ',test_x_flatten.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label one hot encoding shape:  (40000, 10)\n",
      "Validation label one hot encoding shape:  (10000, 10)\n",
      "Test label one hot encoding shape:  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "train_y_one_hot = to_categorical(train_y,category_count)\n",
    "val_y_one_hot=to_categorical(val_y,category_count)\n",
    "test_y_one_hot=to_categorical(test_y,category_count)\n",
    "\n",
    "print('Train label one hot encoding shape: ',train_y_one_hot.shape)\n",
    "print('Validation label one hot encoding shape: ',val_y_one_hot.shape)\n",
    "print('Test label one hot encoding shape: ',test_y_one_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CVAE model**\n",
    "Creating a CVAE class and plugging encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relu brings a lot of activation values = 0, leaky seems better\n",
    "# https://towardsdatascience.com/the-dying-relu-problem-clearly-explained-42d0c54e0d24\n",
    "\n",
    "def bn_relu(inputs):\n",
    "    bn = layers.BatchNormalization()(inputs)\n",
    "    relu = layers.LeakyReLU(0.2)(bn)\n",
    "    return(relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, filters: int, kernel_size: int = 3):\n",
    "    y = layers.Conv2D(kernel_size=kernel_size,\n",
    "               strides= 1,\n",
    "               filters=filters,\n",
    "               padding=\"same\")(x)\n",
    "    y = bn_relu(y)\n",
    "    y = layers.Conv2D(kernel_size=kernel_size,\n",
    "               strides=1,\n",
    "               filters=filters,\n",
    "               padding=\"same\")(y)\n",
    "\n",
    "    out = layers.Concatenate()([x, y])\n",
    "    out = bn_relu(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder3( input_shape = (28, 28, 1),  label_size=10, encoded_dim = 2): \n",
    "\n",
    "    inputs = layers.Input(shape=(input_shape[0],\n",
    "                input_shape[1], input_shape[2] + label_size), dtype='float32',\n",
    "                name='Input')\n",
    "    #inputs = layers.Input(shape = input_shape)\n",
    "    #labels_inputs = layers.Input(shape = (50, 50, 2))\n",
    "    #encoder_inputs = layers.Concatenate()([inputs, labels_inputs])\n",
    "    #block 1\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                      padding='same',\n",
    "                      name='block1_conv1')(inputs)\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                      padding='same',\n",
    "                      name='block1_conv2')(x)\n",
    "    x = bn_relu(x)\n",
    "    # block 2\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      padding='same',\n",
    "                      name='block2_conv1')(x)\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      padding='same',\n",
    "                      name='block2_conv2')(x)\n",
    "\n",
    "    x = bn_relu(x)\n",
    "    x = layers.MaxPool2D(pool_size=2, strides=2,name='S4')(x)\n",
    "\n",
    "    # block 3\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      padding='same',\n",
    "                      name='block3_conv1')(x)\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                padding='same',\n",
    "                name='block3_conv2')(x)    \n",
    "    x = bn_relu(x)            \n",
    "    x = layers.Flatten()(x)\n",
    "    y = layers.Dense(encoded_dim * 2 )(x)\n",
    "    mu = layers.Dense(encoded_dim, name='mu')(y)\n",
    "    log_var = layers.Dense(encoded_dim, name='log_var')(y)\n",
    "    \n",
    "\n",
    "    model = keras.Model(inputs, [mu, log_var], name='encoder')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder5( input_shape = (28, 28, 1),  label_size=10, encoded_dim = 2): \n",
    "\n",
    "    inputs = layers.Input(shape=(input_shape[0],\n",
    "            input_shape[1], input_shape[2] + label_size), dtype='float32',name='Input')\n",
    "    #inputs = layers.Input(shape = input_shape)\n",
    "    #labels_inputs = layers.Input(shape = (50, 50, 2))\n",
    "    #encoder_inputs = layers.Concatenate()([inputs, labels_inputs])\n",
    "    #block 1\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                      padding='same',\n",
    "                      name='block1_conv1')(inputs)\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                      padding='same',\n",
    "                      name='block1_conv2')(x)\n",
    "    x = bn_relu(x)\n",
    "    # block 2\n",
    "    x = residual_block(x, 32)\n",
    "\n",
    "\n",
    "    x = layers.MaxPool2D(pool_size=2, strides=2,name='S4')(x)\n",
    "\n",
    "    # block 3\n",
    "    x = residual_block(x, 64)         \n",
    "    x = layers.Flatten()(x)\n",
    "    y = layers.Dense(encoded_dim * 2 )(x)\n",
    "    mu = layers.Dense(encoded_dim, name='mu')(y)\n",
    "    log_var = layers.Dense(encoded_dim, name='log_var')(y)\n",
    "    \n",
    "\n",
    "    model = keras.Model(inputs, [mu, log_var], name='encoder')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder5(input_shape, encoded_dim = 2,label_size=10): \n",
    "\n",
    "    decoder_inputs = layers.Input(shape=(encoded_dim + label_size,) , name='decoder_input')\n",
    "    x = layers.Dense(encoded_dim)\n",
    "    x = layers.Dense(encoded_dim * 2 )\n",
    "    x = layers.Dense(input_shape[0]/2 * input_shape[1]/2 *64)(decoder_inputs)\n",
    "    x = layers.Reshape(target_shape=(int(input_shape[0]/2),\n",
    "                     int(input_shape[1]/2), 64))(x)\n",
    "    x = residual_block(x, 64) \n",
    "    # block 2\n",
    "    x = residual_block(x, 32) \n",
    "\n",
    "    x = layers.UpSampling2D()(x)\n",
    "    \n",
    "    # block 3\n",
    "    x = residual_block(x, 16) \n",
    "                        \n",
    "    outputs = layers.Conv2DTranspose(filters=input_shape[-1], kernel_size=2,\n",
    "                             strides=1, activation='sigmoid',padding='same')(x)\n",
    "\n",
    "    model = keras.Model(decoder_inputs, outputs, name='decoder')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder4( input_shape = (28, 28, 1),  label_size=10, encoded_dim = 2): \n",
    "\n",
    "    inputs = layers.Input(shape=(input_shape[0],\n",
    "            input_shape[1], input_shape[2] + label_size), dtype='float32',name='Input')\n",
    "    #inputs = layers.Input(shape = input_shape)\n",
    "    #labels_inputs = layers.Input(shape = (50, 50, 2))\n",
    "    #encoder_inputs = layers.Concatenate()([inputs, labels_inputs])\n",
    "    #block 1\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      padding='same',\n",
    "                      name='block1_conv1')(inputs)\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                        padding='same',\n",
    "                        name='block1_conv2')(x)\n",
    "\n",
    "    x = bn_relu(x)\n",
    "    # block 2\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      padding='same',\n",
    "                      name='block2_conv1')(x)\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      padding='same',\n",
    "                      name='block2_conv2')(x)\n",
    "    x = bn_relu(x)   \n",
    "    x = layers.MaxPool2D(pool_size=2, strides=2,name='S4')(x)\n",
    "    \n",
    "    \n",
    "    # block 3\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      padding='same',\n",
    "                      name='block3_conv1')(x)\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "        padding='same',\n",
    "        name='block3_conv2')(x)\n",
    "\n",
    "    x = bn_relu(x)   \n",
    "\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      padding='same',\n",
    "                      name='block4_conv1')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      padding='same',\n",
    "                      name='block4_conv2')(x)\n",
    "    x = bn_relu(x)          \n",
    "    #x = layers.Conv2D(filters=5, kernel_size=5,strides=1,padding='same')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    y = layers.Dense(encoded_dim * 2 )(x)\n",
    "    mu = layers.Dense(encoded_dim, name='mu')(y)\n",
    "    log_var = layers.Dense(encoded_dim, name='log_var')(y)\n",
    "    \n",
    "\n",
    "    model = keras.Model(inputs, [mu, log_var], name='encoder')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder4(input_shape, encoded_dim = 2,label_size=10): \n",
    "\n",
    "    decoder_inputs = layers.Input(shape=(encoded_dim + label_size,) , name='decoder_input')\n",
    "    x = layers.Dense(encoded_dim)\n",
    "    x = layers.Dense(encoded_dim * 2 )\n",
    "    x = layers.Dense(input_shape[0]/2 * input_shape[1]/2 * 512)(decoder_inputs)\n",
    "    x = layers.Reshape(target_shape=(int(input_shape[0]/2),\n",
    "                     int(input_shape[1]/2), 512))(x)\n",
    "    x = bn_relu(x) \n",
    "    x = layers.Conv2DTranspose(512, (3, 3),\n",
    "                padding='same',\n",
    "                name='up_block0_conv1')(x)\n",
    "    x = bn_relu(x) \n",
    "\n",
    "    x = layers.Conv2DTranspose(256, (3, 3),\n",
    "                      padding='same',\n",
    "                      name='up_block1_conv1')(x)\n",
    "\n",
    "    x = bn_relu(x) \n",
    "    # block 2\n",
    "    x = layers.Conv2DTranspose(128, (3, 3),\n",
    "                      padding='same',\n",
    "                      name='up_block5_conv1')(x)\n",
    "\n",
    "    x = bn_relu(x) \n",
    "    x = layers.UpSampling2D()(x)\n",
    "    \n",
    "    # block 3\n",
    "    x = layers.Conv2DTranspose(64, (3, 3),\n",
    "                      padding='same',\n",
    "                      name='up_block6_conv1')(x)\n",
    "\n",
    "    x = bn_relu(x)                                \n",
    "    outputs = layers.Conv2DTranspose(filters=input_shape[-1], kernel_size=2,\n",
    "                             strides=1, activation='sigmoid',padding='same')(x)\n",
    "\n",
    "    model = keras.Model(decoder_inputs, outputs, name='decoder')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder3(input_shape, encoded_dim = 2,label_size=10): \n",
    "\n",
    "    decoder_inputs = layers.Input(shape=(encoded_dim + label_size,),\n",
    "                                 name='decoder_input')\n",
    "    x = layers.Dense(encoded_dim)\n",
    "\n",
    "    x = layers.Dense(encoded_dim * 2 )\n",
    " \n",
    "    x = layers.Dense(input_shape[0]/2 * input_shape[1]/2 *64)(decoder_inputs)\n",
    "   \n",
    "    x = layers.Reshape(target_shape=(int(input_shape[0]/2),\n",
    "                     int(input_shape[1]/2), 64))(x)\n",
    "    x = bn_relu(x) \n",
    "    x = layers.Conv2DTranspose(64, (3, 3),\n",
    "                      padding='same',\n",
    "                      name='up_block4_conv1')(x)\n",
    "    x = layers.Conv2DTranspose(64, (3, 3),\n",
    "                    padding='same',\n",
    "                    name='up_block4_conv2')(x)  \n",
    "    x = bn_relu(x) \n",
    "    # block 2\n",
    "    x = layers.Conv2DTranspose(32, (3, 3),\n",
    "                      padding='same',\n",
    "                      name='up_block5_conv1')(x)\n",
    "    x = layers.Conv2DTranspose(32, (3, 3),\n",
    "                      padding='same',\n",
    "                      name='up_block5_conv2')(x)\n",
    "    x = bn_relu(x) \n",
    "    x = layers.UpSampling2D()(x)\n",
    "    \n",
    "    # block 3\n",
    "    x = layers.Conv2DTranspose(16, (3, 3),\n",
    "                      padding='same',\n",
    "                      name='up_block6_conv1')(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(16, (3, 3),\n",
    "                    padding='same',\n",
    "                    name='up_block6_conv2')(x)\n",
    "    x = bn_relu(x)                                \n",
    "    outputs = layers.Conv2DTranspose(filters=input_shape[-1], kernel_size=2,\n",
    "                             strides=1, activation='sigmoid',padding='same')(x)\n",
    "\n",
    "    model = keras.Model(decoder_inputs, outputs, name='decoder')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder2( input_shape = (28, 28, 1),  label_size=10, encoded_dim = 2): \n",
    "\n",
    "    inputs = layers.Input(shape=(input_shape[0],\n",
    "            input_shape[1], input_shape[2] + label_size), dtype='float32',name='Input')\n",
    "    #inputs = layers.Input(shape = input_shape)\n",
    "    #labels_inputs = layers.Input(shape = (50, 50, 2))\n",
    "    #encoder_inputs = layers.Concatenate()([inputs, labels_inputs])\n",
    "   #block 0\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                      strides=(2, 2),\n",
    "                      padding='same',\n",
    "                      kernel_initializer='HeNormal',\n",
    "                      name='block0')(inputs)\n",
    "    x = layers.BatchNormalization()(x)                  \n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                      strides=(1, 1),\n",
    "                      padding='same',\n",
    "                      kernel_initializer='HeNormal',\n",
    "                      name='block0_1')(x)\n",
    "    x = layers.BatchNormalization()(x)                  \n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                      strides=(1, 1),\n",
    "                      padding='same',\n",
    "                      kernel_initializer='HeNormal',\n",
    "                      name='block0_2')(x)\n",
    "    x = layers.BatchNormalization()(x)                  \n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "\n",
    "    #block 1\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      strides=(2, 2),\n",
    "                      padding='same',\n",
    "                      kernel_initializer='HeNormal',\n",
    "                      name='block1')(x)\n",
    "    x = layers.BatchNormalization()(x)                  \n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      strides=(1, 1),\n",
    "                      padding='same',\n",
    "                      kernel_initializer='HeNormal',\n",
    "                      name='block1_1')(x)\n",
    "    x = layers.BatchNormalization()(x)                  \n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      strides=(1, 1),\n",
    "                      padding='same',\n",
    "                      kernel_initializer='HeNormal',\n",
    "                      name='block1_2')(x)\n",
    "    x = layers.BatchNormalization()(x)                  \n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    # block 2\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      strides=(2, 2),\n",
    "                      padding='same',\n",
    "                      kernel_initializer='HeNormal',\n",
    "                      name='block2')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      strides=(1, 1),\n",
    "                      padding='same',\n",
    "                      kernel_initializer='HeNormal',\n",
    "                      name='block2_1')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      strides=(1, 1),\n",
    "                      padding='same',\n",
    "                      kernel_initializer='HeNormal',\n",
    "                      name='block2_2')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    # block 3\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      strides=(2, 2),                      \n",
    "                      padding='same',\n",
    "                      kernel_initializer='HeNormal',\n",
    "                      name='block3')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                        strides=(1, 1),                      \n",
    "                        padding='same',\n",
    "                        kernel_initializer='HeNormal',\n",
    "                        name='block3_1')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                        strides=(1, 1),                      \n",
    "                        padding='same',\n",
    "                        kernel_initializer='HeNormal',\n",
    "                        name='block3_2')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "     # block 4\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      strides=(2, 2),\n",
    "                      padding='same',\n",
    "                      kernel_initializer='HeNormal',\n",
    "                      name='block4')(x)\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                strides=(1, 1),\n",
    "                padding='same',\n",
    "                kernel_initializer='HeNormal',\n",
    "                name='block4_1')(x)\n",
    "\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                strides=(1, 1),\n",
    "                padding='same',\n",
    "                kernel_initializer='HeNormal',\n",
    "                name='block4_2')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "               \n",
    "   # x = layers.Conv2D(filters=5, kernel_size=5, strides=1,padding='same')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    y = layers.Dense(encoded_dim * 2)(x)\n",
    "    mu = layers.Dense(encoded_dim, name='mu')(y)\n",
    "    log_var = layers.Dense(encoded_dim, name='log_var')(y)\n",
    "    \n",
    "\n",
    "    model = keras.Model(inputs, [mu, log_var], name='encoder')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder2(input_shape, encoded_dim = 2,label_size=10): \n",
    "\n",
    "    decoder_inputs = layers.Input(shape=(encoded_dim + label_size,) , name='decoder_input')\n",
    "    \n",
    "    x = layers.Dense(encoded_dim * 2)(decoder_inputs)\n",
    "\n",
    "    x = layers.Dense(int(input_shape[0]/16 * input_shape[1]/16 * 256))(x)\n",
    "\n",
    "    x = layers.Reshape(target_shape=(int(input_shape[0]/16),\n",
    "                     int(input_shape[1]/16), 256))(x)\n",
    "                     \n",
    "        #block 1 up\n",
    "    x = layers.Conv2DTranspose(256, (3, 3),\n",
    "                      strides=(2, 2),\n",
    "                      padding='same',\n",
    "                      kernel_initializer='HeNormal',\n",
    "                      name='block1_up')(x)\n",
    "    x = layers.BatchNormalization()(x)                  \n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(256, (3, 3),\n",
    "                      strides=(1, 1),\n",
    "                      padding='same',\n",
    "                      kernel_initializer='HeNormal',\n",
    "                      name='block1_1_up')(x)\n",
    "    x = layers.BatchNormalization()(x)                  \n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    \n",
    "\n",
    "        #block 2 up\n",
    "    x = layers.Conv2DTranspose(128, (3, 3),\n",
    "                      strides=(2, 2),\n",
    "                      padding='same',\n",
    "                      kernel_initializer='HeNormal',\n",
    "                      name='block2_up')(x)\n",
    "    x = layers.BatchNormalization()(x)                  \n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(128, (3, 3),\n",
    "                    strides=(1, 1),\n",
    "                    padding='same',\n",
    "                    kernel_initializer='HeNormal',\n",
    "                    name='block2_1_up')(x)\n",
    "    x = layers.BatchNormalization()(x)                  \n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "            #block 3 up\n",
    "    x = layers.Conv2DTranspose(64, (3, 3),\n",
    "                      strides=(2, 2),\n",
    "                      padding='same',\n",
    "                      kernel_initializer='HeNormal',\n",
    "                      name='block3_up')(x)\n",
    "    x = layers.BatchNormalization()(x)                  \n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(64, (3, 3),\n",
    "                    strides=(1, 1),\n",
    "                    padding='same',\n",
    "                    kernel_initializer='HeNormal',\n",
    "                    name='block3_1_up')(x)\n",
    "    x = layers.BatchNormalization()(x)                  \n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "             #block 4 up\n",
    "    x = layers.Conv2DTranspose(32, (3, 3),\n",
    "                      strides=(2, 2),\n",
    "                      padding='same',\n",
    "                      kernel_initializer='HeNormal',\n",
    "                      name='block4_up')(x)\n",
    "    x = layers.BatchNormalization()(x)                  \n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(32, (3, 3),\n",
    "                    strides=(1, 1),\n",
    "                    padding='same',\n",
    "                    kernel_initializer='HeNormal',\n",
    "                    name='block4_1_up')(x)\n",
    "    x = layers.BatchNormalization()(x)                  \n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "                 #block 5 up\n",
    "    x = layers.Conv2DTranspose(16, (3, 3),\n",
    "                      strides=(1, 1),\n",
    "                      padding='same',\n",
    "                      kernel_initializer='HeNormal',\n",
    "                      name='block5_up')(x)\n",
    "    x = layers.BatchNormalization()(x)                  \n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(16, (3, 3),\n",
    "                    strides=(1, 1),\n",
    "                    padding='same',\n",
    "                    kernel_initializer='HeNormal',\n",
    "                    name='block5_1_up')(x)\n",
    "    x = layers.BatchNormalization()(x)                  \n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "                                   \n",
    "    outputs = layers.Conv2DTranspose(filters=input_shape[-1], kernel_size=1,\n",
    "                             strides=1, activation='sigmoid',padding='same')(x)\n",
    "\n",
    "    model = keras.Model(decoder_inputs, outputs, name='decoder')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder( input_shape = (28, 28, 1),  label_size=10, encoded_dim = 2): \n",
    "\n",
    "    inputs = layers.Input(shape=(input_shape[0],\n",
    "            input_shape[1], input_shape[2] + label_size), dtype='float32',name='Input')\n",
    "    #inputs = layers.Input(shape = input_shape)\n",
    "    #labels_inputs = layers.Input(shape = (50, 50, 2))\n",
    "    #encoder_inputs = layers.Concatenate()([inputs, labels_inputs])\n",
    "\n",
    "\n",
    "    #block 1\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv1')(inputs)\n",
    "\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv2')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    # block 2\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv1')(x)\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv2')(x)\n",
    "    x = layers.MaxPool2D(pool_size=2, strides=2,name='S4')(x)\n",
    "    \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # block 3\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv1')(x)\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                activation='relu',\n",
    "                padding='same',\n",
    "                name='block3_conv2')(x)    \n",
    "                    \n",
    "    x = layers.Conv2D(filters=5, kernel_size=5,strides=1,padding='same')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    y = layers.Dense(encoded_dim * 2)(x)\n",
    "    mu = layers.Dense(encoded_dim, name='mu')(y)\n",
    "    log_var = layers.Dense(encoded_dim, name='log_var')(y)\n",
    "    \n",
    "\n",
    "    model = keras.Model(inputs, [mu, log_var], name='encoder')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(input_shape, encoded_dim = 2,label_size=10): \n",
    "    #add normalization layers???\n",
    "    decoder_inputs = layers.Input(shape=(encoded_dim + label_size,) , name='decoder_input')\n",
    "    x = layers.Dense(encoded_dim)\n",
    "    x = layers.Dense(encoded_dim * 2)\n",
    "    x = layers.Dense(input_shape[0]/2 * input_shape[1]/2 *64)(decoder_inputs)\n",
    "    x = layers.Reshape(target_shape=(int(input_shape[0]/2),\n",
    "                     int(input_shape[1]/2), 64))(x)\n",
    "    x = layers.Conv2DTranspose(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block4_conv1')(x)\n",
    "    x = layers.Conv2DTranspose(64, (3, 3),\n",
    "                    activation='relu',\n",
    "                    padding='same',\n",
    "                    name='up_block4_conv2')(x)  \n",
    "    \n",
    "    # block 2\n",
    "    x = layers.Conv2DTranspose(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block5_conv1')(x)\n",
    "    x = layers.Conv2DTranspose(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block5_conv2')(x)\n",
    "    x = layers.UpSampling2D()(x)\n",
    "    \n",
    "    # block 3\n",
    "    x = layers.Conv2DTranspose(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block6_conv1')(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(16, (3, 3),\n",
    "                    activation='relu',\n",
    "                    padding='same',\n",
    "                    name='up_block6_conv2')(x)\n",
    "                                   \n",
    "    outputs = layers.Conv2DTranspose(filters=input_shape[-1], kernel_size=2,\n",
    "                             strides=1, activation='sigmoid',padding='same')(x)\n",
    "\n",
    "    model = keras.Model(decoder_inputs, outputs, name='decoder')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-01 14:08:28.851843: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "cvae_encoder = encoder3(encoded_dim = encoded_dim, input_shape = input_shape)\n",
    "cvae_decoder = decoder3(encoded_dim = encoded_dim, input_shape = input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input (InputLayer)             [(None, 32, 32, 13)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 32, 32, 16)   1888        ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 32, 32, 16)   2320        ['block1_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32, 16)  64          ['block1_conv2[0][0]']           \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 32, 32, 16)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)          (None, 32, 32, 32)   4640        ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)          (None, 32, 32, 32)   9248        ['block2_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 32, 32)  128         ['block2_conv2[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 32, 32, 32)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " S4 (MaxPooling2D)              (None, 16, 16, 32)   0           ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)          (None, 16, 16, 64)   18496       ['S4[0][0]']                     \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)          (None, 16, 16, 64)   36928       ['block3_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 16, 16, 64)  256         ['block3_conv2[0][0]']           \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 16, 16, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 16384)        0           ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 20)           327700      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " mu (Dense)                     (None, 10)           210         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " log_var (Dense)                (None, 10)           210         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 402,088\n",
      "Trainable params: 401,864\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cvae_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " decoder_input (InputLayer)  [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16384)             344064    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " up_block4_conv1 (Conv2DTran  (None, 16, 16, 64)       36928     \n",
      " spose)                                                          \n",
      "                                                                 \n",
      " up_block4_conv2 (Conv2DTran  (None, 16, 16, 64)       36928     \n",
      " spose)                                                          \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 16, 16, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " up_block5_conv1 (Conv2DTran  (None, 16, 16, 32)       18464     \n",
      " spose)                                                          \n",
      "                                                                 \n",
      " up_block5_conv2 (Conv2DTran  (None, 16, 16, 32)       9248      \n",
      " spose)                                                          \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 16, 16, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 16, 16, 32)        0         \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 32, 32, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " up_block6_conv1 (Conv2DTran  (None, 32, 32, 16)       4624      \n",
      " spose)                                                          \n",
      "                                                                 \n",
      " up_block6_conv2 (Conv2DTran  (None, 32, 32, 16)       2320      \n",
      " spose)                                                          \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 32, 32, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 32, 32, 16)        0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 32, 32, 3)        195       \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 453,475\n",
      "Trainable params: 453,123\n",
      "Non-trainable params: 352\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cvae_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, beta, shape, **kwargs):\n",
    "        super(CVAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.beta = beta\n",
    "        self.shape = shape\n",
    "        self.latent_var = []\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        #\n",
    "        self.v_total_loss_tracker = keras.metrics.Mean(name=\"v_total_loss\")\n",
    "        self.v_reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"v_reconstruction_loss\")\n",
    "        self.v_kl_loss_tracker = keras.metrics.Mean(name=\"v_kl_loss\")\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "       \n",
    "    def call(self, inputs):\n",
    "        _, input_label, conditional_input = self.conditional_input(inputs)\n",
    "        z_mean, z_log_var = self.encoder(conditional_input)\n",
    "        z_cond = self.sampling(z_mean, z_log_var, input_label)\n",
    "        return self.decoder(z_cond)\n",
    "    \n",
    "    def conditional_input(self, inputs, label_size=10): \n",
    "  \n",
    "        image_size = [self.shape[0], self.shape[1], self.shape[2]]\n",
    "    \n",
    "        input_img = layers.InputLayer(input_shape=image_size,\n",
    "                                      dtype ='float32')(inputs[0])\n",
    "        input_label = layers.InputLayer(input_shape=(label_size, ),\n",
    "                                        dtype ='float32')(inputs[1])\n",
    "\n",
    "        labels = tf.reshape(inputs[1], [-1, 1, 1, label_size])\n",
    "        labels = tf.cast(labels, dtype='float32')\n",
    "        ones = tf.ones([inputs[0].shape[0]] + image_size[0:-1] + [label_size]) \n",
    "        labels = ones * labels\n",
    "        conditional_input = layers.Concatenate(axis=3)([input_img, labels]) \n",
    "        return  input_img, input_label, conditional_input\n",
    "\n",
    "    def sampling(self, z_mean, z_log_var, input_label):\n",
    "        if len(input_label.shape) == 1:\n",
    "            input_label = np.expand_dims(input_label, axis=0)\n",
    "\n",
    "        eps = tf.random.normal(tf.shape(z_log_var), dtype=tf.float32,\n",
    "                               mean=0., stddev=1.0, name='epsilon')\n",
    "        z = z_mean + tf.exp(z_log_var / 2) * eps\n",
    "        z_cond = tf.concat([z, input_label], axis=1)\n",
    "        return z_cond\n",
    "\n",
    "    def train_step(self, data):\n",
    "\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "        \n",
    "            input_img, input_label, conditional_input = self.conditional_input(data)\n",
    "            z_mean, z_log_var = self.encoder(conditional_input)\n",
    "            self.latent_var.append(z_log_var)\n",
    "            z_cond = self.sampling(z_mean, z_log_var, input_label)\n",
    "            reconstruction = self.decoder(z_cond)\n",
    "            reconstruction_loss = np.prod(self.shape) * tf.keras.losses.MSE(tf.keras.backend.flatten(input_img),\n",
    "                                    tf.keras.backend.flatten(reconstruction))            \n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean)\n",
    "                      - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1)) # was just reduce_sum\n",
    "            kl_loss = self.beta * kl_loss\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "            #total_loss = tf.reduce_mean(total_loss) #not necessary since I added red mean in kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        #wandb.log({\"loss\": total_loss, \"reconstructon_loss\": reconstruction_loss, \"kl_loss\": kl_loss,})\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        input_img, input_label, conditional_input = self.conditional_input(data)\n",
    "        z_mean, z_log_var = self.encoder(conditional_input)\n",
    "        z_cond = self.sampling(z_mean, z_log_var, input_label)\n",
    "        reconstruction = self.decoder(z_cond)\n",
    "        reconstruction_loss = np.prod(self.shape) * tf.keras.losses.MSE(tf.keras.backend.flatten(input_img),\n",
    "                             tf.keras.backend.flatten(reconstruction)) # over weighted MSE    \n",
    "\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean)\n",
    "                  - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "        kl_loss = self.beta * kl_loss\n",
    "        total_loss = reconstruction_loss + kl_loss\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return{\n",
    "            'loss': total_loss,\n",
    "            'reconstruction_loss': reconstruction_loss,\n",
    "            'kl_loss': kl_loss\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kl coefficient: 0.003\n",
      "Model: \"cvae\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder (Functional)        [(None, 10),              402088    \n",
      "                              (None, 10)]                        \n",
      "                                                                 \n",
      " decoder (Functional)        (None, 32, 32, 3)         453475    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 855,575\n",
      "Trainable params: 854,987\n",
      "Non-trainable params: 588\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "kl_coefficient = encoded_dim / (input_shape[0] * input_shape[1] * input_shape[2])\n",
    "print('kl coefficient: {:.3f}'.format(kl_coefficient))\n",
    "# from b vae paper, use beta = encoded_dimension / pixel_dimension i.e. -> 0.068\n",
    "cvae = CVAE(cvae_encoder, cvae_decoder, kl_coefficient, input_shape)\n",
    "cvae.built = True\n",
    "cvae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae_input = cvae.encoder.input[0]\n",
    "cvae_output = cvae.decoder.output\n",
    "mu = cvae.encoder.get_layer('mu').output\n",
    "log_var = cvae.encoder.get_layer('log_var').output\n",
    "\n",
    "learning_rate = 0.0001\n",
    "opt = keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "cvae.compile(optimizer = opt)\n",
    "#cvae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([100, 512])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_mean = np.random.normal(size=(100, 512))\n",
    "z_log_var =  np.random.normal(size=(100, 512))\n",
    "\n",
    "kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean)\n",
    "            - tf.exp(z_log_var))\n",
    "\n",
    "kl_loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1)) #sum over encoded dimensiosn, average over batch\n",
    "kl_loss.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=613991.1010629229>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_img = np.random.normal(size=(100, 32, 32, 3))\n",
    "reconstruction = np.random.normal(size=(100, 32, 32, 3))\n",
    "\n",
    "reconstruction_loss = np.prod(input_img.shape) * tf.keras.losses.MSE(tf.keras.backend.flatten(input_img),\n",
    "                                    tf.keras.backend.flatten(reconstruction)) \n",
    "\n",
    "reconstruction_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction_loss = tf.reduce_mean(tf.reduce_sum(\n",
    "\n",
    "                keras.losses.binary_crossentropy(input_img,\n",
    "                                    reconstruction), axis=(1, 2)))\n",
    "\n",
    "reconstruction_loss.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_count = 100\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '20220601-140832_cvae_cifar10_ndim:10_kl:0.003_epoch:100_batch:100' created\n"
     ]
    }
   ],
   "source": [
    "# Directory\n",
    "directory = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"_{}_{}_ndim:{}_kl:{:.3f}_epoch:{}_batch:{}\".format(cvae.name, \n",
    "             dataset_name, encoded_dim, kl_coefficient, epoch_count, batch_size)\n",
    "  \n",
    "# Parent Directory path\n",
    "parent_dir = \"reports\"\n",
    "  \n",
    "# Path\n",
    "path = os.path.join(parent_dir, directory)\n",
    "  \n",
    "# Create the directory\n",
    "# 'GeeksForGeeks' in\n",
    "# '/home / User / Documents'\n",
    "os.mkdir(path)\n",
    "print(\"Directory '%s' created\" %directory)\n",
    "\n",
    "os.mkdir(path + '/activations')\n",
    "os.mkdir(path + '/filters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "#wandb.init(project=\"my-test-project\", entity=\"nrderus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnrderus\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/PERSONALE/nicolas.derus2/HistoDL/wandb/run-20220601_140833-2kp5f29c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nrderus/HistoDL/runs/2kp5f29c\" target=\"_blank\">summer-aardvark-16</a></strong> to <a href=\"https://wandb.ai/nrderus/HistoDL\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/nrderus/HistoDL/runs/2kp5f29c?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f261d5bb6d0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patience = 5\n",
    "\n",
    "\n",
    "wandb.init(project=\"HistoDL\", entity=\"nrderus\",\n",
    "  config = {\n",
    "  \"dataset\": \"cifar10\",\n",
    "  \"encoded_dim\": encoded_dim,\n",
    "  \"learning_rate\": learning_rate,\n",
    "  \"epochs\": epoch_count,\n",
    "  \"batch_size\": batch_size,\n",
    "  \"patience\": patience,\n",
    "  \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "400/400 [==============================] - 68s 167ms/step - loss: 144.0378 - reconstruction_loss: 108.1905 - kl_loss: 0.2840 - val_loss: 84.7861 - val_reconstruction_loss: 84.4125 - val_kl_loss: 0.3736 - _timestamp: 1654085388.0000 - _runtime: 75.0000\n",
      "Epoch 2/100\n",
      "203/400 [==============>...............] - ETA: 30s - loss: 74.4869 - reconstruction_loss: 73.2401 - kl_loss: 0.3073"
     ]
    }
   ],
   "source": [
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "             patience=patience, restore_best_weights=True)\n",
    "\n",
    "history = cvae.fit([train_x,train_y_one_hot],\n",
    "                   validation_data=([val_x,val_y_one_hot],None),\n",
    "                   epochs=epoch_count,\n",
    "                   batch_size=batch_size,\n",
    "                   callbacks=[early_stop, tensorboard_callback, WandbCallback(save_weights_only=True)  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Val_Plot(history.history['loss'][1:],\n",
    "               history.history['val_loss'][1:],\n",
    "               history.history['reconstruction_loss'][1:],\n",
    "               history.history['val_reconstruction_loss'][1:],\n",
    "               history.history['kl_loss'][1:],\n",
    "               history.history['val_kl_loss'][1:]\n",
    "               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard import notebook\n",
    "notebook.list() # View open TensorBoard instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward the port 6006 on server on 12006 on  my machine\n",
    "# ssh -N -L 16006:127.0.0.1:6006 nicolas.derus2@137.204.48.211\n",
    "# access with http://127.0.0.1:16006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = cvae.evaluate([test_x, test_y_one_hot],None,\n",
    "            batch_size=batch_size,verbose=0)\n",
    "print('Test loss: {:.3f}'.format(test_loss[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Embdedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_size = 10\n",
    "_, input_label_train, train_input = cvae.conditional_input([train_x, train_y_one_hot])\n",
    "_, input_label_test, test_input = cvae.conditional_input([test_x, test_y_one_hot])\n",
    "_, input_label_val, val_input = cvae.conditional_input([val_x, val_y_one_hot])\n",
    "\n",
    "\n",
    "print(input_label_train.shape)\n",
    "print(train_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_mean, train_log_var = cvae.encoder.predict(train_input)\n",
    "test_x_mean, test_log_var = cvae.encoder.predict(test_input)\n",
    "val_x_mean, val_log_var = cvae.encoder.predict(val_input)\n",
    "\n",
    "print(train_x_mean.shape)\n",
    "print(train_log_var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if encoded_dim > 2:\n",
    "    from sklearn import manifold\n",
    "    tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "    train_x_tsne = tsne.fit_transform(train_x_mean[:2000])\n",
    "    test_x_tsne = tsne.fit_transform(test_x_mean[:2000])\n",
    "    val_x_tsne = tsne.fit_transform(val_x_mean[:2000])\n",
    "    plot_2d_data( [train_x_tsne, test_x_tsne, val_x_tsne],\n",
    "            [train_y[:2000], test_y[:2000] ,val_y[:2000]],\n",
    "            ['Train','Test', 'Validation'],(18,6))\n",
    "    plot_2d_data_categorical( [train_x_mean, test_x_mean, val_x_mean],\n",
    "            [train_y, test_y ,val_y],\n",
    "            ['Train','Test', 'Validation'],(12,36))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if encoded_dim == 2:\n",
    "    plot_2d_data( [train_x_mean, test_x_mean, val_x_mean],\n",
    "                [train_y, test_y ,val_y],\n",
    "                ['Train','Test', 'Validation'],(18,6))\n",
    "    plot_2d_data_categorical( [train_x_mean, test_x_mean, val_x_mean],\n",
    "                [train_y, test_y ,val_y],\n",
    "                ['Train','Test', 'Validation'],(12,36))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reconstruction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstructions...\n",
    "z_cond_train = sampling(train_x_mean, train_log_var, input_label_train)\n",
    "z_cond_test = sampling(test_x_mean, test_log_var, input_label_test)\n",
    "z_cond_val = sampling(val_x_mean, val_log_var, input_label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_train = cvae.decoder(z_cond_train)\n",
    "reconstruction_test = cvae.decoder(z_cond_test)\n",
    "reconstruction_val = cvae.decoder(z_cond_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = random.randint(0, reconstruction_train.shape[0])\n",
    "random_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = 5\n",
    "\n",
    "_, axs = plt.subplots(2, image_count, figsize=(12, 3))\n",
    "for i in range(image_count):\n",
    "  random_idx = random.randint(0, reconstruction_train.shape[0])\n",
    "  axs[0, i].imshow(train_x[random_idx])\n",
    "  axs[0, i].axis('off')\n",
    "  #axs[0, i].set_title(train_y[random_idx])\n",
    "  axs[0, i].set_title( labels[int(train_y[random_idx])]  )\n",
    "  axs[1, i].imshow(reconstruction_train[random_idx])\n",
    "  axs[1, i].axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cvae.latent_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparametrization(z_mean, z_log_var, input_label):\n",
    "    \"\"\" Performs the riparametrization trick\"\"\"\n",
    "\n",
    "    eps = tf.random.normal(shape = (input_label.shape[0], encoded_dim),\n",
    "                             mean = 0.0, stddev = 1.0)       \n",
    "    z = z_mean + tf.math.exp(z_log_var * .5) * eps\n",
    "    z_cond = tf.concat([z, input_label], axis=1) # (batch_size, label_dim + latent_dim)\n",
    "\n",
    "    return z_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_label = 5\n",
    "digit_label_one_hot = to_categorical(digit_label, category_count).reshape(1,-1)\n",
    "a = tf.convert_to_tensor(digit_label_one_hot)\n",
    "b = tf.concat([a, a], axis=0) # with 1 dimension, it fails...\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_cond = reparametrization(z_mean=0, z_log_var=0.2, input_label = b)\n",
    "decoded_x = cvae_decoder.predict(z_cond)\n",
    "digit = decoded_x[0].reshape(input_shape) \n",
    "plt.axis('off')\n",
    "plt.imshow(digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_label = 5\n",
    "_, axs = plt.subplots(2, image_count, figsize=(12, 3))\n",
    "for i in range(image_count):\n",
    "    digit_label_one_hot = to_categorical(digit_label, category_count).reshape(1,-1)\n",
    "    a = tf.convert_to_tensor(digit_label_one_hot)\n",
    "    b = tf.concat([a, a], axis=0) # with 1 dimension, it fails...\n",
    "    z_cond = reparametrization(z_mean=0, z_log_var=0.2, input_label = b)\n",
    "    decoded_x = cvae_decoder.predict(z_cond)\n",
    "    digit_0 = decoded_x[0].reshape(input_shape) \n",
    "    digit_1 = decoded_x[1].reshape(input_shape) \n",
    "    axs[0, i].imshow(digit_0)\n",
    "    axs[0, i].axis('off')\n",
    "    #axs[0, i].set_title(digit_label)\n",
    "    axs[0, i].set_title( labels[digit_label]  )\n",
    "    axs[1, i].imshow(digit_1)\n",
    "    axs[1, i].axis('off')\n",
    "    axs[1, i].set_title( labels[digit_label]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae.save_weights('weights/cvae_toy.h5')\n",
    "cvae_encoder.save('models/cvae_encoder_toy.h5')\n",
    "cvae_decoder.save('models/cvae_decoder_toy.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if encoded_dim == 2:\n",
    "  n = 10  # number of images per row and column\n",
    "  limit=3 # random values are sampled from the range [-limit,+limit]\n",
    "  first_dim_const= 0  # constant value of the second latent dimension\n",
    "\n",
    "  grid_y = np.linspace(-limit,limit, n) \n",
    "\n",
    "  generated_images=[]\n",
    "  for digit_label in range(category_count):\n",
    "    digit_label_one_hot=to_categorical(digit_label, category_count).reshape(1,-1)\n",
    "    \n",
    "    single_row_generated_images=[]\n",
    "    for i, yi in enumerate(grid_y):\n",
    "      random_sample = np.array([[first_dim_const, yi]])\n",
    "      z_cond = sampling(z_mean=random_sample, z_log_var=0.3,\n",
    "                      input_label = digit_label_one_hot )\n",
    "      decoded_x = cvae_decoder.predict(z_cond)\n",
    "      single_row_generated_images.append(decoded_x[0].reshape(input_shape))\n",
    "    generated_images.append(single_row_generated_images)      \n",
    "\n",
    "  plot_generated_images(generated_images,n,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cvae.built = True\n",
    "#cvae.load_weights('weights/vae_toy.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualize activation functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = cvae.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = test_x[1]\n",
    "plt.imshow(test)\n",
    "#test = image.img_to_array(test)\n",
    "test = np.expand_dims(test, axis=0)\n",
    "test.shape\n",
    "test_label = test_y_one_hot[0]\n",
    "img_tensor = [test, test_label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "\n",
    "# Extracts the outputs of the top 8 layers:\n",
    "import tensorflow as tf\n",
    "\n",
    "layer_outputs = []\n",
    "layer_names = []\n",
    "for layer in model.layers[1:]:\n",
    "    \n",
    "    try: \n",
    "        layer_outputs.append(layer.get_output_at(1))\n",
    "        layer_names.append(layer.name)\n",
    "    \n",
    "    except:\n",
    "        layer_outputs.append(layer.output)\n",
    "        layer_names.append(layer.name)\n",
    "\n",
    "# Creates a model that will return these outputs, given the model input:\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "activation_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return a list of 5 Numpy arrays:\n",
    "# one array per layer activation\n",
    "if 'encoder' in model.name:\n",
    "    input_img, input_label, conditional_input = cvae.conditional_input(img_tensor)\n",
    "    activations = activation_model.predict(conditional_input) #for encoder\n",
    "\n",
    "if 'decoder' in model.name:\n",
    "    input_img, input_label, conditional_input = cvae.conditional_input(img_tensor)\n",
    "    input_label = np.expand_dims(input_label, axis=0)\n",
    "    z_mean, z_log_var = cvae.encoder(conditional_input)\n",
    "    z_cond = cvae.sampling(z_mean, z_log_var, input_label)\n",
    "    \n",
    "    activations = activation_model.predict(z_cond) #for decoder\n",
    "\n",
    "len(activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def plot_filters(activation_layer, layer_name, counter):\n",
    "    if len(activation_layer.shape) == 2: # if flat layer\n",
    "        print('flat')\n",
    "        return None\n",
    "        if activation_layer.shape[1] == 1875:\n",
    "            activation_layer = activation_layer.reshape(1, 25, 25, 3)\n",
    "        if activation_layer.shape[1] == 1024:\n",
    "           activation_layer = activation_layer.reshape(1, 16, 16, 4)\n",
    "        if activation_layer.shape[1] == 512:\n",
    "           activation_layer = activation_layer.reshape(1, 8, 8, 8)\n",
    "\n",
    "    n = math.floor(np.sqrt(activation_layer.shape[3]))\n",
    "\n",
    "    if int(n + 0.5) ** 2 == activation_layer.shape[3]:\n",
    "\n",
    "        m = n\n",
    "    else:\n",
    "        m = math.floor(activation_layer.shape[3] / n)\n",
    "\n",
    "    if activation_layer.shape[3] == 1:\n",
    "        fig, ax = plt.subplots(1, 1, sharex='col', sharey='row',\n",
    "                                figsize=(15, 15))\n",
    "        fig.suptitle(layer_name)\n",
    "        ax.imshow(activation_layer[0,:, :, 0], cmap='viridis')\n",
    "        fig.savefig(\"reports/\" + directory + '/activations/{}_{}_activations_{}.png'.format(model.name,\n",
    "                     counter, layer_name))\n",
    "        return None   \n",
    "\n",
    "            \n",
    "    if n == 1:\n",
    "\n",
    "        fig, ax = plt.subplots(1, 3, sharex='col', sharey='row',figsize=(15, 15))\n",
    "        fig.suptitle(layer_name)\n",
    "        for i in range(3):\n",
    "            ax[i].imshow(activation_layer[0,:, :, i], cmap='viridis')\n",
    "        fig.savefig(\"reports/\" +directory +'/activations/{}_{}_activations_{}.png'.format(model.name, counter, layer_name))\n",
    "        return None   \n",
    "\n",
    "    fig, ax = plt.subplots(n, m, sharex='col', sharey='row',figsize=(15, 15))\n",
    "    fig.suptitle(layer_name)\n",
    "    \n",
    " \n",
    "\n",
    "    filter_counter = 0\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            ax[i, j].imshow(activation_layer[0,:, :, filter_counter], cmap='viridis')\n",
    "            filter_counter += 1\n",
    "            if filter_counter == (activation_layer.shape[3] ):\n",
    "                break\n",
    "    \n",
    "    fig.savefig(\"reports/\" + directory + \"/activations/{}_{}_activations_{}.png\".format(model.name, counter, layer_name))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for activation, name in zip(activations[0:], layer_names[0:]):\n",
    "\n",
    "    print(name)\n",
    "    print(activation.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for counter, (activation, name) in enumerate(zip(activations[0:], layer_names[0:])):\n",
    "    print(name)\n",
    "    plot_filters(activation, name, counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualize filters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util function to convert a tensor into a valid image\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + K.epsilon())\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_conditional_input( inputs, label_size=10): \n",
    "  \n",
    "        image_size = [input_shape[0], input_shape[1], input_shape[2]]\n",
    "\n",
    "        input_img = layers.InputLayer(input_shape=image_size,\n",
    "                                        dtype ='float32')(inputs[0])\n",
    "        input_label = layers.InputLayer(input_shape=(label_size, ),\n",
    "                                        dtype ='float32')(inputs[1])\n",
    "\n",
    "        labels = tf.reshape(inputs[1], [-1, 1, 1, label_size])\n",
    "        labels = tf.cast(labels, dtype='float32')\n",
    "        ones = tf.ones([inputs[0].shape[0]] + image_size[0:-1] + [label_size]) \n",
    "        labels = ones * labels\n",
    "        conditional_input = layers.Concatenate(axis=3)([input_img, labels]) \n",
    "        return  input_img, input_label, conditional_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nth_filter_loss(filter_index, layer_name):\n",
    "    \"\"\"\n",
    "    We build a loss function that maximizes the activation\n",
    "    of the nth filter of the layer considered\n",
    "    \"\"\"\n",
    "    \n",
    "    layer_output = layer_dict[layer_name].output\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        loss = K.mean(layer_output[:, filter_index, :, :])\n",
    "    else:\n",
    "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "    # Initiate random noise\n",
    "    # Create a connection between the input and the target layer\n",
    "    \n",
    "    submodel = tf.keras.models.Model([model.inputs[0]],\n",
    "                                     [model.get_layer(layer_name).output])\n",
    "\n",
    "# Initiate random noise\n",
    "\n",
    "    input_img_data = np.random.random((1, input_shape[0], input_shape[1],\n",
    "                                     input_shape[2]))\n",
    "    input_img_data = (input_img_data - 0.5) * 20 + 128.\n",
    "\n",
    "    # Cast random noise from np.float64 to tf.float32 Variable\n",
    "    input_img_data = tf.Variable(tf.cast(input_img_data, tf.float32))\n",
    "    data = [input_img_data, train_y_one_hot[0]]\n",
    "    _, _, conditional_input_img = filter_conditional_input(data)\n",
    "    conditional_input_img= tf.Variable(tf.cast(conditional_input_img,\n",
    "                                         tf.float32))\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = submodel(conditional_input_img)\n",
    "            loss_value = tf.reduce_mean(outputs[:, :, :, filter_index])\n",
    "        grads = tape.gradient(loss_value, conditional_input_img)\n",
    "        normalized_grads = grads / (tf.sqrt(tf.reduce_mean(tf.square(grads)))\n",
    "                                   + 1e-5)\n",
    "        conditional_input_img.assign_add(normalized_grads * step_size)\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    #iterate = K.function([input_img], [loss_value, grads])\n",
    "\n",
    "    if loss_value > 0:\n",
    "        img = conditional_input_img.numpy().astype(np.float64)\n",
    "        img = img.squeeze()\n",
    "        img = deprocess_image(img) / 255.\n",
    "        kept_filters.append((img, loss_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Layer name to inspect\n",
    "layer_name = 'block1_conv1'\n",
    "\n",
    "epochs = 100\n",
    "step_size = 1.\n",
    "filter_index = 1\n",
    "\n",
    "# Create a connection between the input and the target layer\n",
    "submodel = tf.keras.models.Model([model.inputs[0]],\n",
    "                                 [model.get_layer(layer_name).output])\n",
    "submodel.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dimensions of the generated pictures for each filter.\n",
    "img_width = input_shape[0]\n",
    "img_height = input_shape[1]\n",
    "\n",
    "# this is the placeholder for the input images\n",
    "input_img = model.input\n",
    "print(input_img.shape)\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "#layer_dict = dict([(layer.name, layer) for layer in model.layers[0:]])\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "layer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_filters = [layer.name for layer in model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs = 100\n",
    "step_size = 1.\n",
    "kept_filters = []\n",
    "filters_dict = dict()\n",
    "for layer_name in layers_filters:\n",
    "    if 'conv' in layer_name:\n",
    "        layer = model.get_layer(layer_name)\n",
    "        print('Processing filter for layer:', layer_name)\n",
    "        for filter_index in range(min(layer.output.shape[-1], 100)):\n",
    "            # print('Processing filter %d' % filter_index)\n",
    "            build_nth_filter_loss(filter_index, layer_name)\n",
    "        filters_dict[layer.name] = kept_filters\n",
    "        kept_filters = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import save_img\n",
    "\n",
    "def stich_filters(kept_filters, layer_name):\n",
    "    # By default, we will stich the best 64 (n*n) filters on a 8 x 8 grid.\n",
    "    n = int(np.sqrt(len(kept_filters)))\n",
    "    # the filters that have the highest loss are assumed to be better-looking.\n",
    "    # we will only keep the top 64 filters.\n",
    "    kept_filters.sort(key=lambda x: x[1], reverse=True)\n",
    "    kept_filters = kept_filters[:n * n]\n",
    "\n",
    "    # build a black picture with enough space for\n",
    "    # our 8 x 8 filters of size 128 x 128, with a 5px margin in between\n",
    "    margin = 5\n",
    "    width = n * img_width + (n - 1) * margin\n",
    "    height = n * img_height + (n - 1) * margin\n",
    "    stitched_filters = np.zeros((width, height, 3))\n",
    "\n",
    "    # fill the picture with our saved filters\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            img, loss = kept_filters[i * n + j]\n",
    "            width_margin = (img_width + margin) * i\n",
    "            height_margin = (img_height + margin) * j\n",
    "            stitched_filters[\n",
    "                width_margin: width_margin + img_width,\n",
    "                height_margin: height_margin + img_height, :] = img[:, :, :3] \n",
    "\n",
    "    # save the result to disk\n",
    "    save_img(\"reports/\" +directory + '/filters/{}_stitched_filters_{}.png'.format(model.name,\n",
    "             layer_name), stitched_filters)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_name, kept_filters in filters_dict.items():\n",
    "    print('Stiching filters for {}'.format(layer_name))\n",
    "    stich_filters(kept_filters, layer_name)\n",
    "    print('number of filters kept:', len(kept_filters))\n",
    "    print('Completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cvae import CVAE\n",
    "CVAE(cvae_encoder, cvae_decoder, kl_coefficient, input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Report activations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpdf import FPDF\n",
    "import os\n",
    "# create a instance of fpdf\n",
    "pdf = FPDF(format='A4')\n",
    "pdf.set_margins(0., 0.,  0.)\n",
    "pdf.set_auto_page_break(0)\n",
    "# use a folder that you created (here it's imgs)\n",
    "img_list = [x for x in os.listdir(\"reports/\" + directory + \"/activations\")] \n",
    "img_list = sorted(img_list, key=lambda x: int(x.split('_')[1]))\n",
    "# add new pages with the image \n",
    "for img in img_list:\n",
    "    pdf.add_page()\n",
    "    pdf.image(\"reports/\" + directory + \"/activations/\"+img, y=50, w=200, h=200)\n",
    "# save the output file\n",
    "pdf.output(\"reports/\" + directory +\"/report_activations.pdf\")\n",
    "print(\"Adding all your images into a pdf file\")\n",
    "print(\"Images pdf is created and saved it into the following path folder:\\n\",\n",
    "      os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Report filters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a instance of fpdf\n",
    "pdf = FPDF(format='A4')\n",
    "pdf.set_margins(30., 0.,  0.)\n",
    "pdf.set_auto_page_break(0)\n",
    "# use a folder that you created (here it's imgs)\n",
    "img_list = [x for x in os.listdir(\"reports/\" + directory + \"/filters\")] \n",
    "img_list = sorted(img_list)\n",
    "# add new pages with the image \n",
    "for img in img_list:\n",
    "    pdf.add_page()\n",
    "    pdf.image(\"reports/\" + directory + \"/filters/\"+img, y=75, w=150, h=150)\n",
    "# save the output file\n",
    "pdf.output(\"reports/\" + directory +\"/report_filters.pdf\")\n",
    "print(\"Adding all your images into a pdf file\")\n",
    "print(\"Images pdf is created and saved it into the following path folder:\\n\",\n",
    "      os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a instance of fpdf\n",
    "pdf = FPDF(format='A4')\n",
    "pdf.set_margins(0., 0.,  0.)\n",
    "pdf.set_auto_page_break(0)\n",
    "# use a folder that you created (here it's imgs)\n",
    "img_list = [x for x in os.listdir(\"reports/\" + directory )] \n",
    "img_list = sorted(img_list)\n",
    "# add new pages with the image \n",
    "for img in img_list:\n",
    "    if 'png' in img:\n",
    "        pdf.add_page()\n",
    "        pdf.image(\"reports/\" + directory + '/' +img, w=275, h=300)\n",
    "# save the output file\n",
    "pdf.output(\"reports/\" + directory +\"/{}.pdf\".format(directory))\n",
    "print(\"Adding all your images into a pdf file\")\n",
    "print(\"Images pdf is created and saved it into the following path folder:\\n\",\n",
    "      os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0284a593613b942586af6b8f0d4ee916e356aed836174e2f823c929bc6bc05cc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('dis_vae')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
