{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/probability/examples/Probabilistic_Layers_VAE#dependencies_prerequisites\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "input_shape = (50, 50, 3)\n",
    "\n",
    "num_features = 7500#50*50*3\n",
    "latent_dim = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick. Instead of sampling from Q(z|X), \n",
    "    sample eps = N(0,I) z = z_mean + sqrt(var)*eps.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    args: list of Tensors\n",
    "        Mean and log of variance of Q(z|X)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    z: Tensor\n",
    "        Sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    eps = tf.random.normal(tf.shape(z_log_var), dtype=tf.float32, mean=0., stddev=1.0, name='epsilon')\n",
    "    z = z_mean + tf.exp(z_log_var / 2) * eps\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    batch_size = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    eps = K.random_normal(shape=(batch_size, dim), mean=0., stddev=1.0)\n",
    "    z = K.exp(0.5 * z_log_var) * eps + z_mean\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 13:44:20.157767: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.VGG19(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(50, 50, 3),\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_CNN(input_shape = (50, 50, 3), latent_dim = 2):\n",
    "\n",
    "    inputs = layers.Input(shape=input_shape,name='Input')\n",
    "    #block 1\n",
    "    x = base_model.get_layer('block1_conv1')(inputs)\n",
    "    x.trainable=False\n",
    "\n",
    "    x = base_model.get_layer('block1_conv2')(x)\n",
    "    x.trainable=False\n",
    "    x = layers.MaxPool2D(pool_size=2, strides=2,name='S1')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # block 2\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv1')(x)\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv2')(x)\n",
    "    x = layers.MaxPool2D(pool_size=2, strides=2,name='S2')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # block 3\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv1')(x)\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                    activation='relu',\n",
    "                    padding='same',\n",
    "                    name='block3_conv2')(x)\n",
    "    x = layers.MaxPool2D(pool_size=2, strides=2,name='S3')(x)\n",
    "    x = layers.BatchNormalization()(x)  \n",
    "                    \n",
    "    x = layers.Conv2D(filters=3, kernel_size=5,strides=1,padding='same')(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    #x = layers.Dense(25*25*3)(x)\n",
    "    y = layers.Dense(latent_dim * 2)(x)\n",
    "    z_mean = layers.Dense(latent_dim, name='z_mean')(y)\n",
    "    z_log_var = layers.Dense(latent_dim, name='z_log_var')(y)\n",
    "    z = layers.Lambda(sampling, name='z')([z_mean, z_log_var]) #reparametrization trick\n",
    "    model = keras.Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_CNN(input_shape = (50, 50, 3), latent_dim = 2): #best\n",
    "\n",
    "    inputs = layers.Input(shape=input_shape,name='Input')\n",
    "    #block 1\n",
    "    x = base_model.get_layer('block1_conv1')(inputs)\n",
    "    x.trainable=False\n",
    "\n",
    "    x = base_model.get_layer('block1_conv2')(x)\n",
    "    x.trainable=False\n",
    "\n",
    "    # block 2\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv1')(x)\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv2')(x)\n",
    "    x = layers.MaxPool2D(pool_size=2, strides=2,name='S4')(x)\n",
    "    \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    # block 3\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv1')(x)\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                    activation='relu',\n",
    "                    padding='same',\n",
    "                    name='block3_conv2')(x)    \n",
    "                    \n",
    "    y = layers.Conv2D(filters=3, kernel_size=5,strides=1,padding='same')(x)\n",
    "    \n",
    "    z_mean = layers.Dense(3, name='z_mean')(y)\n",
    "    z_log_var = layers.Dense(3, name='z_log_var')(y)\n",
    "    z = layers.Lambda(sampling, name='z')([z_mean, z_log_var]) #reparametrization trick\n",
    "    model = keras.Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input (InputLayer)             [(None, 50, 50, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 50, 50, 64)   1792        ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 50, 50, 64)   36928       ['block1_conv1[3][0]']           \n",
      "                                                                                                  \n",
      " S1 (MaxPooling2D)              (None, 25, 25, 64)   0           ['block1_conv2[3][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 25, 25, 64)  256         ['S1[0][0]']                     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)          (None, 25, 25, 32)   18464       ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)          (None, 25, 25, 32)   9248        ['block2_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " S2 (MaxPooling2D)              (None, 12, 12, 32)   0           ['block2_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 12, 12, 32)  128         ['S2[0][0]']                     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)          (None, 12, 12, 16)   4624        ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)          (None, 12, 12, 16)   2320        ['block3_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " S3 (MaxPooling2D)              (None, 6, 6, 16)     0           ['block3_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 6, 6, 16)    64          ['S3[0][0]']                     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 6, 6, 3)      1203        ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 108)          0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 2000)         218000      ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 1000)         2001000     ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 1000)         2001000     ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " z (Lambda)                     (None, 1000)         0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,295,027\n",
      "Trainable params: 4,256,083\n",
      "Non-trainable params: 38,944\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = encoder_CNN(latent_dim = latent_dim)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_CNN( latent_dim = 2):\n",
    "    latent_inputs = layers.Input(shape=(latent_dim, ), name='z_sampling')\n",
    "    x = layers.Dense(25*25*3)(latent_inputs) # if latent_dim < 25*25*3\n",
    "    x = layers.Reshape(target_shape=(25, 25, 3))(x)\n",
    "\n",
    "    #block 1\n",
    "    x = layers.Conv2DTranspose(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block4_conv1')(x)\n",
    "    x = layers.Conv2DTranspose(16, (3, 3),\n",
    "                    activation='relu',\n",
    "                    padding='same',\n",
    "                    name='up_block4_conv2')(x)  \n",
    "\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # block 2\n",
    "    x = layers.Conv2DTranspose(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block5_conv1')(x)\n",
    "    x = layers.Conv2DTranspose(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block5_conv2')(x)\n",
    "\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.UpSampling2D()(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block6_conv1')(x)\n",
    "\n",
    "                      \n",
    "    outputs = layers.Conv2DTranspose(filters=3, kernel_size=3, strides=1, activation='sigmoid',padding='same')(x) \n",
    "\n",
    "    model = keras.Model(latent_inputs, outputs, name='decoder')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_CNN( latent_dim = 2): #best\n",
    "    latent_inputs = layers.Input(shape=(25, 25, 3), name='z_sampling')\n",
    "\n",
    "    x = layers.Conv2DTranspose(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block4_conv1')(latent_inputs)\n",
    "    x = layers.Conv2DTranspose(16, (3, 3),\n",
    "                    activation='relu',\n",
    "                    padding='same',\n",
    "                    name='up_block4_conv2')(x)  \n",
    "    \n",
    "    # block 2\n",
    "    x = layers.Conv2DTranspose(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block5_conv1')(x)\n",
    "    x = layers.Conv2DTranspose(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block5_conv2')(x)\n",
    "    x = layers.UpSampling2D()(x)\n",
    "    \n",
    "    \n",
    "    x = layers.Conv2DTranspose(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block6_conv1')(x)\n",
    "                      \n",
    "    outputs = layers.Conv2DTranspose(filters=3, kernel_size=3, strides=1, activation='sigmoid',padding='same')(x)\n",
    "   # outputs = layers.Reshape(target_shape=(50, 50, 3), name='output')(x)\n",
    "    model = keras.Model(latent_inputs, outputs, name='decoder')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " z_sampling (InputLayer)     [(None, 1000)]            0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1875)              1876875   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 25, 25, 3)         0         \n",
      "                                                                 \n",
      " up_block4_conv1 (Conv2DTran  (None, 25, 25, 16)       448       \n",
      " spose)                                                          \n",
      "                                                                 \n",
      " up_block4_conv2 (Conv2DTran  (None, 25, 25, 16)       2320      \n",
      " spose)                                                          \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 25, 25, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " up_block5_conv1 (Conv2DTran  (None, 25, 25, 32)       4640      \n",
      " spose)                                                          \n",
      "                                                                 \n",
      " up_block5_conv2 (Conv2DTran  (None, 25, 25, 32)       9248      \n",
      " spose)                                                          \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 25, 25, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 50, 50, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " up_block6_conv1 (Conv2DTran  (None, 50, 50, 64)       18496     \n",
      " spose)                                                          \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 50, 50, 3)        1731      \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,913,950\n",
      "Trainable params: 1,913,854\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder = decoder_CNN( latent_dim = latent_dim)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae(input_shape, latent_dim, encoder, decoder):\n",
    "    vae_input = layers.Input(shape = input_shape, name=\"VAE_input\")\n",
    "\n",
    "    encoder = encoder_CNN(latent_dim = latent_dim)\n",
    " \n",
    "\n",
    "    decoder = decoder_CNN(latent_dim = latent_dim)\n",
    "   \n",
    "\n",
    "    vae = keras.Model(encoder.input, decoder(encoder.output[2]), name='VAE')\n",
    "    return vae, encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae, vae_encoder, vae_decoder = vae(input_shape, latent_dim, encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(vae,show_shapes=True, show_layer_names=True,expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, beta, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.beta = beta\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        #self.beta_coefficient = beta_coefficient\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.encoder(inputs)[2]\n",
    "        return self.decoder(x)\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_sum(\n",
    "                    keras.losses.MSE(data, reconstruction), axis=(1, 2) # mod\n",
    "                )\n",
    "           # )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + (self.beta * kl_loss)\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vae = VAE(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "#vae.save('models/vae.h5')  \n",
    "encoder.save('models/vae_encoder.h5')\n",
    "decoder.save('models/vae_decoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#condtional vae\n",
    "class CVAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(CVAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "    \n",
    "    def conditional_input(self, inputs, image_size=[50,50,3], label_size=2): #inputs should be a 2 dim array\n",
    "        input_img = layers.InputLayer(input_shape=image_size, dtype ='float32')(inputs[0])\n",
    "        input_label = layers.InputLayer(input_shape=(label_size, ), dtype ='float32')(inputs[1])\n",
    "        labels = tf.reshape(inputs[1], [-1, 1, 1, label_size]) #batch_size, 1, 1, label_size\n",
    "        labels = tf.cast(labels, dtype='float32')\n",
    "        ones = tf.ones([inputs[0].shape[0]] + image_size[0:-1] + [label_size]) #batch_size, 50, 50, label_size\n",
    "        labels = ones * labels #batch_size, 50, 50, label_size\n",
    "        conditional_input = layers.Concatenate(axis=3)([input_img, labels]) \n",
    "        return  input_img, input_label, conditional_input\n",
    "\n",
    "\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            conditional_input = self.conditional_input(data)\n",
    "            z_mean, z_log_var, z_cond = self.encoder(conditional_input)\n",
    "            reconstruction = self.decoder(z_cond)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.MeanSquaredError(data, reconstruction), axis=(1, 2, 3) # mod\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_CVAE(labels=(0,1), input_shape = (50, 50, 3),  label_size=2): #best\n",
    "\n",
    "    inputs = layers.Input(shape=(input_shape[0],\n",
    "            input_shape[1], input_shape[2] + label_size), dtype='float32',name='Input')\n",
    "    #inputs = layers.Input(shape = input_shape)\n",
    "    #labels_inputs = layers.Input(shape = (50, 50, 2))\n",
    "    #encoder_inputs = layers.Concatenate()([inputs, labels_inputs])\n",
    "\n",
    "\n",
    "    #block 1\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv1')(inputs)\n",
    "\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv2')(x)\n",
    "    \n",
    "    # block 2\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv1')(x)\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv2')(x)\n",
    "    x = layers.MaxPool2D(pool_size=2, strides=2,name='S4')(x)\n",
    "    \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    # block 3\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv1')(x)\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                activation='relu',\n",
    "                padding='same',\n",
    "                name='block3_conv2')(x)    \n",
    "                    \n",
    "    y = layers.Conv2D(filters=5, kernel_size=5,strides=1,padding='same')(x)\n",
    "    \n",
    "    z_mean = layers.Dense(5, name='z_mean')(y)\n",
    "    z_log_var = layers.Dense(5, name='z_log_var')(y)\n",
    "    z_cond = layers.Lambda(sampling, name='z')([z_mean, z_log_var]) #reparametrization trick\n",
    "    model = keras.Model(inputs, [z_mean, z_log_var, z_cond], name='encoder')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae_encoder = encoder_CVAE()\n",
    "cvae_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_CVAE(latent_shape = (25, 25, 5), condition_count = (None, 2), latent_dim = 2): #best\n",
    "\n",
    "    decoder_inputs = layers.Input(shape=latent_shape , name='decoder_input')\n",
    "    x = layers.Conv2DTranspose(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block4_conv1')(decoder_inputs)\n",
    "    x = layers.Conv2DTranspose(16, (3, 3),\n",
    "                    activation='relu',\n",
    "                    padding='same',\n",
    "                    name='up_block4_conv2')(x)  \n",
    "    \n",
    "    # block 2\n",
    "    x = layers.Conv2DTranspose(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block5_conv1')(x)\n",
    "    x = layers.Conv2DTranspose(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block5_conv2')(x)\n",
    "    x = layers.UpSampling2D()(x)\n",
    "    \n",
    "    \n",
    "    x = layers.Conv2DTranspose(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block6_conv1')(x)\n",
    "                      \n",
    "    outputs = layers.Conv2DTranspose(filters=3, kernel_size=3, strides=1, activation='sigmoid',padding='same')(x)\n",
    "   # outputs = layers.Reshape(target_shape=(50, 50, 3), name='output')(x)\n",
    "    model = keras.Model(decoder_inputs, outputs, name='decoder')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae_decoder = decoder_CVAE()\n",
    "cvae_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vae.save('models/vae.h5')  \n",
    "cvae_encoder.save('models/cvae_encoder.h5')\n",
    "cvae_decoder.save('models/cvae_decoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_input( inputs, image_size=[50,50,3], label_size=2): #inputs should be a 2 dim array\n",
    "    input_img = layers.InputLayer(input_shape=image_size, dtype ='float32')(inputs[0])\n",
    "    input_label = layers.InputLayer(input_shape=(label_size, ), dtype ='float32')(inputs[1])\n",
    "    labels = tf.reshape(inputs[1], [-1, 1, 1, label_size]) #batch_size, 1, 1, label_size\n",
    "    labels = tf.cast(labels, dtype='float32')\n",
    "    ones = tf.ones([inputs[0].shape[0]] + image_size[0:-1] + [label_size]) #batch_size, 50, 50, label_size\n",
    "    labels = ones * labels #batch_size, 50, 50, label_size\n",
    "    conditional_input = layers.Concatenate(axis=3)([input_img, labels]) \n",
    "    return  input_img, input_label, labels, conditional_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_labels(labels, batch_size=10, target_size = [10, 25, 25, 3]):\n",
    "\n",
    "    labels = tf.reshape(inputs[1], [-1, 1, 1, label_size]) #batch_size, 1, 1, label_size\n",
    "    labels = tf.cast(labels, dtype='float32')\n",
    "    labels = tf.cast(labels, dtype='float32')\n",
    "    ones = tf.ones([target_size.shape[0]] + target_size[0:-1] + [label_size]) #batch_size, 50, 50, label_size\n",
    "    labels = ones * labels #batch_size, 50, 50, label_size\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs0 = tf.random.normal(shape=(10, 50, 50 ,3))\n",
    "inputs1 = (0, 1)\n",
    "inputs = [inputs0, inputs1]\n",
    "label_size = 2\n",
    "image_size = [50, 50, 3]\n",
    "_, _, labels, _ = conditional_input(inputs)\n",
    "\n",
    "labels.shape\n",
    "reshape_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0284a593613b942586af6b8f0d4ee916e356aed836174e2f823c929bc6bc05cc"
  },
  "kernelspec": {
   "display_name": "dis_vae",
   "language": "python",
   "name": "dis_vae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
