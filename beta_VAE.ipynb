{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/probability/examples/Probabilistic_Layers_VAE#dependencies_prerequisites\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "input_shape = (50, 50, 3)\n",
    "num_features = 7500#50*50*3\n",
    "latent_dim = 25*25*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick. Instead of sampling from Q(z|X), \n",
    "    sample eps = N(0,I) z = z_mean + sqrt(var)*eps.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    args: list of Tensors\n",
    "        Mean and log of variance of Q(z|X)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    z: Tensor\n",
    "        Sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    eps = tf.random.normal(tf.shape(z_log_var), dtype=tf.float32, mean=0., stddev=1.0, name='epsilon')\n",
    "    z = z_mean + tf.exp(z_log_var / 2) * eps\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.VGG19(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(50, 50, 3),\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_CNN(input_shape = (50, 50, 3), latent_dim = 2):\n",
    "\n",
    "    inputs = layers.Input(shape=input_shape,name='Input')\n",
    "    #block 1\n",
    "    x = base_model.get_layer('block1_conv1')(inputs)\n",
    "    x.trainable=False\n",
    "\n",
    "    x = base_model.get_layer('block1_conv2')(x)\n",
    "    x.trainable=False\n",
    "\n",
    "    # block 2\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv1')(x)\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv2')(x)\n",
    "    x = layers.MaxPool2D(pool_size=2, strides=2,name='S4')(x)\n",
    "    \n",
    "\n",
    "    # block 3\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv1')(x)\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                    activation='relu',\n",
    "                    padding='same',\n",
    "                    name='block3_conv2')(x)    \n",
    "                    \n",
    "    x = layers.Conv2D(filters=3, kernel_size=5,strides=1,padding='same',name='output')(x)\n",
    "    \n",
    "    y = layers.Flatten()(x)\n",
    "    #y = layers.Dense(latent_dim, activation ='relu',name='dense_layer')(x)\n",
    "    z_mean = layers.Dense(latent_dim, name='z_mean')(y)\n",
    "    z_log_var = layers.Dense(latent_dim, name='z_log_var')(y)\n",
    "    z = layers.Lambda(sampling, name='z')([z_mean, z_log_var]) #reparametrization trick\n",
    "    model = keras.Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input (InputLayer)             [(None, 50, 50, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 50, 50, 64)   1792        ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 50, 50, 64)   36928       ['block1_conv1[11][0]']          \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)          (None, 50, 50, 32)   18464       ['block1_conv2[11][0]']          \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)          (None, 50, 50, 32)   9248        ['block2_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " S4 (MaxPooling2D)              (None, 25, 25, 32)   0           ['block2_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)          (None, 25, 25, 16)   4624        ['S4[0][0]']                     \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)          (None, 25, 25, 16)   2320        ['block3_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " output (Conv2D)                (None, 25, 25, 3)    1203        ['block3_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 1875)         0           ['output[0][0]']                 \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 1875)         3517500     ['flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 1875)         3517500     ['flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      " z (Lambda)                     (None, 1875)         0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,109,579\n",
      "Trainable params: 7,070,859\n",
      "Non-trainable params: 38,720\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = encoder_CNN(latent_dim = latent_dim)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_CNN( latent_dim = 2):\n",
    "    latent_inputs = layers.Input(shape=(latent_dim,), name='z_sampling')\n",
    "    x = layers.Reshape(target_shape=(25, 25, 3))(latent_inputs)\n",
    "    x = layers.Conv2DTranspose(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block4_conv1')(x)\n",
    "    x = layers.Conv2DTranspose(16, (3, 3),\n",
    "                    activation='relu',\n",
    "                    padding='same',\n",
    "                    name='up_block4_conv2')(x)  \n",
    "\n",
    "    # block 2\n",
    "    x = layers.Conv2DTranspose(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block5_conv1')(x)\n",
    "    x = layers.Conv2DTranspose(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block5_conv2')(x)\n",
    "    x = layers.UpSampling2D()(x)\n",
    "    \n",
    "    \n",
    "    x = layers.Conv2DTranspose(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block6_conv1')(x)\n",
    "                      \n",
    "    outputs = layers.Conv2DTranspose(filters=3, kernel_size=3, strides=1, activation='relu',padding='same')(x)\n",
    "   # outputs = layers.Reshape(target_shape=(50, 50, 3), name='output')(x)\n",
    "    model = keras.Model(latent_inputs, outputs, name='decoder')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " z_sampling (InputLayer)     [(None, 1875)]            0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 25, 25, 3)         0         \n",
      "                                                                 \n",
      " up_block4_conv1 (Conv2DTran  (None, 25, 25, 16)       448       \n",
      " spose)                                                          \n",
      "                                                                 \n",
      " up_block4_conv2 (Conv2DTran  (None, 25, 25, 16)       2320      \n",
      " spose)                                                          \n",
      "                                                                 \n",
      " up_block5_conv1 (Conv2DTran  (None, 25, 25, 32)       4640      \n",
      " spose)                                                          \n",
      "                                                                 \n",
      " up_block5_conv2 (Conv2DTran  (None, 25, 25, 32)       9248      \n",
      " spose)                                                          \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 50, 50, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " up_block6_conv1 (Conv2DTran  (None, 50, 50, 64)       18496     \n",
      " spose)                                                          \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 50, 50, 3)        1731      \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,883\n",
      "Trainable params: 36,883\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder = decoder_CNN(latent_dim = latent_dim)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VAE(input_shape, latent_dim, encoder, decoder):\n",
    "    vae_input = layers.Input(shape = input_shape, name=\"VAE_input\")\n",
    "\n",
    "    encoder = encoder_CNN(latent_dim = latent_dim)\n",
    " \n",
    "\n",
    "    decoder = decoder_CNN(latent_dim = latent_dim)\n",
    "   \n",
    "\n",
    "    vae = keras.Model(encoder.input, decoder(encoder.output), name='VAE')\n",
    "    return vae, encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae, vae_encoder, vae_decoder = VAE(input_shape, latent_dim, encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VAE\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input (InputLayer)             [(None, 50, 50, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 50, 50, 64)   1792        ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 50, 50, 64)   36928       ['block1_conv1[12][0]']          \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)          (None, 50, 50, 32)   18464       ['block1_conv2[12][0]']          \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)          (None, 50, 50, 32)   9248        ['block2_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " S4 (MaxPooling2D)              (None, 25, 25, 32)   0           ['block2_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)          (None, 25, 25, 16)   4624        ['S4[0][0]']                     \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)          (None, 25, 25, 16)   2320        ['block3_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " output (Conv2D)                (None, 25, 25, 3)    1203        ['block3_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)            (None, 1875)         0           ['output[0][0]']                 \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 1875)         3517500     ['flatten_6[0][0]']              \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 1875)         3517500     ['flatten_6[0][0]']              \n",
      "                                                                                                  \n",
      " z (Lambda)                     (None, 1875)         0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, 50, 50, 3)    36883       ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]',              \n",
      "                                                                  'z[0][0]']                      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,146,462\n",
      "Trainable params: 7,107,742\n",
      "Non-trainable params: 38,720\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(vae,show_shapes=True, show_layer_names=True,expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(encoder_mu, encoder_log_variance, beta_coefficient):\n",
    "\n",
    "    def vae_reconstruction_loss(y_true, y_predict):\n",
    "        reconstruction_loss_factor = 1\n",
    "        reconstruction_loss = K.mean(K.square(y_true - y_predict), axis=[1, 2, 3])\n",
    "        return reconstruction_loss_factor * reconstruction_loss\n",
    "\n",
    "    def vae_kl_loss(encoder_mu, encoder_log_variance):\n",
    "        kl_loss = -0.5 * K.sum(1.0 + encoder_log_variance - K.square(encoder_mu) - K.exp(encoder_log_variance), axis=[1, 2, 3])\n",
    "        return kl_loss\n",
    "\n",
    "    def vae_kl_loss_metric(y_true, y_predict):\n",
    "        kl_loss = -0.5 * K.backend.sum(1.0 + encoder_log_variance - K.square(encoder_mu) - K.exp(encoder_log_variance), axis=[1, 2, 3])\n",
    "        return kl_loss\n",
    "\n",
    "    def vae_loss(y_true, y_predict, beta_coefficient):\n",
    "        reconstruction_loss = vae_reconstruction_loss(y_true, y_predict)\n",
    "        kl_loss = vae_kl_loss(y_true, y_predict)\n",
    "\n",
    "        loss = reconstruction_loss + beta_coefficient * kl_loss\n",
    "        return loss\n",
    "\n",
    "    return vae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_coefficient=1\n",
    "\n",
    "#Information needed to compute the loss function\n",
    "vae_input = vae.input\n",
    "vae_output = vae.output\n",
    "mu = encoder.get_layer('z_mean').output\n",
    "log_var= encoder.get_layer('z_log_var').output\n",
    "\n",
    "vae.add_loss(vae_loss( mu, log_var, beta_coefficient))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "vae.save('models/vae.h5')  \n",
    "encoder.save('models/encoder.h5')\n",
    "decoder.save('models/decoder.h5')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0284a593613b942586af6b8f0d4ee916e356aed836174e2f823c929bc6bc05cc"
  },
  "kernelspec": {
   "display_name": "dis_vae",
   "language": "python",
   "name": "dis_vae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
