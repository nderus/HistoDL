{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/probability/examples/Probabilistic_Layers_VAE#dependencies_prerequisites\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "input_shape = (50, 50, 3)\n",
    "num_features = 7500#50*50*3\n",
    "latent_dim = 25*25*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick. Instead of sampling from Q(z|X), \n",
    "    sample eps = N(0,I) z = z_mean + sqrt(var)*eps.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    args: list of Tensors\n",
    "        Mean and log of variance of Q(z|X)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    z: Tensor\n",
    "        Sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    eps = tf.random.normal(tf.shape(z_log_var), dtype=tf.float32, mean=0., stddev=1.0, name='epsilon')\n",
    "    z = z_mean + tf.exp(z_log_var / 2) * eps\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-14 09:35:21.451381: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.VGG19(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(50, 50, 3),\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_CNN(input_shape = (50, 50, 3), latent_dim = 2):\n",
    "\n",
    "    inputs = layers.Input(shape=input_shape,name='Input')\n",
    "    #block 1\n",
    "    x = base_model.get_layer('block1_conv1')(inputs)\n",
    "    x.trainable=False\n",
    "\n",
    "    x = base_model.get_layer('block1_conv2')(x)\n",
    "    x.trainable=False\n",
    "\n",
    "    # block 2\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv1')(x)\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv2')(x)\n",
    "    x = layers.MaxPool2D(pool_size=2, strides=2,name='S4')(x)\n",
    "    \n",
    "\n",
    "    # block 3\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv1')(x)\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                    activation='relu',\n",
    "                    padding='same',\n",
    "                    name='block3_conv2')(x)    \n",
    "                    \n",
    "    x = layers.Conv2D(filters=3, kernel_size=5,strides=1,padding='same')(x)\n",
    "    \n",
    "    y = layers.Flatten()(x)\n",
    "    z_mean = layers.Dense(latent_dim, name='z_mean')(y)\n",
    "    z_log_var = layers.Dense(latent_dim, name='z_log_var')(y)\n",
    "    z = layers.Lambda(sampling, name='z')([z_mean, z_log_var]) #reparametrization trick\n",
    "    model = keras.Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input (InputLayer)             [(None, 50, 50, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 50, 50, 64)   1792        ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 50, 50, 64)   36928       ['block1_conv1[1][0]']           \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)          (None, 50, 50, 32)   18464       ['block1_conv2[1][0]']           \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)          (None, 50, 50, 32)   9248        ['block2_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " S4 (MaxPooling2D)              (None, 25, 25, 32)   0           ['block2_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)          (None, 25, 25, 16)   4624        ['S4[0][0]']                     \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)          (None, 25, 25, 16)   2320        ['block3_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 25, 25, 3)    1203        ['block3_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1875)         0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 1875)         3517500     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 1875)         3517500     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " z (Lambda)                     (None, 1875)         0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,109,579\n",
      "Trainable params: 7,070,859\n",
      "Non-trainable params: 38,720\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = encoder_CNN(latent_dim = latent_dim)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_CNN( latent_dim = 2):\n",
    "    latent_inputs = layers.Input(shape=(latent_dim,), name='z_sampling')\n",
    "    x = layers.Reshape(target_shape=(25, 25, 3))(latent_inputs)\n",
    "    x = layers.Conv2DTranspose(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block4_conv1')(x)\n",
    "    x = layers.Conv2DTranspose(16, (3, 3),\n",
    "                    activation='relu',\n",
    "                    padding='same',\n",
    "                    name='up_block4_conv2')(x)  \n",
    "\n",
    "    # block 2\n",
    "    x = layers.Conv2DTranspose(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block5_conv1')(x)\n",
    "    x = layers.Conv2DTranspose(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block5_conv2')(x)\n",
    "    x = layers.UpSampling2D()(x)\n",
    "    \n",
    "    \n",
    "    x = layers.Conv2DTranspose(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block6_conv1')(x)\n",
    "                      \n",
    "    outputs = layers.Conv2DTranspose(filters=3, kernel_size=3, strides=1, activation='relu',padding='same')(x)\n",
    "   # outputs = layers.Reshape(target_shape=(50, 50, 3), name='output')(x)\n",
    "    model = keras.Model(latent_inputs, outputs, name='decoder')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_CNN( latent_dim = 2):\n",
    "    latent_inputs = layers.Input(shape=(latent_dim, ), name='z_sampling')\n",
    "    x = layers.Reshape(target_shape=(25, 25, 3))(latent_inputs)\n",
    "    x = layers.Conv2DTranspose(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block4_conv1')(x)\n",
    "    x = layers.Conv2DTranspose(16, (3, 3),\n",
    "                    activation='relu',\n",
    "                    padding='same',\n",
    "                    name='up_block4_conv2')(x)  \n",
    "\n",
    "    # block 2\n",
    "    x = layers.Conv2DTranspose(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block5_conv1')(x)\n",
    "    x = layers.Conv2DTranspose(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block5_conv2')(x)\n",
    "    x = layers.UpSampling2D()(x)\n",
    "    \n",
    "    \n",
    "    x = layers.Conv2DTranspose(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block6_conv1')(x)\n",
    "                      \n",
    "    outputs = layers.Conv2DTranspose(filters=3, kernel_size=3, strides=1, activation='relu',padding='same')(x)\n",
    "   # outputs = layers.Reshape(target_shape=(50, 50, 3), name='output')(x)\n",
    "    model = keras.Model(latent_inputs, outputs, name='decoder')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " z_sampling (InputLayer)     [(None, 1875)]            0         \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 25, 25, 3)         0         \n",
      "                                                                 \n",
      " up_block4_conv1 (Conv2DTran  (None, 25, 25, 16)       448       \n",
      " spose)                                                          \n",
      "                                                                 \n",
      " up_block4_conv2 (Conv2DTran  (None, 25, 25, 16)       2320      \n",
      " spose)                                                          \n",
      "                                                                 \n",
      " up_block5_conv1 (Conv2DTran  (None, 25, 25, 32)       4640      \n",
      " spose)                                                          \n",
      "                                                                 \n",
      " up_block5_conv2 (Conv2DTran  (None, 25, 25, 32)       9248      \n",
      " spose)                                                          \n",
      "                                                                 \n",
      " up_sampling2d_4 (UpSampling  (None, 50, 50, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " up_block6_conv1 (Conv2DTran  (None, 50, 50, 64)       18496     \n",
      " spose)                                                          \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 50, 50, 3)        1731      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,883\n",
      "Trainable params: 36,883\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder = decoder_CNN(latent_dim = latent_dim)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae(input_shape, latent_dim, encoder, decoder):\n",
    "    vae_input = layers.Input(shape = input_shape, name=\"VAE_input\")\n",
    "\n",
    "    encoder = encoder_CNN(latent_dim = latent_dim)\n",
    " \n",
    "\n",
    "    decoder = decoder_CNN(latent_dim = latent_dim)\n",
    "   \n",
    "\n",
    "    vae = keras.Model(encoder.input, decoder(encoder.output[2]), name='VAE')\n",
    "    return vae, encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 25, 25, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 25, 25, 3), dtype=tf.float32, name='z_sampling'), name='z_sampling', description=\"created by layer 'z_sampling'\"), but it was called on an input with incompatible shape (None, 1875).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"decoder\" (type Functional).\n\nInput 0 of layer \"up_block4_conv1\" is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: (None, 1875)\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 1875), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/PERSONALE/nicolas.derus2/HistoDL/beta_VAE.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoDL/beta_VAE.ipynb#ch0000009vscode-remote?line=0'>1</a>\u001b[0m vae, vae_encoder, vae_decoder \u001b[39m=\u001b[39m vae(input_shape, latent_dim, encoder, decoder)\n",
      "\u001b[1;32m/home/PERSONALE/nicolas.derus2/HistoDL/beta_VAE.ipynb Cell 10'\u001b[0m in \u001b[0;36mvae\u001b[0;34m(input_shape, latent_dim, encoder, decoder)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoDL/beta_VAE.ipynb#ch0000008vscode-remote?line=3'>4</a>\u001b[0m encoder \u001b[39m=\u001b[39m encoder_CNN(latent_dim \u001b[39m=\u001b[39m latent_dim)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoDL/beta_VAE.ipynb#ch0000008vscode-remote?line=6'>7</a>\u001b[0m decoder \u001b[39m=\u001b[39m decoder_CNN(latent_dim \u001b[39m=\u001b[39m latent_dim)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoDL/beta_VAE.ipynb#ch0000008vscode-remote?line=9'>10</a>\u001b[0m vae \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mModel(encoder\u001b[39m.\u001b[39minput, decoder(encoder\u001b[39m.\u001b[39;49moutput[\u001b[39m2\u001b[39;49m]), name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mVAE\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoDL/beta_VAE.ipynb#ch0000008vscode-remote?line=10'>11</a>\u001b[0m \u001b[39mreturn\u001b[39;00m vae, encoder, decoder\n",
      "File \u001b[0;32m~/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/PERSONALE/nicolas.derus2/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/PERSONALE/nicolas.derus2/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> <a href='file:///home/PERSONALE/nicolas.derus2/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     <a href='file:///home/PERSONALE/nicolas.derus2/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/PERSONALE/nicolas.derus2/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/engine/input_spec.py:213\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    <a href='file:///home/PERSONALE/nicolas.derus2/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/engine/input_spec.py?line=210'>211</a>\u001b[0m   ndim \u001b[39m=\u001b[39m shape\u001b[39m.\u001b[39mrank\n\u001b[1;32m    <a href='file:///home/PERSONALE/nicolas.derus2/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/engine/input_spec.py?line=211'>212</a>\u001b[0m   \u001b[39mif\u001b[39;00m ndim \u001b[39m!=\u001b[39m spec\u001b[39m.\u001b[39mndim:\n\u001b[0;32m--> <a href='file:///home/PERSONALE/nicolas.derus2/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/engine/input_spec.py?line=212'>213</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///home/PERSONALE/nicolas.derus2/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/engine/input_spec.py?line=213'>214</a>\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mis incompatible with the layer: \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///home/PERSONALE/nicolas.derus2/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/engine/input_spec.py?line=214'>215</a>\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mexpected ndim=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mndim\u001b[39m}\u001b[39;00m\u001b[39m, found ndim=\u001b[39m\u001b[39m{\u001b[39;00mndim\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///home/PERSONALE/nicolas.derus2/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/engine/input_spec.py?line=215'>216</a>\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFull shape received: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(shape)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='file:///home/PERSONALE/nicolas.derus2/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/engine/input_spec.py?line=216'>217</a>\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mmax_ndim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/PERSONALE/nicolas.derus2/miniconda3/envs/dis_vae/lib/python3.9/site-packages/keras/engine/input_spec.py?line=217'>218</a>\u001b[0m   ndim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"decoder\" (type Functional).\n\nInput 0 of layer \"up_block4_conv1\" is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: (None, 1875)\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 1875), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "vae, vae_encoder, vae_decoder = vae(input_shape, latent_dim, encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(vae,show_shapes=True, show_layer_names=True,expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(encoder_mu, encoder_log_variance, beta_coefficient):\n",
    "\n",
    "    def vae_reconstruction_loss(y_true, y_predict):\n",
    "        reconstruction_loss_factor = 1\n",
    "        reconstruction_loss = K.mean(K.square(y_true - y_predict), axis=[1, 2, 3])\n",
    "        return reconstruction_loss_factor * reconstruction_loss\n",
    "\n",
    "    def vae_kl_loss(encoder_mu, encoder_log_variance):\n",
    "        kl_loss = -0.5 * K.sum(1.0 + encoder_log_variance - K.square(encoder_mu) - K.exp(encoder_log_variance), axis=[1, 2, 3])\n",
    "        return kl_loss\n",
    "\n",
    "    def vae_kl_loss_metric(y_true, y_predict):\n",
    "        kl_loss = -0.5 * K.backend.sum(1.0 + encoder_log_variance - K.square(encoder_mu) - K.exp(encoder_log_variance), axis=[1, 2, 3])\n",
    "        return kl_loss\n",
    "\n",
    "    def vae_loss(y_true, y_predict, beta_coefficient):\n",
    "        reconstruction_loss = vae_reconstruction_loss(y_true, y_predict)\n",
    "        kl_loss = vae_kl_loss(y_true, y_predict)\n",
    "\n",
    "        loss = reconstruction_loss + beta_coefficient * kl_loss\n",
    "        return loss\n",
    "\n",
    "    return vae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_coefficient=1\n",
    "\n",
    "#Information needed to compute the loss function\n",
    "vae_input = vae.input\n",
    "vae_output = vae.output\n",
    "mu = encoder.get_layer('z_mean').output\n",
    "log_var= encoder.get_layer('z_log_var').output\n",
    "\n",
    "vae.add_loss(vae_loss( mu, log_var, beta_coefficient))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "#vae.save('models/vae.h5')  \n",
    "encoder.save('models/vae_encoder.h5')\n",
    "decoder.save('models/vae_decoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.MeanSquaredError(data, reconstruction), axis=(1, 2, 3) # mod\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer=keras.optimizers.Adam())\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0284a593613b942586af6b8f0d4ee916e356aed836174e2f823c929bc6bc05cc"
  },
  "kernelspec": {
   "display_name": "dis_vae",
   "language": "python",
   "name": "dis_vae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
