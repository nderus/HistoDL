{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/probability/examples/Probabilistic_Layers_VAE#dependencies_prerequisites\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "input_shape = (50, 50, 3)\n",
    "num_features = 7500#50*50*3\n",
    "latent_dim = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick. Instead of sampling from Q(z|X), \n",
    "    sample eps = N(0,I) z = z_mean + sqrt(var)*eps.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    args: list of Tensors\n",
    "        Mean and log of variance of Q(z|X)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    z: Tensor\n",
    "        Sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    eps = tf.random.normal(tf.shape(z_log_var), dtype=tf.float32, mean=0., stddev=1.0, name='epsilon')\n",
    "    z = z_mean + tf.exp(z_log_var / 2) * eps\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.VGG19(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(50, 50, 3),\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_CNN(input_shape = (50, 50, 3), latent_dim = 2):\n",
    "\n",
    "    inputs = layers.Input(shape=input_shape,name='Input')\n",
    "    #block 1\n",
    "    x = base_model.get_layer('block1_conv1')(inputs)\n",
    "    x.trainable=False\n",
    "\n",
    "    x = base_model.get_layer('block1_conv2')(x)\n",
    "    x.trainable=False\n",
    "\n",
    "    # block 2\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv1')(x)\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv2')(x)\n",
    "    x = layers.MaxPool2D(pool_size=2, strides=2,name='S4')(x)\n",
    "    \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    # block 3\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv1')(x)\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                    activation='relu',\n",
    "                    padding='same',\n",
    "                    name='block3_conv2')(x)    \n",
    "                    \n",
    "    x = layers.Conv2D(filters=3, kernel_size=5,strides=1,padding='same')(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    y = layers.Dense(latent_dim * 2)(x)\n",
    "    z_mean = layers.Dense(latent_dim, name='z_mean')(y)\n",
    "    z_log_var = layers.Dense(latent_dim, name='z_log_var')(y)\n",
    "    z = layers.Lambda(sampling, name='z')([z_mean, z_log_var]) #reparametrization trick\n",
    "    model = keras.Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_CNN(input_shape = (50, 50, 3), latent_dim = 2): #best\n",
    "\n",
    "    inputs = layers.Input(shape=input_shape,name='Input')\n",
    "    #block 1\n",
    "    x = base_model.get_layer('block1_conv1')(inputs)\n",
    "    x.trainable=False\n",
    "\n",
    "    x = base_model.get_layer('block1_conv2')(x)\n",
    "    x.trainable=False\n",
    "\n",
    "    # block 2\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv1')(x)\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv2')(x)\n",
    "    x = layers.MaxPool2D(pool_size=2, strides=2,name='S4')(x)\n",
    "    \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    # block 3\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv1')(x)\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                    activation='relu',\n",
    "                    padding='same',\n",
    "                    name='block3_conv2')(x)    \n",
    "                    \n",
    "    y = layers.Conv2D(filters=3, kernel_size=5,strides=1,padding='same')(x)\n",
    "    \n",
    "    z_mean = layers.Dense(3, name='z_mean')(y)\n",
    "    z_log_var = layers.Dense(3, name='z_log_var')(y)\n",
    "    z = layers.Lambda(sampling, name='z')([z_mean, z_log_var]) #reparametrization trick\n",
    "    model = keras.Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = encoder_CNN(latent_dim = latent_dim)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_CNN( latent_dim = 2):\n",
    "    latent_inputs = layers.Input(shape=(latent_dim, ), name='z_sampling')\n",
    "    x = layers.Dense(25*25*3)(latent_inputs) # if latent_dim < 25*25*3\n",
    "    x = layers.Reshape(target_shape=(25, 25, 3))(x)\n",
    "    x = layers.Conv2DTranspose(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block4_conv1')(x)\n",
    "    x = layers.Conv2DTranspose(16, (3, 3),\n",
    "                    activation='relu',\n",
    "                    padding='same',\n",
    "                    name='up_block4_conv2')(x)  \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    # block 2\n",
    "    x = layers.Conv2DTranspose(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block5_conv1')(x)\n",
    "    x = layers.Conv2DTranspose(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block5_conv2')(x)\n",
    " \n",
    "    x = layers.UpSampling2D()(x)\n",
    "    \n",
    "    \n",
    "    x = layers.Conv2DTranspose(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block6_conv1')(x)\n",
    "                      \n",
    "    outputs = layers.Conv2DTranspose(filters=3, kernel_size=3, strides=1, activation='softmax',padding='same')(x)\n",
    "   # outputs = layers.Reshape(target_shape=(50, 50, 3), name='output')(x)\n",
    "    model = keras.Model(latent_inputs, outputs, name='decoder')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_CNN( latent_dim = 2): #best\n",
    "    latent_inputs = layers.Input(shape=(25, 25, 3), name='z_sampling')\n",
    "\n",
    "    x = layers.Conv2DTranspose(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block4_conv1')(latent_inputs)\n",
    "    x = layers.Conv2DTranspose(16, (3, 3),\n",
    "                    activation='relu',\n",
    "                    padding='same',\n",
    "                    name='up_block4_conv2')(x)  \n",
    "    \n",
    "    # block 2\n",
    "    x = layers.Conv2DTranspose(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block5_conv1')(x)\n",
    "    x = layers.Conv2DTranspose(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block5_conv2')(x)\n",
    "    x = layers.UpSampling2D()(x)\n",
    "    \n",
    "    \n",
    "    x = layers.Conv2DTranspose(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block6_conv1')(x)\n",
    "                      \n",
    "    outputs = layers.Conv2DTranspose(filters=3, kernel_size=3, strides=1, activation='sigmoid',padding='same')(x)\n",
    "   # outputs = layers.Reshape(target_shape=(50, 50, 3), name='output')(x)\n",
    "    model = keras.Model(latent_inputs, outputs, name='decoder')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = decoder_CNN(latent_dim = latent_dim)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae(input_shape, latent_dim, encoder, decoder):\n",
    "    vae_input = layers.Input(shape = input_shape, name=\"VAE_input\")\n",
    "\n",
    "    encoder = encoder_CNN(latent_dim = latent_dim)\n",
    " \n",
    "\n",
    "    decoder = decoder_CNN(latent_dim = latent_dim)\n",
    "   \n",
    "\n",
    "    vae = keras.Model(encoder.input, decoder(encoder.output[2]), name='VAE')\n",
    "    return vae, encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae, vae_encoder, vae_decoder = vae(input_shape, latent_dim, encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(vae,show_shapes=True, show_layer_names=True,expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, beta, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.beta = beta\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        #self.beta_coefficient = beta_coefficient\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.encoder(inputs)[2]\n",
    "        return self.decoder(x)\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_sum(\n",
    "                    keras.losses.MSE(data, reconstruction), axis=(1, 2) # mod\n",
    "                )\n",
    "           # )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + (self.beta * kl_loss)\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vae = VAE(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vae.save('models/vae.h5')  \n",
    "encoder.save('models/vae_encoder.h5')\n",
    "decoder.save('models/vae_decoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#condtional vae\n",
    "class CVAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(CVAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "    \n",
    "    def conditional_input(self, inputs, image_size=[50,50,3], label_size=2): #inputs should be a 2 dim array\n",
    "        input_img = layers.InputLayer(input_shape=image_size, dtype ='float32')(inputs[0])\n",
    "        input_label = layers.InputLayer(input_shape=(label_size, ), dtype ='float32')(inputs[1])\n",
    "        labels = tf.reshape(inputs[1], [-1, 1, 1, label_size]) #batch_size, 1, 1, label_size\n",
    "        labels = tf.cast(labels, dtype='float32')\n",
    "        ones = tf.ones([inputs[0].shape[0]] + image_size[0:-1] + [label_size]) #batch_size, 50, 50, label_size\n",
    "        labels = ones * labels #batch_size, 50, 50, label_size\n",
    "        conditional_input = layers.Concatenate(axis=3)([input_img, labels]) \n",
    "        return  input_img, input_label, conditional_input\n",
    "\n",
    "\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            conditional_input = self.conditional_input(data)\n",
    "            z_mean, z_log_var, z_cond = self.encoder(conditional_input)\n",
    "            reconstruction = self.decoder(z_cond)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.MeanSquaredError(data, reconstruction), axis=(1, 2, 3) # mod\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_CVAE(labels=(0,1), input_shape = (50, 50, 3),  label_size=2): #best\n",
    "\n",
    "    inputs = layers.Input(shape=(input_shape[0],\n",
    "            input_shape[1], input_shape[2] + label_size), dtype='float32',name='Input')\n",
    "    #inputs = layers.Input(shape = input_shape)\n",
    "    #labels_inputs = layers.Input(shape = (50, 50, 2))\n",
    "    #encoder_inputs = layers.Concatenate()([inputs, labels_inputs])\n",
    "\n",
    "\n",
    "    #block 1\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv1')(inputs)\n",
    "\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv2')(x)\n",
    "    \n",
    "    # block 2\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv1')(x)\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv2')(x)\n",
    "    x = layers.MaxPool2D(pool_size=2, strides=2,name='S4')(x)\n",
    "    \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    # block 3\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv1')(x)\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                activation='relu',\n",
    "                padding='same',\n",
    "                name='block3_conv2')(x)    \n",
    "                    \n",
    "    y = layers.Conv2D(filters=5, kernel_size=5,strides=1,padding='same')(x)\n",
    "    \n",
    "    z_mean = layers.Dense(5, name='z_mean')(y)\n",
    "    z_log_var = layers.Dense(5, name='z_log_var')(y)\n",
    "    z_cond = layers.Lambda(sampling, name='z')([z_mean, z_log_var]) #reparametrization trick\n",
    "    model = keras.Model(inputs, [z_mean, z_log_var, z_cond], name='encoder')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae_encoder = encoder_CVAE()\n",
    "cvae_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_CVAE(latent_shape = (25, 25, 5), condition_count = (None, 2), latent_dim = 2): #best\n",
    "\n",
    "    decoder_inputs = layers.Input(shape=latent_shape , name='decoder_input')\n",
    "    x = layers.Conv2DTranspose(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block4_conv1')(decoder_inputs)\n",
    "    x = layers.Conv2DTranspose(16, (3, 3),\n",
    "                    activation='relu',\n",
    "                    padding='same',\n",
    "                    name='up_block4_conv2')(x)  \n",
    "    \n",
    "    # block 2\n",
    "    x = layers.Conv2DTranspose(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block5_conv1')(x)\n",
    "    x = layers.Conv2DTranspose(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block5_conv2')(x)\n",
    "    x = layers.UpSampling2D()(x)\n",
    "    \n",
    "    \n",
    "    x = layers.Conv2DTranspose(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block6_conv1')(x)\n",
    "                      \n",
    "    outputs = layers.Conv2DTranspose(filters=3, kernel_size=3, strides=1, activation='sigmoid',padding='same')(x)\n",
    "   # outputs = layers.Reshape(target_shape=(50, 50, 3), name='output')(x)\n",
    "    model = keras.Model(decoder_inputs, outputs, name='decoder')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae_decoder = decoder_CVAE()\n",
    "cvae_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "#vae.save('models/vae.h5')  \n",
    "cvae_encoder.save('models/cvae_encoder.h5')\n",
    "cvae_decoder.save('models/cvae_decoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_input( inputs, image_size=[50,50,3], label_size=2): #inputs should be a 2 dim array\n",
    "    input_img = layers.InputLayer(input_shape=image_size, dtype ='float32')(inputs[0])\n",
    "    input_label = layers.InputLayer(input_shape=(label_size, ), dtype ='float32')(inputs[1])\n",
    "    labels = tf.reshape(inputs[1], [-1, 1, 1, label_size]) #batch_size, 1, 1, label_size\n",
    "    labels = tf.cast(labels, dtype='float32')\n",
    "    ones = tf.ones([inputs[0].shape[0]] + image_size[0:-1] + [label_size]) #batch_size, 50, 50, label_size\n",
    "    labels = ones * labels #batch_size, 50, 50, label_size\n",
    "    conditional_input = layers.Concatenate(axis=3)([input_img, labels]) \n",
    "    return  input_img, input_label, labels, conditional_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_labels(labels, batch_size=10, target_size = [10, 25, 25, 3]):\n",
    "\n",
    "    labels = tf.reshape(inputs[1], [-1, 1, 1, label_size]) #batch_size, 1, 1, label_size\n",
    "    labels = tf.cast(labels, dtype='float32')\n",
    "    labels = tf.cast(labels, dtype='float32')\n",
    "    ones = tf.ones([target_size.shape[0]] + target_size[0:-1] + [label_size]) #batch_size, 50, 50, label_size\n",
    "    labels = ones * labels #batch_size, 50, 50, label_size\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs0 = tf.random.normal(shape=(10, 50, 50 ,3))\n",
    "inputs1 = (0, 1)\n",
    "inputs = [inputs0, inputs1]\n",
    "label_size = 2\n",
    "image_size = [50, 50, 3]\n",
    "_, _, labels, _ = conditional_input(inputs)\n",
    "\n",
    "labels.shape\n",
    "reshape_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0284a593613b942586af6b8f0d4ee916e356aed836174e2f823c929bc6bc05cc"
  },
  "kernelspec": {
   "display_name": "dis_vae",
   "language": "python",
   "name": "dis_vae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
