{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/probability/examples/Probabilistic_Layers_VAE#dependencies_prerequisites\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "input_shape = (50, 50, 3)\n",
    "num_features = 7500#50*50*3\n",
    "latent_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_CNN(input_shape = (50, 50, 3), latent_dim = 2):\n",
    "\n",
    "    inputs = layers.Input(shape=input_shape, name='Input')\n",
    "\n",
    "    # layer 1\n",
    "    x = layers.Conv2D(filters=6, kernel_size=5, strides=1,padding='valid',name='C1')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.AvgPool2D(pool_size=2, strides=2,name='S2')(x)\n",
    "\n",
    "    # layer 2\n",
    "    x = layers.Conv2D(filters=16, kernel_size=5,strides=1,padding='valid',name='C3')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.AvgPool2D(pool_size=2, strides=2,name='S4')(x)\n",
    "\n",
    "    # layer 3\n",
    "    x = layers.Conv2D(filters=120, kernel_size=5,strides=1,padding='valid',name='C5')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    y = layers.Dense(84, activation ='relu',name='F6')(x)\n",
    "    z_mean = layers.Dense(latent_dim, name='z_mean')(y)\n",
    "    z_log_var = layers.Dense(latent_dim, name='z_log_var')(y)\n",
    "    z = layers.Lambda(sampling, name='z')([z_mean, z_log_var]) #reparametrization trick\n",
    "    model = keras.Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = encoder_CNN(latent_dim = latent_dim)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_CNN(input_shape = (50, 50, 3), latent_dim = 2):\n",
    "    latent_inputs = layers.Input(shape=(latent_dim,), name='z_sampling')\n",
    "    x = layers.Dense(84, activation ='tanh',name='F6l')(latent_inputs)\n",
    "    x = layers.Dropout(0.3)(latent_inputs)\n",
    "    x = layers.Dense(5*5*120, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Reshape(target_shape=(5, 5, 120))(x) #(5, 5, 120)\n",
    "    x = layers.UpSampling2D((2,2), name='S4l')(x) # (10, 10, 120)\n",
    "    x = layers.Conv2DTranspose(filters=16, kernel_size=5,strides=1,padding='valid',name='C5l')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.UpSampling2D((2,2))(x)\n",
    "    x = layers.Conv2DTranspose(filters=6, kernel_size=5, strides=1,padding='valid',name='C1l')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    outputs = layers.Conv2DTranspose(filters=3, kernel_size=19, strides=1,activation='sigmoid',padding='valid')(x)\n",
    "   # outputs = layers.Reshape(target_shape=(50, 50, 3), name='output')(x)\n",
    "    model = keras.Model(latent_inputs, outputs, name='decoder')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = decoder_CNN(latent_dim = latent_dim)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VAE(input_shape, latent_dim, encoder, decoder):\n",
    "    vae_input = layers.Input(shape = input_shape, name=\"VAE_input\")\n",
    "    encoder_output = encoder(vae_input)\n",
    "    decoder_output = decoder(encoder_output[2])\n",
    "    model = keras.Model(vae_input, decoder_output, name='VAE')\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(input_shape, latent_dim, encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(vae,show_shapes=True, show_layer_names=True,expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(encoder_mu, encoder_log_variance, beta_coefficient):\n",
    "\n",
    "    def vae_reconstruction_loss(y_true, y_predict):\n",
    "        reconstruction_loss_factor = 1000\n",
    "        reconstruction_loss = K.mean(K.square(y_true - y_predict), axis=[1, 2, 3])\n",
    "        return reconstruction_loss_factor * reconstruction_loss\n",
    "\n",
    "    def vae_kl_loss(encoder_mu, encoder_log_variance):\n",
    "        kl_loss = -0.5 * K.sum(1.0 + encoder_log_variance - K.square(encoder_mu) - K.exp(encoder_log_variance), axis=[1, 2, 3])\n",
    "        return kl_loss\n",
    "\n",
    "    def vae_kl_loss_metric(y_true, y_predict):\n",
    "        kl_loss = -0.5 * K.backend.sum(1.0 + encoder_log_variance - K.square(encoder_mu) - K.exp(encoder_log_variance), axis=[1, 2, 3])\n",
    "        return kl_loss\n",
    "\n",
    "    def vae_loss(y_true, y_predict, beta_coefficient):\n",
    "        reconstruction_loss = vae_reconstruction_loss(y_true, y_predict)\n",
    "        kl_loss = vae_kl_loss(y_true, y_predict)\n",
    "\n",
    "        loss = reconstruction_loss + beta_coefficient * kl_loss\n",
    "        return loss\n",
    "\n",
    "    return vae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_coefficient=1\n",
    "\n",
    "#Information needed to compute the loss function\n",
    "vae_input = vae.input\n",
    "vae_output = vae.output\n",
    "mu = encoder.get_layer('z_mean').output\n",
    "log_var= encoder.get_layer('z_log_var').output\n",
    "\n",
    "vae.add_loss(vae_loss( mu, log_var, beta_coefficient))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.save('models/vae.h5')  \n",
    "encoder.save('models/encoder.h5')\n",
    "decoder.save('models/decoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer='adam')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0284a593613b942586af6b8f0d4ee916e356aed836174e2f823c929bc6bc05cc"
  },
  "kernelspec": {
   "display_name": "dis_vae",
   "language": "python",
   "name": "dis_vae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
