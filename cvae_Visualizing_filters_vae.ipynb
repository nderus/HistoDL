{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing convnet filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/himanshurawlani/convnet-interpretability-keras/blob/master/Visualizing%20filters/visualizing_convnet_filters.ipynb\n",
    "\n",
    "- for the gradients and : https://www.sicara.ai/blog/2019-08-28-interpretability-deep-learning-tensorflow\n",
    "https://gist.github.com/RaphaelMeudec/31b7bba0b972ec6ec80ed131a59c5b3f#file-kernel_visualization-py\n",
    "\n",
    "- for building blocks instead of layers (better visualization) as blocks (conv + pooling)\n",
    "together can capture structures: https://github.com/nikhilroxtomar/Custom-Blocks-in-TensorFlow-using-Keras-API/blob/main/cifar10.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, beta, shape, **kwargs):\n",
    "        super(CVAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.beta = beta\n",
    "        self.shape = shape\n",
    "        self.latent_var = []\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        #\n",
    "        self.v_total_loss_tracker = keras.metrics.Mean(name=\"v_total_loss\")\n",
    "        self.v_reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"v_reconstruction_loss\")\n",
    "        self.v_kl_loss_tracker = keras.metrics.Mean(name=\"v_kl_loss\")\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "       \n",
    "    def call(self, inputs):\n",
    "        _, input_label, conditional_input = self.conditional_input(inputs)\n",
    "        z_mean, z_log_var = self.encoder(conditional_input)\n",
    "        z_cond = self.sampling(z_mean, z_log_var, input_label)\n",
    "        return self.decoder(z_cond)\n",
    "    \n",
    "    def conditional_input(self, inputs, label_size=10): \n",
    "  \n",
    "        image_size = [self.shape[0], self.shape[1], self.shape[2]]\n",
    "    \n",
    "        input_img = layers.InputLayer(input_shape=image_size,\n",
    "                                      dtype ='float32')(inputs[0])\n",
    "        input_label = layers.InputLayer(input_shape=(label_size, ),\n",
    "                                        dtype ='float32')(inputs[1])\n",
    "\n",
    "        labels = tf.reshape(inputs[1], [-1, 1, 1, label_size])\n",
    "        labels = tf.cast(labels, dtype='float32')\n",
    "        ones = tf.ones([inputs[0].shape[0]] + image_size[0:-1] + [label_size]) \n",
    "        labels = ones * labels\n",
    "        conditional_input = layers.Concatenate(axis=3)([input_img, labels]) \n",
    "        return  input_img, input_label, conditional_input\n",
    "\n",
    "    def sampling(self, z_mean, z_log_var, input_label):\n",
    "\n",
    "        if len(input_label.shape) == 1:\n",
    "            input_label = np.expand_dims(input_label, axis=0)\n",
    "\n",
    "        eps = tf.random.normal(tf.shape(z_log_var), dtype=tf.float32,\n",
    "                               mean=0., stddev=1.0, name='epsilon')\n",
    "        z = z_mean + tf.exp(z_log_var / 2) * eps\n",
    "        z_cond = tf.concat([z, input_label], axis=1)\n",
    "        return z_cond\n",
    "\n",
    "    def train_step(self, data):\n",
    "\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "        \n",
    "            input_img, input_label, conditional_input = self.conditional_input(data)\n",
    "            z_mean, z_log_var = self.encoder(conditional_input)\n",
    "            self.latent_var.append(tf.exp(z_log_var))\n",
    "            z_cond = self.sampling(z_mean, z_log_var, input_label)\n",
    "            reconstruction = self.decoder(z_cond)\n",
    "            reconstruction_loss = np.prod(self.shape) * tf.keras.losses.MSE(tf.keras.backend.flatten(input_img),\n",
    "                                    tf.keras.backend.flatten(reconstruction))            \n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean)\n",
    "                      - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(kl_loss, axis=1) #was reduce_sum\n",
    "            total_loss = reconstruction_loss + (self.beta * kl_loss)\n",
    "            total_loss = tf.reduce_mean(total_loss) \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        input_img, input_label, conditional_input = self.conditional_input(data)\n",
    "        z_mean, z_log_var = self.encoder(conditional_input)\n",
    "        z_cond = self.sampling(z_mean, z_log_var, input_label)\n",
    "        reconstruction = self.decoder(z_cond)\n",
    "        reconstruction_loss = np.prod(self.shape) * tf.keras.losses.MSE(tf.keras.backend.flatten(input_img), tf.keras.backend.flatten(reconstruction)) # over weighted MSE    \n",
    "\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean)\n",
    "                  - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_mean(kl_loss, axis=1) # was reduce_sum\n",
    "        total_loss = reconstruction_loss + (self.beta * kl_loss)\n",
    "        total_loss = tf.reduce_mean(total_loss)\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return{\n",
    "            'loss': total_loss,\n",
    "            'reconstruction_loss': reconstruction_loss,\n",
    "            'kl_loss': kl_loss\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/PERSONALE/nicolas.derus2/HistoDL/cvae_Visualizing_filters_vae.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoDL/cvae_Visualizing_filters_vae.ipynb#ch0000005vscode-remote?line=0'>1</a>\u001b[0m cvae_encoder \u001b[39m=\u001b[39m load_model(\u001b[39m'\u001b[39m\u001b[39mmodels/cvae_encoder_toy.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoDL/cvae_Visualizing_filters_vae.ipynb#ch0000005vscode-remote?line=1'>2</a>\u001b[0m cvae_decoder \u001b[39m=\u001b[39m load_model(\u001b[39m'\u001b[39m\u001b[39mmodels/cvae_decoder_toy.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoDL/cvae_Visualizing_filters_vae.ipynb#ch0000005vscode-remote?line=2'>3</a>\u001b[0m cvae \u001b[39m=\u001b[39m CVAE(encoder\u001b[39m=\u001b[39;49mcvae_encoder, decoder\u001b[39m=\u001b[39;49mcvae_decoder, beta \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoDL/cvae_Visualizing_filters_vae.ipynb#ch0000005vscode-remote?line=3'>4</a>\u001b[0m cvae(np\u001b[39m.\u001b[39mzeros((\u001b[39m1\u001b[39m,\u001b[39m50\u001b[39m,\u001b[39m50\u001b[39m,\u001b[39m3\u001b[39m)))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoDL/cvae_Visualizing_filters_vae.ipynb#ch0000005vscode-remote?line=4'>5</a>\u001b[0m cvae\u001b[39m.\u001b[39mload_weights(\u001b[39m'\u001b[39m\u001b[39mweights/vae.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'shape'"
     ]
    }
   ],
   "source": [
    "cvae_encoder = load_model('models/cvae_encoder_toy.h5')\n",
    "cvae_decoder = load_model('models/cvae_decoder_toy.h5')\n",
    "cvae = CVAE(encoder=cvae_encoder, decoder=cvae_decoder, beta = 1)\n",
    "cvae(np.zeros((1,50,50,3)))\n",
    "cvae.load_weights('weights/vae.h5')\n",
    "model = cvae.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    if 'conv' in layer.name:\n",
    "        print(layer.name)\n",
    "        print(len(layer.get_weights()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting visualization variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximize the activation of a specific filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Layer name to inspect\n",
    "layer_name = 'block1_conv1'\n",
    "\n",
    "epochs = 100\n",
    "step_size = 1.\n",
    "filter_index = 1\n",
    "\n",
    "# Create a connection between the input and the target layer\n",
    "submodel = tf.keras.models.Model([model.inputs[0]], [model.get_layer(layer_name).output])\n",
    "\n",
    "# Initiate random noise\n",
    "if 'encoder' in model.name:\n",
    "    input_img_data = np.random.random((1, 50, 50, 3))\n",
    "    input_img_data = (input_img_data - 0.5) * 20 + 128.\n",
    "\n",
    "if 'decoder' in model.name:\n",
    "    input_img_data = np.random.random((1, 512))\n",
    "    input_img_data = (input_img_data - 0.5) * 20 + 128.\n",
    "\n",
    "# Cast random noise from np.float64 to tf.float32 Variable\n",
    "input_img_data = tf.Variable(tf.cast(input_img_data, tf.float32))\n",
    "\n",
    "# Iterate gradient ascents\n",
    "for _ in range(epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = submodel(input_img_data)\n",
    "        loss_value = tf.reduce_mean(outputs[:, :, :, filter_index])\n",
    "    grads = tape.gradient(loss_value, input_img_data)\n",
    "    normalized_grads = grads / (tf.sqrt(tf.reduce_mean(tf.square(grads))) + 1e-5)\n",
    "    input_img_data.assign_add(normalized_grads * step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = input_img_data.numpy().astype(np.uint8)\n",
    "img = img.squeeze()\n",
    "img = img / 255\n",
    "img.max()\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dimensions of the generated pictures for each filter.\n",
    "img_width = 50\n",
    "img_height = 50\n",
    "\n",
    "# this is the placeholder for the input images\n",
    "input_img = model.input\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "#layer_dict = dict([(layer.name, layer) for layer in model.layers[0:]])\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "layer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "# util function to convert a tensor into a valid image\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + K.epsilon())\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_ascent(iterate):\n",
    "    # step size for gradient ascent    \n",
    "    step = 1.\n",
    "\n",
    "    # we start from a gray image with some random noise\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_img_data = np.random.random((1, 3, img_width, img_height))\n",
    "    else:\n",
    "        input_img_data = np.random.random((1, img_width, img_height, 3))\n",
    "    input_img_data = (input_img_data - 0.5) * 20 + 128\n",
    "\n",
    "    # we run gradient ascent for 20 steps\n",
    "    for i in range(20):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "\n",
    "#         print('------>Current loss value:', loss_value)\n",
    "        if loss_value <= 0.:\n",
    "            # some filters get stuck to 0, we can skip them\n",
    "            break\n",
    "        \n",
    "    # decode the resulting input image\n",
    "    if loss_value > 0:\n",
    "        img = deprocess_image(input_img_data[0])\n",
    "        kept_filters.append((img, loss_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nth_filter_loss(filter_index, layer_name):\n",
    "    \"\"\"\n",
    "    We build a loss function that maximizes the activation\n",
    "    of the nth filter of the layer considered\n",
    "    \"\"\"\n",
    "    \n",
    "    layer_output = layer_dict[layer_name].output\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        loss = K.mean(layer_output[:, filter_index, :, :])\n",
    "    else:\n",
    "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "    # Initiate random noise\n",
    "    # Create a connection between the input and the target layer\n",
    "    \n",
    "    submodel = tf.keras.models.Model([model.inputs[0]], [model.get_layer(layer_name).output])\n",
    "\n",
    "# Initiate random noise\n",
    "\n",
    "    input_img_data = np.random.random((1, 50, 50, 3))\n",
    "    input_img_data = (input_img_data - 0.5) * 20 + 128.\n",
    "\n",
    "    # Cast random noise from np.float64 to tf.float32 Variable\n",
    "    input_img_data = tf.Variable(tf.cast(input_img_data, tf.float32))\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = submodel(input_img_data)\n",
    "            loss_value = tf.reduce_mean(outputs[:, :, :, filter_index])\n",
    "        grads = tape.gradient(loss_value, input_img_data)\n",
    "        normalized_grads = grads / (tf.sqrt(tf.reduce_mean(tf.square(grads))) + 1e-5)\n",
    "        input_img_data.assign_add(normalized_grads * step_size)\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    #iterate = K.function([input_img], [loss_value, grads])\n",
    "\n",
    "    if loss_value > 0:\n",
    "        img = input_img_data.numpy().astype(np.float64)\n",
    "        img = img.squeeze()\n",
    "        img = deprocess_image(img)\n",
    "        kept_filters.append((img, loss_value))\n",
    "    #return iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [layer.name for layer in model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = model.get_layer('block1_conv1')\n",
    "range(min(layer.output.shape[-1], 100))\n",
    "layer_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_index = 5\n",
    "build_nth_filter_loss(filter_index, layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "kept_filters = []\n",
    "filters_dict = dict()\n",
    "for layer_name in layers:\n",
    "    if 'conv' in layer_name:\n",
    "        layer = model.get_layer(layer_name)\n",
    "        print('Processing filter for layer:', layer_name)\n",
    "        for filter_index in range(min(layer.output.shape[-1], 100)):\n",
    "            # print('Processing filter %d' % filter_index)\n",
    "\n",
    "            start_time = time.time()\n",
    "            build_nth_filter_loss(filter_index, layer_name)\n",
    "            end_time = time.time()\n",
    "\n",
    "    #         print('--->Filter %d processed in %ds' % (filter_index, end_time - start_time))\n",
    "        filters_dict[layer.name] = kept_filters\n",
    "        kept_filters = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_name, kept_filters in filters_dict.items():\n",
    "    print(layer_name, len(kept_filters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import save_img\n",
    "\n",
    "def stich_filters(kept_filters, layer_name):\n",
    "    # By default, we will stich the best 64 (n*n) filters on a 8 x 8 grid.\n",
    "    n = int(np.sqrt(len(kept_filters)))\n",
    "    # the filters that have the highest loss are assumed to be better-looking.\n",
    "    # we will only keep the top 64 filters.\n",
    "    kept_filters.sort(key=lambda x: x[1], reverse=True)\n",
    "    kept_filters = kept_filters[:n * n]\n",
    "\n",
    "    # build a black picture with enough space for\n",
    "    # our 8 x 8 filters of size 128 x 128, with a 5px margin in between\n",
    "    margin = 5\n",
    "    width = n * img_width + (n - 1) * margin\n",
    "    height = n * img_height + (n - 1) * margin\n",
    "    stitched_filters = np.zeros((width, height, 3))\n",
    "\n",
    "    # fill the picture with our saved filters\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            img, loss = kept_filters[i * n + j]\n",
    "            width_margin = (img_width + margin) * i\n",
    "            height_margin = (img_height + margin) * j\n",
    "            stitched_filters[\n",
    "                width_margin: width_margin + img_width,\n",
    "                height_margin: height_margin + img_height, :] = img\n",
    "\n",
    "    # save the result to disk\n",
    "    save_img('img/filters/vae/{}_stitched_filters_{}.png'.format(model.name, layer_name), stitched_filters)\n",
    "    \n",
    "for layer_name, kept_filters in filters_dict.items():\n",
    "    print('Stiching filters for {}'.format(layer_name))\n",
    "    stich_filters(kept_filters, layer_name)\n",
    "    print('number of filters kept:', len(kept_filters))\n",
    "    print('Completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "filter_name = 'block1_conv1'\n",
    "\n",
    "img = image.img_to_array(image.load_img('img/filters/vae/{}_stitched_filters_{}.png'.format(model.name, filter_name))) /255.\n",
    "plt.figure(figsize=(17,17))\n",
    "plt.imshow(img)\n",
    "plt.title(filter_name)\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0284a593613b942586af6b8f0d4ee916e356aed836174e2f823c929bc6bc05cc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('dis_vae')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
