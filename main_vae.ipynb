{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO:\n",
    "# add batch_normalization layer\n",
    "\n",
    "# changed binary crossentropy for mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import keras.backend as K\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "import math\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "imagePatches = glob('datasets/breast-histopathology/IDC_regular_ps50_idx5/**/*.png', recursive=True)\n",
    "for filename in imagePatches[0:10]:\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class0 = [] # 0 = no cancer\n",
    "class1 = [] # 1 = cancer\n",
    "\n",
    "for filename in imagePatches:\n",
    "    if filename.endswith(\"class0.png\"):\n",
    "         class0.append(filename)\n",
    "    else:\n",
    "        class1.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampled_class0 = random.sample(class0, 78786)\n",
    "#sampled_class1 = random.sample(class1, 78786)\n",
    "#sampled_class0 = random.sample(class0, 50000)\n",
    "#sampled_class1 = random.sample(class1, 50000)\n",
    "#sampled_class0 = random.sample(class0, 30000)\n",
    "#sampled_class1 = random.sample(class1, 30000)\n",
    "sampled_class0 = random.sample(class0, 5000)\n",
    "sampled_class1 = random.sample(class1, 5000)\n",
    "#sampled_class0 = random.sample(class0, 1000)\n",
    "#sampled_class1 = random.sample(class1, 1000)\n",
    "len(sampled_class0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imread\n",
    "import cv2\n",
    "\n",
    "def get_image_arrays(data, label):\n",
    "    img_arrays = []\n",
    "    for i in data:\n",
    "        if i.endswith('.png'):\n",
    "            img = cv2.imread(i ,cv2.IMREAD_COLOR)\n",
    "            img_sized = cv2.resize(img, (50, 50), #was (70,70)\n",
    "                        interpolation=cv2.INTER_LINEAR)\n",
    "            img_arrays.append([img_sized, label]) \n",
    "    return img_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class0_array = get_image_arrays(sampled_class0, 0)\n",
    "class1_array = get_image_arrays(sampled_class1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = np.concatenate((class0_array, class1_array))\n",
    "#random.seed(41)\n",
    "#random.shuffle(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features, label in combined_data:\n",
    "    X.append(features)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(-1, 50, 50, 3)\n",
    "y = np.array(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.2,\n",
    "                                    random_state = 11)\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, \n",
    "                            test_size = 0.25, random_state = 11) \n",
    "                            # 0.25 x 0.8 = 0.2\n",
    "train_y = to_categorical(train_y)\n",
    "test_y = to_categorical(test_y)\n",
    "val_y = to_categorical(val_y)\n",
    "train_y_label = np.argmax(train_y, axis=1) # from one-hot encoding to integer\n",
    "test_y_label = np.argmax(test_y, axis=1)\n",
    "val_y_label = np.argmax(val_y, axis=1)\n",
    "class_names = ('non-cancer','cancer')\n",
    "print(train_x.shape, test_x.shape, val_x.shape, train_y.shape, test_y.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min value: ', train_x.min())\n",
    "print('Max value: ', train_x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x / 255\n",
    "test_x = test_x / 255\n",
    "val_x = val_x / 255\n",
    "print('Min value: ', train_x.min())\n",
    "print('Max value: ', train_x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize random images from data\n",
    "image_count = 10\n",
    "\n",
    "_, axs = plt.subplots(1, image_count, figsize=(20, 20))\n",
    "for i in range(image_count):\n",
    "  random_idx=random.randint(0, train_x.shape[0])\n",
    "  axs[i].imshow(train_x[random_idx], cmap='gray')\n",
    "  axs[i].axis('off')\n",
    "  axs[i].set_title(class_names[train_y_label[random_idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vae = keras.models.load_model('models/vae.h5')\n",
    "#encoder = keras.models.load_model('models/encoder.h5')\n",
    "#decoder = keras.models.load_model('models/decoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load encoder and decoder models\n",
    "vae_encoder = keras.models.load_model('models/vae_encoder.h5')\n",
    "vae_decoder = keras.models.load_model('models/vae_decoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_shape = (50, 50, 3)\n",
    "\n",
    "num_features = 7500#50*50*3\n",
    "latent_dim = vae_decoder.input_shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/PERSONALE/nicolas.derus2/HistoDL/main_vae.ipynb Cell 21'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoDL/main_vae.ipynb#ch0000020vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mVAE\u001b[39;00m(keras\u001b[39m.\u001b[39mModel):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoDL/main_vae.ipynb#ch0000020vscode-remote?line=1'>2</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, encoder, decoder, beta, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B137.204.48.211/home/PERSONALE/nicolas.derus2/HistoDL/main_vae.ipynb#ch0000020vscode-remote?line=2'>3</a>\u001b[0m         \u001b[39msuper\u001b[39m(VAE, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, beta, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.beta = beta\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        #\n",
    "        self.v_total_loss_tracker = keras.metrics.Mean(name=\"v_total_loss\")\n",
    "        self.v_reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"v_reconstruction_loss\")\n",
    "        self.v_kl_loss_tracker = keras.metrics.Mean(name=\"v_kl_loss\")\n",
    "        \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.encoder(inputs)[2]\n",
    "        return self.decoder(x)\n",
    "        \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            \n",
    "        ]\n",
    "    #removed tf.reduce_sum(MSE)\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "           \n",
    "            #reconstruction_loss = np.prod((50, 50, 3)) * tf.keras.losses.MSE(tf.keras.backend.flatten(data), tf.keras.backend.flatten(reconstruction)) # over weighted MSE  \n",
    "            reconstruction_loss = np.prod((50, 50, 3)) * tf.keras.losses.binary_crossentropy(tf.keras.backend.flatten(data), tf.keras.backend.flatten(reconstruction)) # over weighted MSE   \n",
    "            \n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_sum(kl_loss, axis=1) #removed reduce_mean()\n",
    "            \n",
    "            total_loss = reconstruction_loss + (self.beta * kl_loss)\n",
    "            total_loss = tf.reduce_mean(total_loss) \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        z_mean, z_log_var, z = self.encoder(data)\n",
    "        reconstruction = self.decoder(z)\n",
    "        reconstruction_loss = np.prod((50, 50, 3)) * tf.keras.losses.MSE(tf.keras.backend.flatten(data), tf.keras.backend.flatten(reconstruction)) # over weighted MSE    \n",
    "        \n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_sum(kl_loss, axis=1) \n",
    "        kl_loss = tf.reduce_mean(kl_loss) #added\n",
    "        total_loss = reconstruction_loss + (self.beta * kl_loss)\n",
    "        total_loss = tf.reduce_mean(total_loss)\n",
    "\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return{\n",
    "            'loss': total_loss,\n",
    "            'reconstruction_loss': reconstruction_loss,\n",
    "            'kl_loss': kl_loss\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_coeff = 1\n",
    "vae = VAE(encoder=vae_encoder, decoder=vae_decoder, beta = beta_coeff)\n",
    "#vae.compile(optimizer='Adam')\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1))\n",
    "#plot_model(vae, show_shapes=True, show_layer_names=True,expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x = np.array(val_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 500\n",
    "#model.compile( optimizer='adam')\n",
    "tf.config.run_functions_eagerly(False)\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "history = vae.fit(train_x, validation_data=(val_x, val_x), epochs=epochs, batch_size=batch_size, callbacks=early_stop) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Val_Plot(loss, val_loss, reconstruction_loss, val_reconstruction_loss, kl_loss, val_kl_loss):\n",
    "    \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize= (16,4))\n",
    "    fig.suptitle(\" MODEL'S METRICS VISUALIZATION \")\n",
    "\n",
    "    ax1.plot(range(1, len(loss) + 1), loss)\n",
    "    ax1.plot(range(1, len(val_loss) + 1), val_loss)\n",
    "    ax1.set_title('History of Loss')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend(['training', 'validation'])\n",
    "\n",
    "    ax2.plot(range(1, len(reconstruction_loss) + 1), reconstruction_loss)\n",
    "    ax2.plot(range(1, len(val_reconstruction_loss) + 1), val_reconstruction_loss)\n",
    "    ax2.set_title('History of reconstruction_loss')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('reconstruction_loss')\n",
    "    ax2.legend(['training', 'validation'])\n",
    "    \n",
    "    ax3.plot(range(1, len(kl_loss) + 1), kl_loss)\n",
    "    ax3.plot(range(1, len(val_kl_loss) + 1), val_kl_loss)\n",
    "    ax3.set_title(' History of kl_loss')\n",
    "    ax3.set_xlabel(' Epochs ')\n",
    "    ax3.set_ylabel('kl_loss')\n",
    "    ax3.legend(['training', 'validation'])\n",
    "     \n",
    "    \n",
    "    plt.show()\n",
    "    fig.savefig('img/vae_loss_latent:{}_epochs:{}_beta:{}.png'.format(latent_dim, epochs, beta_coeff))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Val_Plot(history.history['loss'][1:],\n",
    "               history.history['val_loss'][1:],\n",
    "               history.history['reconstruction_loss'][1:],\n",
    "               history.history['val_reconstruction_loss'][1:],\n",
    "               history.history['kl_loss'][1:],\n",
    "               history.history['val_kl_loss'][1:]\n",
    "               )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.save_weights('weights/vae.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('trainHistoryDict.txt', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "object = pd.read_pickle(r'trainHistoryDict.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Val_Plot(history.history['loss'][1:],\n",
    "               history.history['val_loss'][1:],\n",
    "               history.history['reconstruction_loss'][1:],\n",
    "               history.history['val_reconstruction_loss'][1:],\n",
    "               history.history['kl_loss'][1:],\n",
    "               history.history['val_kl_loss'][1:]\n",
    "               )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vae(np.zeros((1,50,50,3)))\n",
    "#vae.built = True\n",
    "#vae.load_weights('weights/vae.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p = vae.predict(train_x[:1000])\n",
    "p = vae.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_x[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(p[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(y_true, y_pred):    \n",
    "    f, ax = plt.subplots(2, 10, figsize=(15, 4))\n",
    "    for i in range(10):\n",
    "        ax[0][i].imshow(np.reshape(y_true[i], (50, 50, 3)), aspect='auto')\n",
    "        ax[1][i].imshow(np.reshape(y_pred[i], (50, 50, 3)), aspect='auto')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(train_x[:100], p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter with images instead of points\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "img_size = 50\n",
    "def imscatter(x, y, ax, imageData, zoom):\n",
    "    images = []\n",
    "    for i in range(len(x)):\n",
    "        x0, y0 = x[i], y[i]\n",
    "        # Convert to image\n",
    "        img = imageData[i]*255.\n",
    "        img = img.astype(np.uint8).reshape([img_size,img_size,3])\n",
    "        #img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
    "        # Note: OpenCV uses BGR and plt uses RGB\n",
    "        image = OffsetImage(img, zoom=zoom)\n",
    "        ab = AnnotationBbox(image, (x0, y0), xycoords='data', frameon=False)\n",
    "        images.append(ax.add_artist(ab))\n",
    "    \n",
    "    ax.update_datalim(np.column_stack([x, y]))\n",
    "    ax.autoscale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/despoisj/LatentSpaceVisualization/blob/master/visuals.py\n",
    "from sklearn import manifold\n",
    "\n",
    "def computeTSNEProjectionOfLatentSpace(X, X_encoded, display=True, save=True):\n",
    "    # Compute latent space representation\n",
    "    print(\"Computing latent space projection...\")\n",
    "    #X_encoded = encoder.predict(X)\n",
    "\n",
    "    # Compute t-SNE embedding of latent space\n",
    "    print(\"Computing t-SNE embedding...\")\n",
    "    tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "    X_tsne = tsne.fit_transform(X_encoded)\n",
    "\n",
    "    # Plot images according to t-sne embedding\n",
    "    if display:\n",
    "        print(\"Plotting t-SNE visualization...\")\n",
    "        fig, ax = plt.subplots(figsize=(15, 15))\n",
    "        ax = fig.add_subplot(111, facecolor='black')\n",
    "        imscatter(X_tsne[:, 0], X_tsne[:, 1], imageData=X, ax=ax, zoom=0.5)\n",
    "        if save:\n",
    "            fig.savefig('img/t-SNE-embedding_vae_latent:{}_epochs:{}_beta:{}.png'.format(latent_dim, epochs, beta_coeff))\n",
    "        plt.show()\n",
    "    else:\n",
    "        return X_tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded = vae_encoder.predict(train_x[:1000])[0]\n",
    "X_encoded.shape\n",
    "#need to reshape for TSNE\n",
    "#X_encoded_flatten = X_encoded.reshape(-1,25*25*3)\n",
    "#X_encoded_flatten.shape\n",
    "X_encoded_flatten = X_encoded\n",
    "X_encoded_flatten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "X_tsne = tsne.fit_transform(X_encoded_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeTSNEProjectionOfLatentSpace(train_x[:1000,], X_encoded_flatten, display=True, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "df['y'] = train_y_label[:1000]\n",
    "df['comp-1'] = X_tsne[:,0]\n",
    "df['comp-2'] = X_tsne[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "colors = {0:'blue', 1:'red'}\n",
    "\n",
    "ax.scatter(df[\"comp-1\"], df[\"comp-2\"], c=df['y'].map(colors), label=colors) \n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTSNEProjectionOfPixelSpace(X, display=True):\n",
    "    # Compute t-SNE embedding of latent space\n",
    "    print(\"Computing t-SNE embedding...\")\n",
    "    tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "    X_tsne = tsne.fit_transform(X.reshape([-1, 50* 50* 3]))\n",
    "\n",
    "    # Plot images according to t-sne embedding\n",
    "    if display:\n",
    "        print(\"Plotting t-SNE visualization...\")\n",
    "        fig, ax = plt.subplots(figsize=(15, 15))\n",
    "        ax = fig.add_subplot(111, facecolor='black')\n",
    "        imscatter(X_tsne[:, 0], X_tsne[:, 1], imageData=X, ax=ax, zoom=0.5)\n",
    "        fig.savefig('img/t-SNE_original_space.png')\n",
    "        plt.show()\n",
    "    else:\n",
    "        return X_tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computeTSNEProjectionOfPixelSpace(train_x[:1000], display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReconstructedImages(X, encoder, decoder):\n",
    "    img_size = 50\n",
    "    nbSamples = X.shape[0]\n",
    "    nbSquares = int(math.sqrt(nbSamples))\n",
    "    nbSquaresHeight = 2*nbSquares\n",
    "    nbSquaresWidth = nbSquaresHeight\n",
    "    resultImage = np.zeros((nbSquaresHeight*img_size,int(nbSquaresWidth*img_size/2),X.shape[-1]))\n",
    "\n",
    "    reconstructedX = decoder.predict(encoder.predict(X)[2])\n",
    "\n",
    "    for i in range(nbSamples) :     # \n",
    "        original = X[i]\n",
    "        reconstruction = reconstructedX[i]\n",
    "        rowIndex = i%nbSquaresWidth\n",
    "        columnIndex = int((i-rowIndex)/nbSquaresHeight)\n",
    "        resultImage[rowIndex*img_size:(rowIndex+1)*img_size,columnIndex*2*img_size:(columnIndex+1)*2*img_size,:] = np.hstack([original,reconstruction])\n",
    "\n",
    "    return resultImage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstructions for samples in dataset\n",
    "def visualizeReconstructedImages(X_train, X_test, encoder, decoder, save=False):\n",
    "    trainReconstruction = getReconstructedImages(X_train, encoder, decoder)\n",
    "    testReconstruction = getReconstructedImages(X_test, encoder, decoder)\n",
    "\n",
    "    if not save:\n",
    "        print(\"Generating 10 image reconstructions...\")\n",
    "\n",
    "    result = np.hstack([trainReconstruction,\n",
    "            np.zeros([trainReconstruction.shape[0],5,\n",
    "            trainReconstruction.shape[-1]]),\n",
    "            testReconstruction])\n",
    "    result = (result*255.).astype(np.uint8)\n",
    "\n",
    "    if save:\n",
    "        fig, _ = plt.subplots(figsize=(15, 15))\n",
    "        plt.imshow(result)\n",
    "        fig.savefig('img/vae_reconstructions_latent:{}_epochs:{}_beta:{}.png'.format(latent_dim, epochs, beta_coeff))\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizeReconstructedImages(train_x[:100], test_x[:100],vae_encoder, vae_decoder, save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#noise = np.random.normal(size=(1, 25, 25, 3))\n",
    "#noise = noise.reshape((1,25,25,3))\n",
    "#decoded = vae_decoder.predict(noise)\n",
    "#plt.imshow((decoded[0]*255.).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(decoder):    \n",
    "    _, ax = plt.subplots(2, 10, figsize=(15, 4))\n",
    "    for i in range(2):\n",
    "        for j in range(10):\n",
    "            noise = []\n",
    "            for k in range(0,1875):\n",
    "                noise.append( random.randint(-1.5, 1.5) )\n",
    "                \n",
    "            noise = np.array(noise)\n",
    "            noise = noise.reshape(1, 1000)\n",
    "\n",
    "            decoded = vae_decoder.predict(noise)\n",
    "            ax[i][j].imshow(decoded[0], aspect='auto')\n",
    "       \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(decoder):    \n",
    "    _, ax = plt.subplots(2, 10, figsize=(15, 4))\n",
    "    for i in range(2):\n",
    "        for j in range(10):\n",
    "            noise = np.random.normal(loc=0, scale = 1, size=vae_decoder.input_shape[1])\n",
    "                \n",
    "            noise = np.array(noise)\n",
    "            noise = noise.reshape(1, 1000)\n",
    "\n",
    "            decoded = vae_decoder.predict(noise).squeeze()\n",
    "            ax[i][j].imshow( (decoded*255.).astype(np.uint8) )\n",
    "       \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(decoder):    \n",
    "    fig, ax = plt.subplots(2, 10, figsize=(15, 4))\n",
    "    for i in range(2):\n",
    "        for j in range(10):\n",
    "            noise = np.random.normal(loc=0, scale = 1, size=latent_dim)\n",
    "                \n",
    "            noise = np.array(noise)\n",
    "            noise = noise.reshape(1, latent_dim)\n",
    "\n",
    "            decoded = vae_decoder.predict(noise).squeeze()\n",
    "            ax[i][j].imshow( (decoded*255.).astype(np.uint8) )\n",
    "    fig.savefig('img/vae_generations_latent:{}_epochs:{}_beta:{}.png'.format(latent_dim, epochs, beta_coeff))   \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_images(vae_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shows linear inteprolation in image space vs latent space\n",
    "def visualizeInterpolation(start, end, encoder, decoder, save=False, nbSteps=5):\n",
    "    print(\"Generating interpolations...\")\n",
    "\n",
    "    # Create micro batch\n",
    "    X = np.array([start, end])\n",
    "\n",
    "    # Compute latent space projection\n",
    "    latentX = encoder.predict(X)[2]\n",
    "    latentStart, latentEnd = latentX\n",
    "\n",
    "    # Get original image for comparison\n",
    "    startImage, endImage = X\n",
    "\n",
    "    vectors = []\n",
    "    normalImages = []\n",
    "    #Linear interpolation\n",
    "    alphaValues = np.linspace(0, 1, nbSteps)\n",
    "    for alpha in alphaValues:\n",
    "        # Latent space interpolation\n",
    "        vector = latentStart*(1-alpha) + latentEnd*alpha\n",
    "        vectors.append(vector)\n",
    "        # Image space interpolation\n",
    "        blendImage = cv2.addWeighted(startImage, 1-alpha, endImage, alpha, 0)\n",
    "        normalImages.append(blendImage)\n",
    "\n",
    "    # Decode latent space vectors\n",
    "    vectors = np.array(vectors)\n",
    "    reconstructions = decoder.predict(vectors)\n",
    "\n",
    "    # Put final image together\n",
    "    resultLatent = None\n",
    "    resultImage = None\n",
    "\n",
    "    for i in range(len(reconstructions)):\n",
    "        interpolatedImage = normalImages[i]*255\n",
    "        interpolatedImage = cv2.resize(interpolatedImage,(50,50))\n",
    "        interpolatedImage = interpolatedImage.astype(np.uint8)\n",
    "        resultImage = interpolatedImage if resultImage is None else np.hstack([resultImage,interpolatedImage])\n",
    "\n",
    "        reconstructedImage = reconstructions[i]*255.\n",
    "        reconstructedImage = reconstructedImage.reshape(50,50,3)\n",
    "        #reconstructedImage = cv2.resize(reconstructedImage,(50,50))\n",
    "        reconstructedImage = reconstructedImage.astype(np.uint8)\n",
    "        resultLatent = reconstructedImage if resultLatent is None else np.hstack([resultLatent,reconstructedImage])\n",
    "\n",
    "    result = np.vstack([resultImage,resultLatent])\n",
    "    fig, ax = plt.subplots(figsize=(18, 4))\n",
    "    ax.imshow(result)\n",
    "    plt.tight_layout()\n",
    "       #    plt.imshow(result)\n",
    "    if save:\n",
    "        \n",
    "        fig.savefig('img/vector_interpolation_epochs:{}_beta:{}.png'.format(epochs, beta_coeff))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizeInterpolation(train_x[random.randint(0,train_x.shape[0])], train_x[random.randint(0, train_x.shape[0])],\n",
    "                     vae_encoder, vae_decoder, save=False, nbSteps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_email_pdf_figs(path_to_pdf, subject, message, destination, password_path=None):\n",
    "    ## credits: http://linuxcursor.com/python-programming/06-how-to-send-pdf-ppt-attachment-with-html-body-in-python-script\n",
    "    from socket import gethostname\n",
    "    #import email\n",
    "    from email.mime.application import MIMEApplication\n",
    "    from email.mime.multipart import MIMEMultipart\n",
    "    from email.mime.text import MIMEText\n",
    "    import smtplib\n",
    "    import json\n",
    "\n",
    "    server = smtplib.SMTP('smtp-mail.outlook.com', 587)\n",
    "    server.starttls()\n",
    "\n",
    "    server.login('nicolas.derus2@unibo.it', 'Epiphone1111-')\n",
    "    # Craft message (obj)\n",
    "    msg = MIMEMultipart()\n",
    "\n",
    "    message = f'{message}\\nSend from Hostname: {gethostname()}'\n",
    "    msg['Subject'] = subject\n",
    "    msg['From'] = 'nicolas.derus2@unibo.it'\n",
    "    msg['To'] = destination\n",
    "    # Insert the text to the msg going by e-mail\n",
    "    msg.attach(MIMEText(message, \"plain\"))\n",
    "    # Attach the pdf to the msg going by e-mail\n",
    "\n",
    "    for path in path_to_pdf:    \n",
    "        with open(path, \"rb\") as f:\n",
    "            #attach = email.mime.application.MIMEApplication(f.read(),_subtype=\"pdf\")\n",
    "            attach = MIMEApplication(f.read(),_subtype=\"pdf\")\n",
    "            attach.add_header('Content-Disposition','attachment',filename=str(path))\n",
    "            msg.attach(attach)\n",
    "    # send msg\n",
    "    server.send_message(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_pdf = ('/home/PERSONALE/nicolas.derus2/HistoDL/img/vae_loss_latent:{}_epochs:{}_beta:{}.png'.format(latent_dim, epochs, beta_coeff), #loss\n",
    "                '/home/PERSONALE/nicolas.derus2/HistoDL/img/t-SNE-embedding_vae_latent:{}_epochs:{}_beta:{}.png'.format(latent_dim, epochs, beta_coeff), #embedding\n",
    "                '/home/PERSONALE/nicolas.derus2/HistoDL/img/vae_reconstructions_latent:{}_epochs:{}_beta:{}.png'.format(latent_dim, epochs, beta_coeff), #reconstuctions\n",
    "                '/home/PERSONALE/nicolas.derus2/HistoDL/img/vae_generations_latent:{}_epochs:{}_beta:{}.png'.format(latent_dim, epochs, beta_coeff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_email_pdf_figs(path_to_pdf, 'Run completed!', 'HistoDL ', 'nrderus1@gmail.com', password_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss\n",
    "#send_email_pdf_figs('/home/PERSONALE/nicolas.derus2/HistoDL/img/vae_loss_latent:{}_epochs:{}_beta:{}.png'.format(latent_dim, epochs, beta_coeff), 'Run completed!', 'HistoDL - Embedding', 'nrderus1@gmail.com', password_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding\n",
    "#send_email_pdf_figs('/home/PERSONALE/nicolas.derus2/HistoDL/img/t-SNE-embedding_vae_latent:{}_epochs:{}_beta:{}.png'.format(latent_dim, epochs, beta_coeff), 'Run completed!', 'HistoDL - Embedding', 'nrderus1@gmail.com', password_path=None)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0284a593613b942586af6b8f0d4ee916e356aed836174e2f823c929bc6bc05cc"
  },
  "kernelspec": {
   "display_name": "dis_vae",
   "language": "python",
   "name": "dis_vae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
