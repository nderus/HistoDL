{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO:\n",
    "# add batch_normalization layer\n",
    "\n",
    "# try with flattened inputs ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import keras.backend as K\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "imagePatches = glob('datasets/breast-histopathology/IDC_regular_ps50_idx5/**/*.png', recursive=True)\n",
    "for filename in imagePatches[0:10]:\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class0 = [] # 0 = no cancer\n",
    "class1 = [] # 1 = cancer\n",
    "\n",
    "for filename in imagePatches:\n",
    "    if filename.endswith(\"class0.png\"):\n",
    "         class0.append(filename)\n",
    "    else:\n",
    "        class1.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_class0 = random.sample(class0, 78786)\n",
    "sampled_class1 = random.sample(class1, 78786)\n",
    "len(sampled_class0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imread\n",
    "import cv2\n",
    "\n",
    "def get_image_arrays(data, label):\n",
    "    img_arrays = []\n",
    "    for i in data:\n",
    "        if i.endswith('.png'):\n",
    "            img = cv2.imread(i ,cv2.IMREAD_COLOR)\n",
    "            img_sized = cv2.resize(img, (50, 50), #was (70,70)\n",
    "                        interpolation=cv2.INTER_LINEAR)\n",
    "            img_arrays.append([img_sized, label]) \n",
    "    return img_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class0_array = get_image_arrays(sampled_class0, 0)\n",
    "class1_array = get_image_arrays(sampled_class1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = np.concatenate((class0_array, class1_array))\n",
    "#random.seed(41)\n",
    "#random.shuffle(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features, label in combined_data:\n",
    "    X.append(features)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(-1, 50, 50, 3)\n",
    "y = np.array(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.2,\n",
    "                                    random_state = 11)\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, \n",
    "                            test_size = 0.25, random_state = 11) \n",
    "                            # 0.25 x 0.8 = 0.2\n",
    "train_y = to_categorical(train_y)\n",
    "test_y = to_categorical(test_y)\n",
    "val_y = to_categorical(val_y)\n",
    "train_y_label = np.argmax(train_y, axis=1) # from one-hot encoding to integer\n",
    "test_y_label = np.argmax(test_y, axis=1)\n",
    "val_y_label = np.argmax(val_y, axis=1)\n",
    "class_names = ('non-cancer','cancer')\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min value: ', train_x.min())\n",
    "print('Max value: ', train_x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x / 255\n",
    "test_x = test_x / 255\n",
    "print('Min value: ', train_x.min())\n",
    "print('Max value: ', train_x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = 10\n",
    "\n",
    "_, axs = plt.subplots(1, image_count, figsize=(20, 20))\n",
    "for i in range(image_count):\n",
    "  random_idx=random.randint(0, train_x.shape[0])\n",
    "  axs[i].imshow(train_x[random_idx], cmap='gray')\n",
    "  axs[i].axis('off')\n",
    "  axs[i].set_title(class_names[train_y_label[random_idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 250\n",
    "input_shape = (50, 50, 3)\n",
    "\n",
    "num_features = 7500#50*50*3\n",
    "latent_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vae = keras.models.load_model('models/vae.h5')\n",
    "#encoder = keras.models.load_model('models/encoder.h5')\n",
    "#decoder = keras.models.load_model('models/decoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vae = keras.models.load_model('models/vae.h5')\n",
    "vae_encoder = keras.models.load_model('models/vae_encoder.h5')\n",
    "vae_decoder = keras.models.load_model('models/vae_decoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        #self.beta_coefficient = beta_coefficient\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.encoder(inputs)[2]\n",
    "        return self.decoder(x)\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_sum(\n",
    "                    keras.losses.MSE(data, reconstruction), axis=(1, 2) # mod\n",
    "                )\n",
    "           # )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = (1000 * reconstruction_loss) + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(encoder=vae_encoder, decoder=vae_decoder)\n",
    "vae.compile(optimizer='RMSprop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vae\n",
    "#model.compile( optimizer='adam')\n",
    "tf.config.run_functions_eagerly(True)\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='loss', patience=2, restore_best_weights=True)\n",
    "history = model.fit(train_x, epochs=50, batch_size=250*2, callbacks=early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Val_Plot(loss, reconstruction_loss, kl_loss):\n",
    "    \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize= (16,4))\n",
    "    fig.suptitle(\" MODEL'S METRICS VISUALIZATION \")\n",
    "\n",
    "    ax1.plot(range(1, len(loss) + 1), loss)\n",
    "    ax1.set_title('History of Loss')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "\n",
    "    ax2.plot(range(1, len(reconstruction_loss) + 1), reconstruction_loss)\n",
    "    ax2.set_title('History of reconstruction_loss')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('reconstruction_loss')\n",
    "    #ax1.legend(['training', 'validation'])\n",
    "\n",
    "    #ax2.legend(['training', 'validation'])\n",
    "    \n",
    "    ax3.plot(range(1, len(kl_loss) + 1), kl_loss)\n",
    "\n",
    "    ax3.set_title(' History of kl_loss')\n",
    "    ax3.set_xlabel(' Epochs ')\n",
    "    ax3.set_ylabel('kl_loss')\n",
    "    #ax3.legend(['training', 'validation'])\n",
    "     \n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "Train_Val_Plot(history.history['loss'],\n",
    "               history.history['reconstruction_loss'],\n",
    "               history.history['kl_loss']\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('trainHistoryDict.txt', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_x[0])\n",
    "plt.show()\n",
    "\n",
    "train_x[0].shape\n",
    "\n",
    "print(train_y[0])\n",
    "print(train_y_label[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = vae.predict(train_x[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vae.save_weights('weights/vae.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae(np.zeros((1,50,50,3)))\n",
    "vae.load_weights('weights/vae.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(p[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_x[15])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(y_true, y_pred):    \n",
    "    f, ax = plt.subplots(2, 10, figsize=(15, 4))\n",
    "    for i in range(10):\n",
    "        ax[0][i].imshow(np.reshape(y_true[i], (50, 50, 3)), aspect='auto')\n",
    "        ax[1][i].imshow(np.reshape(y_pred[i], (50, 50, 3)), aspect='auto')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(train_x, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter with images instead of points\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "img_size = 50\n",
    "def imscatter(x, y, ax, imageData, zoom):\n",
    "    images = []\n",
    "    for i in range(len(x)):\n",
    "        x0, y0 = x[i], y[i]\n",
    "        # Convert to image\n",
    "        img = imageData[i]*255.\n",
    "        img = img.astype(np.uint8).reshape([img_size,img_size,3])\n",
    "        #img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
    "        # Note: OpenCV uses BGR and plt uses RGB\n",
    "        image = OffsetImage(img, zoom=zoom)\n",
    "        ab = AnnotationBbox(image, (x0, y0), xycoords='data', frameon=False)\n",
    "        images.append(ax.add_artist(ab))\n",
    "    \n",
    "    ax.update_datalim(np.column_stack([x, y]))\n",
    "    ax.autoscale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/despoisj/LatentSpaceVisualization/blob/master/visuals.py\n",
    "from sklearn import manifold\n",
    "\n",
    "def computeTSNEProjectionOfLatentSpace(X, X_encoded, display=True, save=True):\n",
    "    # Compute latent space representation\n",
    "    print(\"Computing latent space projection...\")\n",
    "    #X_encoded = encoder.predict(X)\n",
    "\n",
    "    # Compute t-SNE embedding of latent space\n",
    "    print(\"Computing t-SNE embedding...\")\n",
    "    tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "    X_tsne = tsne.fit_transform(X_encoded)\n",
    "\n",
    "    # Plot images according to t-sne embedding\n",
    "    if display:\n",
    "        print(\"Plotting t-SNE visualization...\")\n",
    "        fig, ax = plt.subplots(figsize=(15, 15))\n",
    "        ax = fig.add_subplot(111, facecolor='black')\n",
    "        imscatter(X_tsne[:, 0], X_tsne[:, 1], imageData=X, ax=ax, zoom=0.5)\n",
    "        if save:\n",
    "            fig.savefig('img/t-SNE-embedding_vae.png')\n",
    "        plt.show()\n",
    "    else:\n",
    "        return X_tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded = vae_encoder.predict(train_x[:1000])[2]\n",
    "#X_encoded.shape\n",
    "#need to reshape for TSNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeTSNEProjectionOfLatentSpace(train_x[:1000,], X_encoded[:1000,], display=True, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "X_tsne = tsne.fit_transform(X_encoded[:1000,])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "df['y'] = train_y_label[:1000]\n",
    "df['comp-1'] = X_tsne[:,0]\n",
    "df['comp-2'] = X_tsne[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "colors = {0:'blue', 1:'red'}\n",
    "\n",
    "ax.scatter(df[\"comp-1\"], df[\"comp-2\"], c=df['y'].map(colors), label=colors) \n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTSNEProjectionOfPixelSpace(X, display=True):\n",
    "    # Compute t-SNE embedding of latent space\n",
    "    print(\"Computing t-SNE embedding...\")\n",
    "    tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "    X_tsne = tsne.fit_transform(X.reshape([-1, 50* 50* 3]))\n",
    "\n",
    "    # Plot images according to t-sne embedding\n",
    "    if display:\n",
    "        print(\"Plotting t-SNE visualization...\")\n",
    "        fig, ax = plt.subplots(figsize=(15, 15))\n",
    "        ax = fig.add_subplot(111, facecolor='black')\n",
    "        imscatter(X_tsne[:, 0], X_tsne[:, 1], imageData=X, ax=ax, zoom=0.5)\n",
    "        fig.savefig('img/t-SNE_original_space.png')\n",
    "        plt.show()\n",
    "    else:\n",
    "        return X_tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeTSNEProjectionOfPixelSpace(train_x[:1000], display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReconstructedImages(X, encoder, decoder):\n",
    "    nbSamples = X.shape[0]\n",
    "    nbSquares = int(math.sqrt(nbSamples))\n",
    "    nbSquaresHeight = 2*nbSquares\n",
    "    nbSquaresWidth = nbSquaresHeight\n",
    "    resultImage = np.zeros((nbSquaresHeight*img_size,int(nbSquaresWidth*img_size/2),X.shape[-1]))\n",
    "\n",
    "    reconstructedX = decoder.predict(encoder.predict(X)[2])\n",
    "\n",
    "    for i in range(nbSamples) :     # \n",
    "        original = X[i]\n",
    "        reconstruction = reconstructedX[i]\n",
    "        rowIndex = i%nbSquaresWidth\n",
    "        columnIndex = int((i-rowIndex)/nbSquaresHeight)\n",
    "        resultImage[rowIndex*img_size:(rowIndex+1)*img_size,columnIndex*2*img_size:(columnIndex+1)*2*img_size,:] = np.hstack([original,reconstruction])\n",
    "\n",
    "    return resultImage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstructions for samples in dataset\n",
    "def visualizeReconstructedImages(X_train, X_test, encoder, decoder, save=False):\n",
    "    trainReconstruction = getReconstructedImages(X_train,encoder, decoder)\n",
    "    testReconstruction = getReconstructedImages(X_test,encoder, decoder)\n",
    "\n",
    "    if not save:\n",
    "        print(\"Generating 10 image reconstructions...\")\n",
    "\n",
    "    result = np.hstack([trainReconstruction,np.zeros([trainReconstruction.shape[0],5,trainReconstruction.shape[-1]]),testReconstruction])\n",
    "    result = (result*255.).astype(np.uint8)\n",
    "\n",
    "    if save:\n",
    "        fig, ax = plt.subplots(figsize=(15, 15))\n",
    "        plt.imshow(result)\n",
    "        fig.savefig('img/vae_reconstructions.png')\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizeReconstructedImages(train_x[:100], test_x[:100],vae_encoder, vae_decoder, save =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows linear inteprolation in image space vs latent space\n",
    "def visualizeInterpolation(start, end, encoder, decoder, save=False, nbSteps=5):\n",
    "    print(\"Generating interpolations...\")\n",
    "\n",
    "    # Create micro batch\n",
    "    X = np.array([start, end])\n",
    "\n",
    "    # Compute latent space projection\n",
    "    latentX = encoder.predict(X)\n",
    "    latentStart, latentEnd = latentX\n",
    "\n",
    "    # Get original image for comparison\n",
    "    startImage, endImage = X\n",
    "\n",
    "    vectors = []\n",
    "    normalImages = []\n",
    "    #Linear interpolation\n",
    "    alphaValues = np.linspace(0, 1, nbSteps)\n",
    "    for alpha in alphaValues:\n",
    "        # Latent space interpolation\n",
    "        vector = latentStart*(1-alpha) + latentEnd*alpha\n",
    "        vectors.append(vector)\n",
    "        # Image space interpolation\n",
    "        blendImage = cv2.addWeighted(startImage,1-alpha,endImage,alpha,0)\n",
    "        normalImages.append(blendImage)\n",
    "\n",
    "    # Decode latent space vectors\n",
    "    vectors = np.array(vectors)\n",
    "    reconstructions = decoder.predict(vectors)\n",
    "\n",
    "    # Put final image together\n",
    "    resultLatent = None\n",
    "    resultImage = None\n",
    "\n",
    "    for i in range(len(reconstructions)):\n",
    "        interpolatedImage = normalImages[i]*255\n",
    "        interpolatedImage = cv2.resize(interpolatedImage,(50,50))\n",
    "        interpolatedImage = interpolatedImage.astype(np.uint8)\n",
    "        resultImage = interpolatedImage if resultImage is None else np.hstack([resultImage,interpolatedImage])\n",
    "\n",
    "        reconstructedImage = reconstructions[i]*255.\n",
    "        #reconstructedImage = reconstructedImage.reshape([28,28])\n",
    "        #reconstructedImage = cv2.resize(reconstructedImage,(50,50))\n",
    "        reconstructedImage = reconstructedImage.astype(np.uint8)\n",
    "        resultLatent = reconstructedImage if resultLatent is None else np.hstack([resultLatent,reconstructedImage])\n",
    "    \n",
    "        result = np.vstack([resultImage,resultLatent])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create micro batch\n",
    "#X = np.array([start, end])\n",
    "X = np.array(train_x[0:100])\n",
    "# Compute latent space projection\n",
    "latentX = vae_encoder.predict(X)[2]\n",
    "latentX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "latentStart = latentX[0]\n",
    "latentEnd = latentX[1]\n",
    "# Get original image for comparison\n",
    "startImage, endImage = X\n",
    "\n",
    "vectors = []\n",
    "normalImages = []\n",
    "#Linear interpolation\n",
    "alphaValues = np.linspace(0, 1, 5)\n",
    "for alpha in alphaValues:\n",
    "    # Latent space interpolation\n",
    "    vector = latentStart*(1-alpha) + latentEnd*alpha\n",
    "    vectors.append(vector)\n",
    "    # Image space interpolation\n",
    "    blendImage = cv2.addWeighted(startImage,1-alpha,endImage,alpha,0)\n",
    "    normalImages.append(blendImage)\n",
    "\n",
    "# Decode latent space vectors\n",
    "vectors = np.array(vectors)\n",
    "reconstructions = vae_decoder.predict(vectors)\n",
    "\n",
    "# Put final image together\n",
    "resultLatent = None\n",
    "resultImage = None\n",
    "\n",
    "for i in range(len(reconstructions)):\n",
    "    interpolatedImage = normalImages[i]*255\n",
    "    interpolatedImage = cv2.resize(interpolatedImage,(50,50))\n",
    "    interpolatedImage = interpolatedImage.astype(np.uint8)\n",
    "    resultImage = interpolatedImage if resultImage is None else np.hstack([resultImage,interpolatedImage])\n",
    "\n",
    "    reconstructedImage = reconstructions[i]*255.\n",
    "    #reconstructedImage = reconstructedImage.reshape([28,28])\n",
    "    #reconstructedImage = cv2.resize(reconstructedImage,(50,50))\n",
    "    reconstructedImage = reconstructedImage.astype(np.uint8)\n",
    "    resultLatent = reconstructedImage if resultLatent is None else np.hstack([resultLatent,reconstructedImage])\n",
    "\n",
    "    result = np.vstack([resultImage,resultLatent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes A, B, C, A+B, A+B-C in latent space\n",
    "def visualizeArithmetics(a, b, c, encoder, decoder):\n",
    "    print(\"Computing arithmetics...\")\n",
    "    # Create micro batch\n",
    "    X = np.array([a,b,c])\n",
    "\n",
    "    # Compute latent space projection\n",
    "    latentA, latentB, latentC = encoder.predict(X)\n",
    "\n",
    "    add = latentA+latentB\n",
    "    addSub = latentA+latentB-latentC\n",
    "\n",
    "    # Create micro batch\n",
    "    X = np.array([latentA,latentB,latentC,add,addSub])\n",
    "\n",
    "    # Compute reconstruction\n",
    "    reconstructedA, reconstructedB, reconstructedC, reconstructedAdd, reconstructedAddSub = decoder.predict(X)\n",
    "\n",
    "    cv2.imshow(\"Arithmetics in latent space\",np.hstack([reconstructedA, reconstructedB, reconstructedC, reconstructedAdd, reconstructedAddSub]))\n",
    "    cv2.waitKey()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0284a593613b942586af6b8f0d4ee916e356aed836174e2f823c929bc6bc05cc"
  },
  "kernelspec": {
   "display_name": "dis_vae",
   "language": "python",
   "name": "dis_vae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
