{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import keras.backend as K\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_count=10 #Number of digit categories\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = keras.datasets.mnist.load_data()\n",
    "\n",
    "print('Train data flatten shape: ',train_x.shape)\n",
    "print('Train label shape: ',train_y.shape)\n",
    "print('Test data flatten shape: ',test_x.shape)\n",
    "print('Test label shape: ',test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count=10\n",
    "\n",
    "_, axs = plt.subplots(1, image_count,figsize=(15, 10))\n",
    "for i in range(image_count):\n",
    "  random_idx=random.randint(0,train_x.shape[0])\n",
    "  axs[i].imshow(train_x[random_idx],cmap='gray')\n",
    "  axs[i].axis('off')\n",
    "  axs[i].set_title(train_y[random_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size=10000\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size = val_size,random_state = 1,shuffle=True)\n",
    "\n",
    "print('Train data flatten shape: ',train_x.shape)\n",
    "print('Train label shape: ',train_y.shape)\n",
    "print('Validation data flatten shape: ',val_x.shape)\n",
    "print('Validation label shape: ',val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(train_x.shape) == 3:\n",
    "    train_x = np.expand_dims(train_x, axis=3)\n",
    "    test_x = np.expand_dims(test_x, axis=3)\n",
    "    val_x = np.expand_dims(val_x, axis=3)\n",
    "\n",
    "print('Train shape: ',train_x.shape)\n",
    "print('Test shape: ',test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_x = train_x/255.0\n",
    "val_x = val_x/255.0\n",
    "test_x = test_x/255.0\n",
    "\n",
    "print('Min value: ',train_x.min())\n",
    "print('Max value: ',train_x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_x.shape[2] == 1:\n",
    "    train_x = (train_x * 2) - 1\n",
    "    val_x = (val_x * 2) - 1\n",
    "    test_x = (test_x * 2) -1\n",
    "    print('Min value: ',train_x.min())\n",
    "    print('Max value: ',train_x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(z_mean, z_log_var, input_label):\n",
    "    \"\"\"Reparameterization trick. Instead of sampling from Q(z|X), \n",
    "    sample eps = N(0,I) z = z_mean + sqrt(var)*eps.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    args: list of Tensors\n",
    "        Mean and log of variance of Q(z|X)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    z: Tensor\n",
    "        Sampled latent vector\n",
    "    \"\"\"\n",
    "    eps = tf.random.normal(tf.shape(z_log_var), dtype=tf.float32, mean=0., stddev=1.0, name='epsilon')\n",
    "    z = z_mean + tf.exp(z_log_var / 2) * eps\n",
    "    z_cond = tf.concat([z, input_label], axis=1) # (batch_size, label_dim + latent_dim)\n",
    "    return z_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_CVAE( input_shape = (32, 32, 3),  label_size=2, latent_dim = 2): \n",
    "\n",
    "    inputs = layers.Input(shape=(input_shape[0],\n",
    "            input_shape[1], input_shape[2] + label_size), dtype='float32',name='Input')\n",
    "    #inputs = layers.Input(shape = input_shape)\n",
    "    #labels_inputs = layers.Input(shape = (50, 50, 2))\n",
    "    #encoder_inputs = layers.Concatenate()([inputs, labels_inputs])\n",
    "\n",
    "\n",
    "    #block 1\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv1')(inputs)\n",
    "\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv2')(x)\n",
    "    \n",
    "    # block 2\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv1')(x)\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv2')(x)\n",
    "    x = layers.MaxPool2D(pool_size=2, strides=2,name='S4')(x)\n",
    "    \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # block 3\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv1')(x)\n",
    "    x = layers.Conv2D(16, (3, 3),\n",
    "                activation='relu',\n",
    "                padding='same',\n",
    "                name='block3_conv2')(x)    \n",
    "                    \n",
    "    x = layers.Conv2D(filters=5, kernel_size=5,strides=1,padding='same')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    y = layers.Dense(latent_dim * 2)(x)\n",
    "    z_mean = layers.Dense(latent_dim, name='z_mean')(y)\n",
    "    z_log_var = layers.Dense(latent_dim, name='z_log_var')(y)\n",
    "    #z_cond = layers.Lambda(sampling, name='z')([z_mean, z_log_var, input_label]) #reparametrization trick\n",
    "    model = keras.Model(inputs, [z_mean, z_log_var], name='encoder')\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_CVAE(latent_dim = 2,label_size=2): \n",
    "\n",
    "    decoder_inputs = layers.Input(shape=(latent_dim + label_size,) , name='decoder_input')\n",
    "    x = layers.Dense(14*14*1)(decoder_inputs) # if latent_dim < 25*25*3\n",
    "    x = layers.Reshape(target_shape=(14, 14, 1))(x)\n",
    "    x = layers.Conv2DTranspose(16, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block4_conv1')(x)\n",
    "    x = layers.Conv2DTranspose(16, (3, 3),\n",
    "                    activation='relu',\n",
    "                    padding='same',\n",
    "                    name='up_block4_conv2')(x)  \n",
    "    \n",
    "    # block 2\n",
    "    x = layers.Conv2DTranspose(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block5_conv1')(x)\n",
    "    x = layers.Conv2DTranspose(32, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block5_conv2')(x)\n",
    "    x = layers.UpSampling2D()(x)\n",
    "    \n",
    "    \n",
    "    x = layers.Conv2DTranspose(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='up_block6_conv1')(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(64, (3, 3),\n",
    "                    activation='relu',\n",
    "                    padding='same',\n",
    "                    name='up_block6_conv2')(x)\n",
    "                      \n",
    "                      \n",
    "    outputs = layers.Conv2DTranspose(filters=1, kernel_size=3, strides=1, activation='sigmoid',padding='same')(x)\n",
    "   # outputs = layers.Reshape(target_shape=(50, 50, 3), name='output')(x)\n",
    "    model = keras.Model(decoder_inputs, outputs, name='decoder')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae_encoder = encoder_CVAE(input_shape = (28, 28, 1), latent_dim = 2, label_size=category_count)\n",
    "cvae_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae_decoder = decoder_CVAE(latent_dim = 2, label_size = category_count)\n",
    "cvae_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#condtional vae\n",
    "class CVAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, beta, **kwargs):\n",
    "        super(CVAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.beta = beta\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        #\n",
    "        self.v_total_loss_tracker = keras.metrics.Mean(name=\"v_total_loss\")\n",
    "        self.v_reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"v_reconstruction_loss\")\n",
    "        self.v_kl_loss_tracker = keras.metrics.Mean(name=\"v_kl_loss\")\n",
    "       \n",
    "    def call(self, inputs):\n",
    "        _, input_label, conditional_input = self.conditional_input(inputs)\n",
    "        z_mean, z_log_var = self.encoder(conditional_input)\n",
    "        z_cond = sampling(z_mean, z_log_var, input_label)\n",
    "        return self.decoder(z_cond)\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "    \n",
    "    def conditional_input(self, inputs, image_size=[28, 28, 1], label_size=10): #inputs should be a 2 dim array\n",
    "        input_img = layers.InputLayer(input_shape=image_size, dtype ='float32')(inputs[0])\n",
    "        input_label = layers.InputLayer(input_shape=(label_size, ), dtype ='float32')(inputs[1])\n",
    "        labels = tf.reshape(inputs[1], [-1, 1, 1, label_size]) #batch_size, 1, 1, label_size\n",
    "        labels = tf.cast(labels, dtype='float32')\n",
    "        ones = tf.ones([inputs[0].shape[0]] + image_size[0:-1] + [label_size]) #batch_size, 50, 50, label_size\n",
    "        labels = ones * labels #batch_size, 50, 50, label_size\n",
    "        conditional_input = layers.Concatenate(axis=3)([input_img, labels]) \n",
    "        return  input_img, input_label, conditional_input\n",
    "\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "    \n",
    "        with tf.GradientTape() as tape:\n",
    "        \n",
    "            input_img, input_label, conditional_input = self.conditional_input(data)\n",
    "            z_mean, z_log_var = self.encoder(conditional_input)\n",
    "            z_cond = sampling(z_mean, z_log_var, input_label)\n",
    "            reconstruction = self.decoder(z_cond)\n",
    "            reconstruction_loss = np.prod((28, 28, 1)) * tf.keras.losses.MSE(tf.keras.backend.flatten(input_img), tf.keras.backend.flatten(reconstruction)) # over weighted MSE    \n",
    "            \n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_sum(kl_loss, axis=1)\n",
    "            total_loss = reconstruction_loss + (self.beta * kl_loss)\n",
    "            total_loss = tf.reduce_mean(total_loss) \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "            print(data[0].shape)\n",
    "        input_img, input_label, conditional_input = self.conditional_input(data)\n",
    "        z_mean, z_log_var= self.encoder(conditional_input)\n",
    "        z_cond = sampling(z_mean, z_log_var, input_label)\n",
    "        reconstruction = self.decoder(z_cond)\n",
    "        reconstruction_loss = np.prod((32, 32, 3)) * tf.keras.losses.MSE(tf.keras.backend.flatten(input_img), tf.keras.backend.flatten(reconstruction)) # over weighted MSE    \n",
    "\n",
    "        kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        kl_loss = tf.reduce_sum(kl_loss, axis=1)\n",
    "        total_loss = reconstruction_loss + (self.beta * kl_loss)\n",
    "        total_loss = tf.reduce_mean(total_loss)\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return{\n",
    "            'loss': total_loss,\n",
    "            'reconstruction_loss': reconstruction_loss,\n",
    "            'kl_loss': kl_loss\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_one_hot = to_categorical(train_y,category_count)\n",
    "val_y_one_hot=to_categorical(val_y,category_count)\n",
    "test_y_one_hot=to_categorical(test_y,category_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [train_x, train_y_one_hot]\n",
    "inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_input(inputs, image_size=[28,28,1], label_size=10): #inputs should be a 2 dim array\n",
    "    input_img = layers.InputLayer(input_shape=image_size, dtype ='float32')(inputs[0])\n",
    "    input_label = layers.InputLayer(input_shape=(label_size, ), dtype ='float32')(inputs[1])\n",
    "    labels = tf.reshape(inputs[1], [-1, 1, 1, label_size]) #batch_size, 1, 1, label_size\n",
    "    labels = tf.cast(labels, dtype='float32')\n",
    "    ones = tf.ones([inputs[0].shape[0]] + image_size[0:-1] + [label_size]) #batch_size, 50, 50, label_size\n",
    "    labels = ones * labels #batch_size, 50, 50, label_size\n",
    "    conditional_input = layers.Concatenate(axis=3)([input_img, labels]) \n",
    "    return  input_img, input_label, conditional_input\n",
    "\n",
    "\n",
    "input_img, input_label, conditional_input = conditional_input(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mean, z_log_var = cvae_encoder(conditional_input)\n",
    "z_cond = sampling(z_mean, z_log_var, input_label)\n",
    "z_cond.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction = cvae_decoder(z_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img.shape)\n",
    "print(reconstruction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reconstruction_loss = np.prod((28, 28, 1)) * tf.keras.losses.MSE(tf.keras.backend.flatten(input_img), tf.keras.backend.flatten(reconstruction)) # over weighted MSE    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_coeff = 1\n",
    "cvae = CVAE(encoder=cvae_encoder, decoder=cvae_decoder, beta = beta_coeff)\n",
    "#vae.compile(optimizer='Adam')\n",
    "cvae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1))\n",
    "#lot_model(vae, show_shapes=True, show_layer_names=True,expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae.decoder.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 10\n",
    "#model.compile( optimizer='adam')\n",
    "tf.config.run_functions_eagerly(False)\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "history = cvae.fit([train_x, train_y_one_hot], train_x,\n",
    "                    epochs=epochs, batch_size=batch_size, callbacks=early_stop) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = [train_x, train_y_one_hot]\n",
    "#tf.concat([z, input_label], axis=1)\n",
    "p = cvae.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Val_Plot(loss, val_loss, reconstruction_loss, val_reconstruction_loss, kl_loss, val_kl_loss):\n",
    "    \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize= (16,4))\n",
    "    fig.suptitle(\" MODEL'S METRICS VISUALIZATION \")\n",
    "\n",
    "    ax1.plot(range(1, len(loss) + 1), loss)\n",
    "    ax1.plot(range(1, len(val_loss) + 1), val_loss)\n",
    "    ax1.set_title('History of Loss')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend(['training', 'validation'])\n",
    "\n",
    "    ax2.plot(range(1, len(reconstruction_loss) + 1), reconstruction_loss)\n",
    "    ax2.plot(range(1, len(val_reconstruction_loss) + 1), val_reconstruction_loss)\n",
    "    ax2.set_title('History of reconstruction_loss')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('reconstruction_loss')\n",
    "    ax2.legend(['training', 'validation'])\n",
    "    \n",
    "    ax3.plot(range(1, len(kl_loss) + 1), kl_loss)\n",
    "    ax3.plot(range(1, len(val_kl_loss) + 1), val_kl_loss)\n",
    "    ax3.set_title(' History of kl_loss')\n",
    "    ax3.set_xlabel(' Epochs ')\n",
    "    ax3.set_ylabel('kl_loss')\n",
    "    ax3.legend(['training', 'validation'])\n",
    "     \n",
    "    \n",
    "    plt.show()\n",
    "    #fig.savefig('img/vae_loss_latent:{}_epochs:{}_beta:{}.png'.format(latent_dim, epochs, beta_coeff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Val_Plot(history.history['loss'][1:],\n",
    "               history.history['val_loss'][1:],\n",
    "               history.history['reconstruction_loss'][1:],\n",
    "               history.history['val_reconstruction_loss'][1:],\n",
    "               history.history['kl_loss'][1:],\n",
    "               history.history['val_kl_loss'][1:]\n",
    "               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cvae.save_weights('weights/vae_toy.h5')\n",
    "cvae.built = True\n",
    "cvae.load_weights('weights/vae_toy.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(y_true, y_pred):    \n",
    "    f, ax = plt.subplots(2, 10, figsize=(15, 4))\n",
    "    for i in range(10):\n",
    "        ax[0][i].imshow(np.reshape(y_true[i], (32, 32, 3)), aspect='auto')\n",
    "        ax[1][i].imshow(np.reshape(y_pred[i], (32, 32, 3)), aspect='auto')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(train_x[:100], p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter with images instead of points\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "img_size = 32\n",
    "def imscatter(x, y, ax, imageData, zoom):\n",
    "    images = []\n",
    "    for i in range(len(x)):\n",
    "        x0, y0 = x[i], y[i]\n",
    "        # Convert to image\n",
    "        img = imageData[i]*255.\n",
    "        img = img.astype(np.uint8).reshape([img_size,img_size,3])\n",
    "        #img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
    "        # Note: OpenCV uses BGR and plt uses RGB\n",
    "        image = OffsetImage(img, zoom=zoom)\n",
    "        ab = AnnotationBbox(image, (x0, y0), xycoords='data', frameon=False)\n",
    "        images.append(ax.add_artist(ab))\n",
    "    \n",
    "    ax.update_datalim(np.column_stack([x, y]))\n",
    "    ax.autoscale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/despoisj/LatentSpaceVisualization/blob/master/visuals.py\n",
    "from sklearn import manifold\n",
    "\n",
    "def computeTSNEProjectionOfLatentSpace(X, X_encoded, display=True, save=True):\n",
    "    # Compute latent space representation\n",
    "    print(\"Computing latent space projection...\")\n",
    "    #X_encoded = encoder.predict(X)\n",
    "\n",
    "    # Compute t-SNE embedding of latent space\n",
    "    print(\"Computing t-SNE embedding...\")\n",
    "    tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "    X_tsne = tsne.fit_transform(X_encoded)\n",
    "\n",
    "    # Plot images according to t-sne embedding\n",
    "    if display:\n",
    "        print(\"Plotting t-SNE visualization...\")\n",
    "        fig, ax = plt.subplots(figsize=(15, 15))\n",
    "        ax = fig.add_subplot(111, facecolor='black')\n",
    "        imscatter(X_tsne[:, 0], X_tsne[:, 1], imageData=X, ax=ax, zoom=0.5)\n",
    "        if save:\n",
    "            fig.savefig('img/t-SNE-embedding_vae_epochs:{}_beta:{}.png'.format(epochs, beta_coeff))\n",
    "        plt.show()\n",
    "    else:\n",
    "        return X_tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded = cvae.encoder.predict(inputs)\n",
    "X_encoded.shape\n",
    "#need to reshape for TSNE\n",
    "#X_encoded_flatten = X_encoded.reshape(-1,25*25*3)\n",
    "#X_encoded_flatten.shape\n",
    "X_encoded_flatten = X_encoded\n",
    "X_encoded_flatten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeTSNEProjectionOfLatentSpace(train_x[:1000,], X_encoded_flatten, display=True, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReconstructedImages(X, encoder, decoder):\n",
    "    img_size = 32\n",
    "    nbSamples = X.shape[0]\n",
    "    nbSquares = int(math.sqrt(nbSamples))\n",
    "    nbSquaresHeight = 2*nbSquares\n",
    "    nbSquaresWidth = nbSquaresHeight\n",
    "    resultImage = np.zeros((nbSquaresHeight*img_size,int(nbSquaresWidth*img_size/2),X.shape[-1]))\n",
    "\n",
    "    reconstructedX = decoder.predict(encoder.predict(X)[2])\n",
    "\n",
    "    for i in range(nbSamples) :     # \n",
    "        original = X[i]\n",
    "        reconstruction = reconstructedX[i]\n",
    "        rowIndex = i%nbSquaresWidth\n",
    "        columnIndex = int((i-rowIndex)/nbSquaresHeight)\n",
    "        resultImage[rowIndex*img_size:(rowIndex+1)*img_size,columnIndex*2*img_size:(columnIndex+1)*2*img_size,:] = np.hstack([original,reconstruction])\n",
    "\n",
    "    return resultImage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstructions for samples in dataset\n",
    "def visualizeReconstructedImages(X_train, X_test, encoder, decoder, save=False):\n",
    "    trainReconstruction = getReconstructedImages(X_train, encoder, decoder)\n",
    "    testReconstruction = getReconstructedImages(X_test, encoder, decoder)\n",
    "\n",
    "    if not save:\n",
    "        print(\"Generating 10 image reconstructions...\")\n",
    "\n",
    "    result = np.hstack([trainReconstruction,\n",
    "            np.zeros([trainReconstruction.shape[0],5,\n",
    "            trainReconstruction.shape[-1]]),\n",
    "            testReconstruction])\n",
    "    result = (result*255.).astype(np.uint8)\n",
    "\n",
    "    if save:\n",
    "        fig, _ = plt.subplots(figsize=(15, 15))\n",
    "        plt.imshow(result)\n",
    "        fig.savefig('img/vae_reconstructions_epochs:{}_beta:{}.png'.format(epochs, beta_coeff))\n",
    "    else:\n",
    "        fig, _ = plt.subplots(figsize=(15, 15))\n",
    "        plt.imshow(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizeReconstructedImages(train_x[:100], test_x[:100], cvae_encoder, cvae_decoder, save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = cvae.encoder.output_shape[0][1]\n",
    "latent_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae.decoder.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_images(decoder):    \n",
    "    fig, ax = plt.subplots(2, 10, figsize=(15, 4))\n",
    "    label = train_y_one_hot[0]\n",
    "    print(label)\n",
    "    for i in range(2):\n",
    "        for j in range(10):\n",
    "            noise = np.random.normal(loc=0, scale = 1, size=(20,latent_dim))\n",
    "                \n",
    "            noise = np.array(noise)\n",
    "            print(noise.shape)\n",
    "            print(label.shape)\n",
    "            #noise = noise.reshape(1, latent_dim)\n",
    "            input = tf.concat([noise, label], axis=1)\n",
    "            decoded = cvae_decoder.predict(input).squeeze()\n",
    "            ax[i][j].imshow( (decoded*255.).astype(np.uint8) )\n",
    "    fig.savefig('img/vae_generations_latent:{}_epochs:{}_beta:{}.png'.format(latent_dim, epochs, beta_coeff))   \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_images(cvae_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGeneratedImages(X, y, encoder, decoder):\n",
    "    img_size = 32\n",
    "    nbSamples = X.shape[0]\n",
    "    nbSquares = int(math.sqrt(nbSamples))\n",
    "    nbSquaresHeight = 2*nbSquares\n",
    "    nbSquaresWidth = nbSquaresHeight\n",
    "    resultImage = np.zeros((nbSquaresHeight*img_size,int(nbSquaresWidth*img_size/2),X.shape[-1]))\n",
    "\n",
    "    inputs = [X[:1000], y[:1000] ]\n",
    "    #_, _, conditional_input = cvae.conditional_input(inputs)\n",
    "    reconstructedX = decoder.predict(encoder.predict(inputs)[2])\n",
    "\n",
    "    for i in range(nbSamples) :     # \n",
    "        #original = X[i]\n",
    "        reconstruction = reconstructedX[i]\n",
    "        rowIndex = i%nbSquaresWidth\n",
    "        columnIndex = int((i-rowIndex)/nbSquaresHeight)\n",
    "        resultImage[rowIndex*img_size:(rowIndex+1)*img_size,columnIndex*2*img_size:(columnIndex+1)*2*img_size,:] = np.hstack([reconstruction])\n",
    "\n",
    "    return resultImage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstructions for samples in dataset\n",
    "def visualizeGeneratedImages(encoder, decoder, save=False):\n",
    "    X_healthy = generate_random_img(decoder, labels = (0,1) )\n",
    "    X_cancer = generate_random_img(decoder, labels= (1,0) )\n",
    "    healthyReconstruction = getGeneratedImages(X = X_healthy, y= (0,1), encoder = encoder, decoder = decoder)\n",
    "    cancerReconstruction = getGeneratedImages(X= X_cancer, y= (1,0), encoder = encoder, decoder = decoder)\n",
    "\n",
    "    if not save:\n",
    "        print(\"Generating 10 image reconstructions...\")\n",
    "\n",
    "    result = np.hstack([healthyReconstruction,\n",
    "            np.zeros([healthyReconstruction.shape[0],5,\n",
    "            healthyReconstruction.shape[-1]]),\n",
    "            cancerReconstruction])\n",
    "    result = (result*255.).astype(np.uint8)\n",
    "\n",
    "    if save:\n",
    "        fig, _ = plt.subplots(figsize=(15, 15))\n",
    "        plt.imshow(result)\n",
    "        fig.savefig('img/Cvae_generated_epochs:{}_beta:{}.png'.format(epochs, beta_coeff))\n",
    "    else:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizeGeneratedImages(vae_encoder, vae_decoder, save=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0284a593613b942586af6b8f0d4ee916e356aed836174e2f823c929bc6bc05cc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('dis_vae')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
